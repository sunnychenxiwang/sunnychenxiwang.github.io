<!DOCTYPE html>
<html lang="en-us" dir="ltr">
    <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content="è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€ ä¸»è¦æ ¹æ®cs224nåšç¬”è®°ï¼ŒåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ä¸ºè¾… å‚è€ƒèµ„æº http://web.stanford.edu/class/cs224n/ï¼šè¯¾ä»¶ã€ä½œä¸šã€é™„ä»¶é˜…è¯»èµ„æ–™ https://showmeai.tech/article-detail/235 https://github.com/Yiming-Wange/CS224n-2023-solution WordVec å¦‚ä½•åœ¨è®¡ç®—æœºè¡¨è¾¾è¯çš„æ„ä¹‰ WordNetï¼šæ„å»ºä¸€ä¸ªåŒ…å«åŒä¹‰è¯é›†å’Œä¸Šä½è¯ï¼ˆä»å±å…³ç³»ï¼ŒåŠ¨ç‰©æ˜¯â€œç‹—â€ã€â€œçŒ«â€ã€â€œé¸Ÿâ€ç­‰å…·ä½“åŠ¨ç‰©çš„ä¸Šä½è¯ï¼‰çš„åˆ—è¡¨çš„è¾å…¸ã€‚é—®é¢˜ï¼š1ï¼‰å¿½ç•¥è¯æ±‡çš„ç»†å¾®å·®åˆ«ï¼Œä¹Ÿä¸èƒ½å®šé‡è®¡ç®—å•è¯çš„ç›¸ä¼¼æ€§ã€‚2ï¼‰éš¾ä»¥æŒç»­æ›´æ–°ã€‚3ï¼‰ç”±äººå·¥æ„å»ºï¼Œå¸¦æœ‰ä¸»è§‚æ€§ä»¥åŠæˆæœ¬é«˜ 1 WordNetæ˜¯ä¸€ä¸ªè¯æ±‡æ•°æ®åº“ï¼Œè®°å½•äº†å•è¯ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ï¼ŒåŒ…æ‹¬åŒä¹‰è¯ã€ä¸‹ä¹‰è¯å’Œéƒ¨åˆ†ä¹‰è¯ç­‰è¯­ä¹‰å…³è”ã€‚åŒä¹‰è¯è¢«ç»„ç»‡æˆåŒä¹‰è¯é›†ï¼Œé…æœ‰ç®€çŸ­çš„å®šä¹‰å’Œä½¿ç”¨ç¤ºä¾‹ã€‚å®ƒå¯ä»¥è¢«çœ‹ä½œæ˜¯å­—å…¸å’Œè¯å…¸çš„ç»“åˆå’Œå»¶ä¼¸ã€‚è™½ç„¶å¯ä»¥é€šè¿‡ç½‘ç»œæµè§ˆå™¨è®¿é—®ï¼Œä½†å…¶ä¸»è¦ç”¨é€”æ˜¯ç”¨äºè‡ªåŠ¨æ–‡æœ¬åˆ†æå’Œäººå·¥æ™ºèƒ½åº”ç”¨ã€‚æœ€åˆæ˜¯ç”¨è‹±è¯­åˆ›å»ºçš„ï¼Œè‹±è¯­WordNetæ•°æ®åº“å’Œè½¯ä»¶å·¥å…·ä»¥BSDé£æ ¼è®¸å¯è¯å‘å¸ƒï¼Œå¹¶å¯ä»WordNetç½‘ç«™å…è´¹ä¸‹è½½ã€‚ç°åœ¨å·²ç»æœ‰200å¤šç§è¯­è¨€çš„WordNetã€‚ 1 2 3 4 5 6 7 8 9 10 11 # åŒä¹‰è¯é›† from nltk.corpus import wordnet as wn poses = { &#39;n&#39;:&#39;noun&#39;, &#39;v&#39;:&#39;verb&#39;, &#39;s&#39;:&#39;adj (s)&#39;, &#39;a&#39;:&#39;adj&#39;, &#39;r&#39;:&#39;adv&#39;} for synset in wn.synsets(&#34;good&#34;): print(&#34;{}: {}&#34;.format(poses[synset.pos()], &#34;, &#34;.join([l.name() for l in synset.lemmas()]))) # ä¸Šä½è¯ from nltk.corpus import wordnet as wn panda = wn.synset(&#34;panda.n.01&#34;) hyper = lambda s: s.hypernyms() list(panda.closure(hyper)) è¯æ±‡çš„ç¦»æ•£è¡¨å¾ï¼šå°†æ¯ä¸ªè¯è¯­çœ‹ä½œå•ç‹¬ç¦»æ•£çš„ç¬¦å·ï¼Œå¹¶æŠŠå•è¯è¡¨å¾ä¸ºç‹¬çƒ­ç¼–ç ã€‚é—®é¢˜ï¼š1ï¼‰æ¯ä¸ªè¯å‘é‡ä¹‹é—´æ­£äº¤ä¸èƒ½å¾ˆå¥½çš„å»ºæ¨¡å•è¯ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚2ï¼‰å‘é‡ç»´åº¦å¤§ï¼Œæ¯å¢åŠ ä¸€ä¸ªå•è¯å°±å¢åŠ ä¸€ä¸ªç»´åº¦ã€‚è§£å†³æ–¹æ¡ˆï¼šé€šè¿‡å¤§é‡æ•°æ®å­¦ä¹ è¯å‘é‡æœ¬èº«ç›¸ä¼¼æ€§ï¼Œè·å¾—æ›´ç²¾ç¡®çš„ç¨ å¯†è¯å‘é‡ç¼–ç  åŸºäºä¸Šä¸‹æ–‡è¯æ±‡è¡¨å¾ã€‚æ ¸å¿ƒæ€æƒ³ï¼šä¸€ä¸ªå•è¯çš„æ„æ€æ˜¯ç”±ç»å¸¸å‡ºç°åœ¨å®ƒé™„è¿‘çš„å•è¯ç»™å‡ºçš„ã€‚æ–¹æ³•ï¼šå½“ä¸€ä¸ªå•è¯wå‡ºç°åœ¨æ–‡æœ¬ä¸­æ—¶ï¼Œå®ƒçš„ä¸Šä¸‹æ–‡æ˜¯å‡ºç°åœ¨å…¶é™„è¿‘çš„ä¸€ç»„å•è¯ï¼ˆåœ¨ä¸€ä¸ªå›ºå®šå¤§å°çš„çª—å£ä¸­ï¼‰ã€‚åŸºäºæµ·é‡æ•°æ®ï¼Œä½¿ç”¨wçš„è®¸å¤šä¸Šä¸‹æ–‡æ¥æ„å»ºwçš„è¡¨ç¤º">
<title>è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€</title>

<link rel='canonical' href='http://localhost:1313/p/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80/'>

<link rel="stylesheet" href="/scss/style.min.0304c6baf04e01a8fe70693791cb744d56a3578a3120a8796cefc66825aa39c7.css"><meta property='og:title' content="è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€">
<meta property='og:description' content="è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€ ä¸»è¦æ ¹æ®cs224nåšç¬”è®°ï¼ŒåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ä¸ºè¾… å‚è€ƒèµ„æº http://web.stanford.edu/class/cs224n/ï¼šè¯¾ä»¶ã€ä½œä¸šã€é™„ä»¶é˜…è¯»èµ„æ–™ https://showmeai.tech/article-detail/235 https://github.com/Yiming-Wange/CS224n-2023-solution WordVec å¦‚ä½•åœ¨è®¡ç®—æœºè¡¨è¾¾è¯çš„æ„ä¹‰ WordNetï¼šæ„å»ºä¸€ä¸ªåŒ…å«åŒä¹‰è¯é›†å’Œä¸Šä½è¯ï¼ˆä»å±å…³ç³»ï¼ŒåŠ¨ç‰©æ˜¯â€œç‹—â€ã€â€œçŒ«â€ã€â€œé¸Ÿâ€ç­‰å…·ä½“åŠ¨ç‰©çš„ä¸Šä½è¯ï¼‰çš„åˆ—è¡¨çš„è¾å…¸ã€‚é—®é¢˜ï¼š1ï¼‰å¿½ç•¥è¯æ±‡çš„ç»†å¾®å·®åˆ«ï¼Œä¹Ÿä¸èƒ½å®šé‡è®¡ç®—å•è¯çš„ç›¸ä¼¼æ€§ã€‚2ï¼‰éš¾ä»¥æŒç»­æ›´æ–°ã€‚3ï¼‰ç”±äººå·¥æ„å»ºï¼Œå¸¦æœ‰ä¸»è§‚æ€§ä»¥åŠæˆæœ¬é«˜ 1 WordNetæ˜¯ä¸€ä¸ªè¯æ±‡æ•°æ®åº“ï¼Œè®°å½•äº†å•è¯ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ï¼ŒåŒ…æ‹¬åŒä¹‰è¯ã€ä¸‹ä¹‰è¯å’Œéƒ¨åˆ†ä¹‰è¯ç­‰è¯­ä¹‰å…³è”ã€‚åŒä¹‰è¯è¢«ç»„ç»‡æˆåŒä¹‰è¯é›†ï¼Œé…æœ‰ç®€çŸ­çš„å®šä¹‰å’Œä½¿ç”¨ç¤ºä¾‹ã€‚å®ƒå¯ä»¥è¢«çœ‹ä½œæ˜¯å­—å…¸å’Œè¯å…¸çš„ç»“åˆå’Œå»¶ä¼¸ã€‚è™½ç„¶å¯ä»¥é€šè¿‡ç½‘ç»œæµè§ˆå™¨è®¿é—®ï¼Œä½†å…¶ä¸»è¦ç”¨é€”æ˜¯ç”¨äºè‡ªåŠ¨æ–‡æœ¬åˆ†æå’Œäººå·¥æ™ºèƒ½åº”ç”¨ã€‚æœ€åˆæ˜¯ç”¨è‹±è¯­åˆ›å»ºçš„ï¼Œè‹±è¯­WordNetæ•°æ®åº“å’Œè½¯ä»¶å·¥å…·ä»¥BSDé£æ ¼è®¸å¯è¯å‘å¸ƒï¼Œå¹¶å¯ä»WordNetç½‘ç«™å…è´¹ä¸‹è½½ã€‚ç°åœ¨å·²ç»æœ‰200å¤šç§è¯­è¨€çš„WordNetã€‚ 1 2 3 4 5 6 7 8 9 10 11 # åŒä¹‰è¯é›† from nltk.corpus import wordnet as wn poses = { &#39;n&#39;:&#39;noun&#39;, &#39;v&#39;:&#39;verb&#39;, &#39;s&#39;:&#39;adj (s)&#39;, &#39;a&#39;:&#39;adj&#39;, &#39;r&#39;:&#39;adv&#39;} for synset in wn.synsets(&#34;good&#34;): print(&#34;{}: {}&#34;.format(poses[synset.pos()], &#34;, &#34;.join([l.name() for l in synset.lemmas()]))) # ä¸Šä½è¯ from nltk.corpus import wordnet as wn panda = wn.synset(&#34;panda.n.01&#34;) hyper = lambda s: s.hypernyms() list(panda.closure(hyper)) è¯æ±‡çš„ç¦»æ•£è¡¨å¾ï¼šå°†æ¯ä¸ªè¯è¯­çœ‹ä½œå•ç‹¬ç¦»æ•£çš„ç¬¦å·ï¼Œå¹¶æŠŠå•è¯è¡¨å¾ä¸ºç‹¬çƒ­ç¼–ç ã€‚é—®é¢˜ï¼š1ï¼‰æ¯ä¸ªè¯å‘é‡ä¹‹é—´æ­£äº¤ä¸èƒ½å¾ˆå¥½çš„å»ºæ¨¡å•è¯ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚2ï¼‰å‘é‡ç»´åº¦å¤§ï¼Œæ¯å¢åŠ ä¸€ä¸ªå•è¯å°±å¢åŠ ä¸€ä¸ªç»´åº¦ã€‚è§£å†³æ–¹æ¡ˆï¼šé€šè¿‡å¤§é‡æ•°æ®å­¦ä¹ è¯å‘é‡æœ¬èº«ç›¸ä¼¼æ€§ï¼Œè·å¾—æ›´ç²¾ç¡®çš„ç¨ å¯†è¯å‘é‡ç¼–ç  åŸºäºä¸Šä¸‹æ–‡è¯æ±‡è¡¨å¾ã€‚æ ¸å¿ƒæ€æƒ³ï¼šä¸€ä¸ªå•è¯çš„æ„æ€æ˜¯ç”±ç»å¸¸å‡ºç°åœ¨å®ƒé™„è¿‘çš„å•è¯ç»™å‡ºçš„ã€‚æ–¹æ³•ï¼šå½“ä¸€ä¸ªå•è¯wå‡ºç°åœ¨æ–‡æœ¬ä¸­æ—¶ï¼Œå®ƒçš„ä¸Šä¸‹æ–‡æ˜¯å‡ºç°åœ¨å…¶é™„è¿‘çš„ä¸€ç»„å•è¯ï¼ˆåœ¨ä¸€ä¸ªå›ºå®šå¤§å°çš„çª—å£ä¸­ï¼‰ã€‚åŸºäºæµ·é‡æ•°æ®ï¼Œä½¿ç”¨wçš„è®¸å¤šä¸Šä¸‹æ–‡æ¥æ„å»ºwçš„è¡¨ç¤º">
<meta property='og:url' content='http://localhost:1313/p/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80/'>
<meta property='og:site_name' content='Hugo Theme Stack Starter'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:published_time' content='2024-08-16T20:36:47&#43;08:00'/><meta property='article:modified_time' content='2024-08-16T20:36:47&#43;08:00'/>
<meta name="twitter:title" content="è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€">
<meta name="twitter:description" content="è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€ ä¸»è¦æ ¹æ®cs224nåšç¬”è®°ï¼ŒåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ä¸ºè¾… å‚è€ƒèµ„æº http://web.stanford.edu/class/cs224n/ï¼šè¯¾ä»¶ã€ä½œä¸šã€é™„ä»¶é˜…è¯»èµ„æ–™ https://showmeai.tech/article-detail/235 https://github.com/Yiming-Wange/CS224n-2023-solution WordVec å¦‚ä½•åœ¨è®¡ç®—æœºè¡¨è¾¾è¯çš„æ„ä¹‰ WordNetï¼šæ„å»ºä¸€ä¸ªåŒ…å«åŒä¹‰è¯é›†å’Œä¸Šä½è¯ï¼ˆä»å±å…³ç³»ï¼ŒåŠ¨ç‰©æ˜¯â€œç‹—â€ã€â€œçŒ«â€ã€â€œé¸Ÿâ€ç­‰å…·ä½“åŠ¨ç‰©çš„ä¸Šä½è¯ï¼‰çš„åˆ—è¡¨çš„è¾å…¸ã€‚é—®é¢˜ï¼š1ï¼‰å¿½ç•¥è¯æ±‡çš„ç»†å¾®å·®åˆ«ï¼Œä¹Ÿä¸èƒ½å®šé‡è®¡ç®—å•è¯çš„ç›¸ä¼¼æ€§ã€‚2ï¼‰éš¾ä»¥æŒç»­æ›´æ–°ã€‚3ï¼‰ç”±äººå·¥æ„å»ºï¼Œå¸¦æœ‰ä¸»è§‚æ€§ä»¥åŠæˆæœ¬é«˜ 1 WordNetæ˜¯ä¸€ä¸ªè¯æ±‡æ•°æ®åº“ï¼Œè®°å½•äº†å•è¯ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ï¼ŒåŒ…æ‹¬åŒä¹‰è¯ã€ä¸‹ä¹‰è¯å’Œéƒ¨åˆ†ä¹‰è¯ç­‰è¯­ä¹‰å…³è”ã€‚åŒä¹‰è¯è¢«ç»„ç»‡æˆåŒä¹‰è¯é›†ï¼Œé…æœ‰ç®€çŸ­çš„å®šä¹‰å’Œä½¿ç”¨ç¤ºä¾‹ã€‚å®ƒå¯ä»¥è¢«çœ‹ä½œæ˜¯å­—å…¸å’Œè¯å…¸çš„ç»“åˆå’Œå»¶ä¼¸ã€‚è™½ç„¶å¯ä»¥é€šè¿‡ç½‘ç»œæµè§ˆå™¨è®¿é—®ï¼Œä½†å…¶ä¸»è¦ç”¨é€”æ˜¯ç”¨äºè‡ªåŠ¨æ–‡æœ¬åˆ†æå’Œäººå·¥æ™ºèƒ½åº”ç”¨ã€‚æœ€åˆæ˜¯ç”¨è‹±è¯­åˆ›å»ºçš„ï¼Œè‹±è¯­WordNetæ•°æ®åº“å’Œè½¯ä»¶å·¥å…·ä»¥BSDé£æ ¼è®¸å¯è¯å‘å¸ƒï¼Œå¹¶å¯ä»WordNetç½‘ç«™å…è´¹ä¸‹è½½ã€‚ç°åœ¨å·²ç»æœ‰200å¤šç§è¯­è¨€çš„WordNetã€‚ 1 2 3 4 5 6 7 8 9 10 11 # åŒä¹‰è¯é›† from nltk.corpus import wordnet as wn poses = { &#39;n&#39;:&#39;noun&#39;, &#39;v&#39;:&#39;verb&#39;, &#39;s&#39;:&#39;adj (s)&#39;, &#39;a&#39;:&#39;adj&#39;, &#39;r&#39;:&#39;adv&#39;} for synset in wn.synsets(&#34;good&#34;): print(&#34;{}: {}&#34;.format(poses[synset.pos()], &#34;, &#34;.join([l.name() for l in synset.lemmas()]))) # ä¸Šä½è¯ from nltk.corpus import wordnet as wn panda = wn.synset(&#34;panda.n.01&#34;) hyper = lambda s: s.hypernyms() list(panda.closure(hyper)) è¯æ±‡çš„ç¦»æ•£è¡¨å¾ï¼šå°†æ¯ä¸ªè¯è¯­çœ‹ä½œå•ç‹¬ç¦»æ•£çš„ç¬¦å·ï¼Œå¹¶æŠŠå•è¯è¡¨å¾ä¸ºç‹¬çƒ­ç¼–ç ã€‚é—®é¢˜ï¼š1ï¼‰æ¯ä¸ªè¯å‘é‡ä¹‹é—´æ­£äº¤ä¸èƒ½å¾ˆå¥½çš„å»ºæ¨¡å•è¯ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚2ï¼‰å‘é‡ç»´åº¦å¤§ï¼Œæ¯å¢åŠ ä¸€ä¸ªå•è¯å°±å¢åŠ ä¸€ä¸ªç»´åº¦ã€‚è§£å†³æ–¹æ¡ˆï¼šé€šè¿‡å¤§é‡æ•°æ®å­¦ä¹ è¯å‘é‡æœ¬èº«ç›¸ä¼¼æ€§ï¼Œè·å¾—æ›´ç²¾ç¡®çš„ç¨ å¯†è¯å‘é‡ç¼–ç  åŸºäºä¸Šä¸‹æ–‡è¯æ±‡è¡¨å¾ã€‚æ ¸å¿ƒæ€æƒ³ï¼šä¸€ä¸ªå•è¯çš„æ„æ€æ˜¯ç”±ç»å¸¸å‡ºç°åœ¨å®ƒé™„è¿‘çš„å•è¯ç»™å‡ºçš„ã€‚æ–¹æ³•ï¼šå½“ä¸€ä¸ªå•è¯wå‡ºç°åœ¨æ–‡æœ¬ä¸­æ—¶ï¼Œå®ƒçš„ä¸Šä¸‹æ–‡æ˜¯å‡ºç°åœ¨å…¶é™„è¿‘çš„ä¸€ç»„å•è¯ï¼ˆåœ¨ä¸€ä¸ªå›ºå®šå¤§å°çš„çª—å£ä¸­ï¼‰ã€‚åŸºäºæµ·é‡æ•°æ®ï¼Œä½¿ç”¨wçš„è®¸å¤šä¸Šä¸‹æ–‡æ¥æ„å»ºwçš„è¡¨ç¤º">
    <link rel="shortcut icon" href="/favicon.png" />

  


    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu897059592634026878.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
                    <span class="emoji">ğŸ¥</span>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">Hugo Theme Stack Starter</a></h1>
            <h2 class="site-description">Lorem ipsum dolor sit amet, consectetur adipiscing elit.</h2>
        </div>
    </header><ol class="menu-social">
            
                <li>
                    <a 
                        href='https://github.com/CaiJimmy/hugo-theme-stack'
                        target="_blank"
                        title="GitHub"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" />
</svg>



                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://twitter.com'
                        target="_blank"
                        title="Twitter"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M22 4.01c-1 .49 -1.98 .689 -3 .99c-1.121 -1.265 -2.783 -1.335 -4.38 -.737s-2.643 2.06 -2.62 3.737v1c-3.245 .083 -6.135 -1.395 -8 -4c0 0 -4.182 7.433 4 11c-1.872 1.247 -3.739 2.088 -6 2c3.308 1.803 6.913 2.423 10.034 1.517c3.58 -1.04 6.522 -3.723 7.651 -7.742a13.84 13.84 0 0 0 .497 -3.753c-.002 -.249 1.51 -2.772 1.818 -4.013z" />
</svg>



                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>Home</span>
            </a>
        </li>
        
        
        <li >
            <a href='/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>Archives</span>
            </a>
        </li>
        
        
        <li >
            <a href='/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>Search</span>
            </a>
        </li>
        
        
        <li >
            <a href='/links/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5" />
  <path d="M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5" />
</svg>



                
                <span>Links</span>
            </a>
        </li>
        
        <li class="menu-bottom-section">
            <ol class="menu">

                
                    <li id="dark-mode-toggle">
                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <span>Dark Mode</span>
                    </li>
                
            </ol>
        </li>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">Table of contents</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#wordvec">WordVec</a></li>
    <li><a href="#classifier">Classifier</a></li>
    <li><a href="#backpropagation">BackPropagation</a></li>
    <li><a href="#rnn">RNN</a></li>
    <li><a href="#attention">Attention</a></li>
    <li><a href="#pre-training">Pre-training</a></li>
    <li><a href="#nlg">NLG</a></li>
    <li><a href="#prompt">Prompt</a></li>
    <li><a href="#instruction">Instruction</a></li>
    <li><a href="#rlhf">RLHF</a></li>
    <li><a href="#dpo">DPO</a></li>
    <li><a href="#reasoning">Reasoning</a></li>
    <li><a href="#agents">Agents</a></li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/p/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E5%9F%BA%E7%A1%80/">è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€</a>
        </h2>
    
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Aug 16, 2024</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    14 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <h1 id="è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€">è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€
</h1><p>ä¸»è¦æ ¹æ®cs224nåšç¬”è®°ï¼ŒåŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ ä¸ºè¾…</p>
<p>å‚è€ƒèµ„æº</p>
<ul>
<li><a class="link" href="http://web.stanford.edu/class/cs224n/"  target="_blank" rel="noopener"
    >http://web.stanford.edu/class/cs224n/</a>ï¼šè¯¾ä»¶ã€ä½œä¸šã€é™„ä»¶é˜…è¯»èµ„æ–™</li>
<li><a class="link" href="https://showmeai.tech/article-detail/235"  target="_blank" rel="noopener"
    >https://showmeai.tech/article-detail/235</a></li>
<li><a class="link" href="https://github.com/Yiming-Wange/CS224n-2023-solution"  target="_blank" rel="noopener"
    >https://github.com/Yiming-Wange/CS224n-2023-solution</a></li>
</ul>
<h2 id="wordvec">WordVec
</h2><p>å¦‚ä½•åœ¨è®¡ç®—æœºè¡¨è¾¾è¯çš„æ„ä¹‰</p>
<ul>
<li>
<p>WordNetï¼šæ„å»ºä¸€ä¸ªåŒ…å«åŒä¹‰è¯é›†å’Œä¸Šä½è¯ï¼ˆä»å±å…³ç³»ï¼ŒåŠ¨ç‰©æ˜¯â€œç‹—â€ã€â€œçŒ«â€ã€â€œé¸Ÿâ€ç­‰å…·ä½“åŠ¨ç‰©çš„ä¸Šä½è¯ï¼‰çš„åˆ—è¡¨çš„è¾å…¸ã€‚é—®é¢˜ï¼š1ï¼‰å¿½ç•¥è¯æ±‡çš„ç»†å¾®å·®åˆ«ï¼Œä¹Ÿä¸èƒ½å®šé‡è®¡ç®—å•è¯çš„ç›¸ä¼¼æ€§ã€‚2ï¼‰éš¾ä»¥æŒç»­æ›´æ–°ã€‚3ï¼‰ç”±äººå·¥æ„å»ºï¼Œå¸¦æœ‰ä¸»è§‚æ€§ä»¥åŠæˆæœ¬é«˜</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-markdown" data-lang="markdown"><span class="line"><span class="cl">WordNetæ˜¯ä¸€ä¸ªè¯æ±‡æ•°æ®åº“ï¼Œè®°å½•äº†å•è¯ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ï¼ŒåŒ…æ‹¬åŒä¹‰è¯ã€ä¸‹ä¹‰è¯å’Œéƒ¨åˆ†ä¹‰è¯ç­‰è¯­ä¹‰å…³è”ã€‚åŒä¹‰è¯è¢«ç»„ç»‡æˆåŒä¹‰è¯é›†ï¼Œé…æœ‰ç®€çŸ­çš„å®šä¹‰å’Œä½¿ç”¨ç¤ºä¾‹ã€‚å®ƒå¯ä»¥è¢«çœ‹ä½œæ˜¯å­—å…¸å’Œè¯å…¸çš„ç»“åˆå’Œå»¶ä¼¸ã€‚è™½ç„¶å¯ä»¥é€šè¿‡ç½‘ç»œæµè§ˆå™¨è®¿é—®ï¼Œä½†å…¶ä¸»è¦ç”¨é€”æ˜¯ç”¨äºè‡ªåŠ¨æ–‡æœ¬åˆ†æå’Œäººå·¥æ™ºèƒ½åº”ç”¨ã€‚æœ€åˆæ˜¯ç”¨è‹±è¯­åˆ›å»ºçš„ï¼Œè‹±è¯­WordNetæ•°æ®åº“å’Œè½¯ä»¶å·¥å…·ä»¥BSDé£æ ¼è®¸å¯è¯å‘å¸ƒï¼Œå¹¶å¯ä»WordNetç½‘ç«™å…è´¹ä¸‹è½½ã€‚ç°åœ¨å·²ç»æœ‰200å¤šç§è¯­è¨€çš„WordNetã€‚
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># åŒä¹‰è¯é›†</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">wordnet</span> <span class="k">as</span> <span class="n">wn</span>
</span></span><span class="line"><span class="cl"><span class="n">poses</span> <span class="o">=</span> <span class="p">{</span> <span class="s1">&#39;n&#39;</span><span class="p">:</span><span class="s1">&#39;noun&#39;</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">:</span><span class="s1">&#39;verb&#39;</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">:</span><span class="s1">&#39;adj (s)&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">:</span><span class="s1">&#39;adj&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">:</span><span class="s1">&#39;adv&#39;</span><span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">synset</span> <span class="ow">in</span> <span class="n">wn</span><span class="o">.</span><span class="n">synsets</span><span class="p">(</span><span class="s2">&#34;good&#34;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="nb">print</span><span class="p">(</span><span class="s2">&#34;</span><span class="si">{}</span><span class="s2">: </span><span class="si">{}</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">poses</span><span class="p">[</span><span class="n">synset</span><span class="o">.</span><span class="n">pos</span><span class="p">()],</span> <span class="s2">&#34;, &#34;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">l</span><span class="o">.</span><span class="n">name</span><span class="p">()</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">synset</span><span class="o">.</span><span class="n">lemmas</span><span class="p">()])))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># ä¸Šä½è¯</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">wordnet</span> <span class="k">as</span> <span class="n">wn</span>
</span></span><span class="line"><span class="cl"><span class="n">panda</span> <span class="o">=</span> <span class="n">wn</span><span class="o">.</span><span class="n">synset</span><span class="p">(</span><span class="s2">&#34;panda.n.01&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">hyper</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">s</span><span class="o">.</span><span class="n">hypernyms</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">list</span><span class="p">(</span><span class="n">panda</span><span class="o">.</span><span class="n">closure</span><span class="p">(</span><span class="n">hyper</span><span class="p">))</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>è¯æ±‡çš„ç¦»æ•£è¡¨å¾ï¼šå°†æ¯ä¸ªè¯è¯­çœ‹ä½œå•ç‹¬ç¦»æ•£çš„ç¬¦å·ï¼Œå¹¶æŠŠå•è¯è¡¨å¾ä¸ºç‹¬çƒ­ç¼–ç ã€‚é—®é¢˜ï¼š1ï¼‰æ¯ä¸ªè¯å‘é‡ä¹‹é—´æ­£äº¤ä¸èƒ½å¾ˆå¥½çš„å»ºæ¨¡å•è¯ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚2ï¼‰å‘é‡ç»´åº¦å¤§ï¼Œæ¯å¢åŠ ä¸€ä¸ªå•è¯å°±å¢åŠ ä¸€ä¸ªç»´åº¦ã€‚è§£å†³æ–¹æ¡ˆï¼šé€šè¿‡å¤§é‡æ•°æ®å­¦ä¹ è¯å‘é‡æœ¬èº«ç›¸ä¼¼æ€§ï¼Œè·å¾—æ›´ç²¾ç¡®çš„ç¨ å¯†è¯å‘é‡ç¼–ç </p>
</li>
<li>
<p>åŸºäºä¸Šä¸‹æ–‡è¯æ±‡è¡¨å¾ã€‚æ ¸å¿ƒæ€æƒ³ï¼šä¸€ä¸ªå•è¯çš„æ„æ€æ˜¯ç”±ç»å¸¸å‡ºç°åœ¨å®ƒé™„è¿‘çš„å•è¯ç»™å‡ºçš„ã€‚æ–¹æ³•ï¼šå½“ä¸€ä¸ªå•è¯wå‡ºç°åœ¨æ–‡æœ¬ä¸­æ—¶ï¼Œå®ƒçš„ä¸Šä¸‹æ–‡æ˜¯å‡ºç°åœ¨å…¶é™„è¿‘çš„ä¸€ç»„å•è¯ï¼ˆåœ¨ä¸€ä¸ªå›ºå®šå¤§å°çš„çª—å£ä¸­ï¼‰ã€‚åŸºäºæµ·é‡æ•°æ®ï¼Œä½¿ç”¨wçš„è®¸å¤šä¸Šä¸‹æ–‡æ¥æ„å»ºwçš„è¡¨ç¤º</p>
</li>
</ul>
<p>Word2vec</p>
<p>ä»¥ä¸‹ä»¥Skip-gramä¸ºä¾‹</p>
<ul>
<li>
<p>æ ¸å¿ƒæ€è·¯</p>
<ul>
<li>åŸºäºæµ·é‡æ–‡æœ¬è¯­æ–™åº“æ„å»º</li>
<li>è¯æ±‡è¡¨ä¸­çš„æ¯ä¸ªå•è¯éƒ½ç”±ä¸€ä¸ªå‘é‡è¡¨ç¤ºï¼ˆå­¦ä¹ å®Œæˆåä¼šå›ºå®šï¼‰</li>
<li>å¯¹åº”è¯­æ–™åº“æ–‡æœ¬ä¸­çš„æ¯ä¸ªä½ç½® <img src="https://www.zhihu.com/equation?tex=t"
	
	
	
	loading="lazy"
	
		alt="å…¬å¼"
	
	
>ï¼Œæœ‰ä¸€ä¸ªä¸­å¿ƒè¯ <img src="https://www.zhihu.com/equation?tex=c"
	
	
	
	loading="lazy"
	
		alt="å…¬å¼"
	
	
> å’Œä¸€äº›ä¸Šä¸‹æ–‡(â€œå¤–éƒ¨â€)å•è¯ <img src="https://www.zhihu.com/equation?tex=o"
	
	
	
	loading="lazy"
	
		alt="å…¬å¼"
	
	
></li>
<li>åœ¨å›ºå®šçª—å£å†…é¢„æµ‹ä¸Šä¸‹æ–‡å•è¯ï¼Œä½¿ç”¨ <img src="https://www.zhihu.com/equation?tex=c"
	
	
	
	loading="lazy"
	
		alt="å…¬å¼"
	
	
> å’Œ <img src="https://www.zhihu.com/equation?tex=o"
	
	
	
	loading="lazy"
	
		alt="å…¬å¼"
	
	
> çš„è¯å‘é‡æ¥è®¡ç®—æ¦‚ç‡ <img src="https://www.zhihu.com/equation?tex=P%28o%7Cc%29"
	
	
	
	loading="lazy"
	
		alt="å…¬å¼"
	
	
>ï¼Œå³ç»™å®šä¸­å¿ƒè¯æ¨æ–­ä¸Šä¸‹æ–‡è¯æ±‡çš„æ¦‚ç‡ï¼ˆåä¹‹äº¦ç„¶)</li>
<li>æ¨¡å‹ä¼šéå†æ•´ä¸ªè¯­æ–™åº“ä¸­çš„æ¯ä¸ªå•è¯ï¼Œä½¿ç”¨ä¸­å¿ƒå•è¯å‘é‡é¢„æµ‹å‘¨å›´çš„å•è¯ï¼ˆSkip-Gramï¼‰ï¼Œä¸æ–­è°ƒæ•´è¯å‘é‡ï¼ˆæ›´æ–°å‘é‡å‚æ•°ï¼‰æ¥æœ€å¤§åŒ–è¿™ä¸ªæ¦‚ç‡ï¼ˆé¢„æµ‹ä¸Šä¸‹æ–‡ï¼‰</li>
</ul>
</li>
<li>
<p>ä¼¼ç„¶å‡½æ•°ä¸ç›®æ ‡å‡½æ•°
$$
å¯¹äºæ¯ä¸ªä½ç½®t=1,&hellip;T,åœ¨å¤§å°ä¸ºmçš„å›ºå®šçª—å£å†…é¢„æµ‹ä¸Šä¸‹æ–‡å•è¯,\thetaä¸ºæ¨¡å‹åŒ…å«çš„æ‰€æœ‰å¾…ä¼˜åŒ–æƒé‡å˜é‡,ç»™å®šä¸­å¿ƒè¯w_j,ä¼¼ç„¶å‡½æ•°ä¸º:\
\text{Likelihood} = L(\theta) = \prod_{t=1}^{T} \prod_{\substack{j \neq 0 \ -m \leq j \leq m}} P(w_{t+j} \mid w_t ; \theta)\
å¯¹åº”ä¸Šè¿°ä¼¼ç„¶å‡½æ•°çš„ç›®æ ‡å‡½æ•°J(Î¸)å¯ä»¥å–ä½œ(å¹³å‡)è´Ÿå¯¹æ•°ä¼¼ç„¶:\
J(\theta) = -\frac{1}{T} \log L(\theta) = -\frac{1}{T} \sum_{t=1}^{T} \sum_{\substack{j \neq 0 \ -m \leq j \leq m}} \log P(w_{t+j} \mid w_t ; \theta)
$$</p>
</li>
<li>
<p>å¦‚ä½•è®¡ç®—æ¦‚ç‡å€¼ï¼šU VçŸ©é˜µæ¯è¡Œä»£è¡¨ä¸€ä¸ªå•è¯çš„è¯å‘é‡ï¼Œç‚¹ä¹˜åå¾—åˆ°çš„åˆ†æ•°é€šè¿‡softmaxæ˜ å°„ä¸ºæ¦‚ç‡åˆ†å¸ƒã€‚å¾—åˆ°çš„æ¦‚ç‡åˆ†å¸ƒæ˜¯å¯¹äºè¯¥ä¸­å¿ƒè¯è€Œè¨€çš„ä¸Šä¸‹æ–‡ä¸­å•è¯çš„æ¦‚ç‡åˆ†å¸ƒï¼Œè¯¥åˆ†å¸ƒä¸ä¸Šä¸‹æ–‡æ‰€åœ¨çš„å…·ä½“ä½ç½®æ— å…³ï¼Œæ‰€ä»¥åœ¨æ¯ä¸ªä½ç½®çš„é¢„æµ‹éƒ½æ˜¯ä¸€æ ·çš„ã€‚theã€andã€thatã€ofç­‰åœç”¨è¯ï¼Œæ˜¯æ¯ä¸ªå•è¯ç‚¹ä¹˜åå¾—åˆ°çš„è¾ƒå¤§æ¦‚ç‡çš„å•è¯ï¼Œå»æ‰è¿™ä¸€éƒ¨åˆ†å¯ä»¥ä½¿è¯å‘é‡æ•ˆæœæ›´å¥½ã€‚<img src="C:/Users/wcx/Desktop/%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%e5%a4%84%e7%90%86%e5%9f%ba%e7%a1%80/images/word2vec/%e5%8f%82%e6%95%b0%e8%ae%a1%e7%ae%97.png"
	
	
	
	loading="lazy"
	
	
>
$$
å¯¹äºæ¯ä¸ªè¯wéƒ½ä¼šç”¨ä¸¤ä¸ªå‘é‡:å½“wæ˜¯ä¸­å¿ƒè¯æ—¶ï¼Œæˆ‘ä»¬æ ‡è®°è¯å‘é‡ä¸ºv_w,å½“wæ˜¯ä¸Šä¸‹æ–‡è¯æ—¶ï¼Œæˆ‘ä»¬æ ‡è®°è¯å‘é‡ä¸ºu_w.\
P(o\mid c) = \frac{\exp(u_o^T v_c)}{\sum_{w \in V} \exp(u_w^T v_c)}\
å‘é‡u_oå’Œå‘é‡v_cè¿›è¡Œç‚¹ä¹˜.å‘é‡ä¹‹é—´è¶Šç›¸ä¼¼,ç‚¹ä¹˜ç»“æœè¶Šå¤§,ä»è€Œå½’ä¸€åŒ–åå¾—åˆ°çš„æ¦‚ç‡å€¼ä¹Ÿè¶Šå¤§\
æ¨¡å‹è®­ç»ƒä¸ºæœ€å¤§åŒ–å½“å‡ºç°ä¸­å¿ƒè¯cæ—¶ å…¶ä¸Šä¸‹æ–‡å•è¯ä¸ºoçš„æ¦‚ç‡\
æ¨¡å‹çš„è®­ç»ƒæ­£æ˜¯ä¸ºäº†ä½¿å¾—å…·æœ‰ç›¸ä¼¼ä¸Šä¸‹æ–‡çš„å•è¯,å…·æœ‰ç›¸ä¼¼çš„å‘é‡\
å–å¹‚ä½¿ä»»ä½•æ•°éƒ½ä¸ºæ­£ åˆ†æ¯å¯¹æ•´ä¸ªè¯æ±‡è¡¨è¿›è¡Œæ ‡å‡†åŒ–,ä»è€Œç»™å‡ºæ¦‚ç‡åˆ†å¸ƒ\
ä½¿ç”¨äº†softmaxå°†ä»»æ„x_iæ˜ å°„åˆ°æ¦‚ç‡åˆ†å¸ƒp_i  \text{softmax}(x_i) = \frac{\exp(x_i)}{\sum_{j=1}^{n} \exp(x_j)} = p_i\
softmaxçš„ç†è§£:maxå› ä¸ºæ”¾å¤§äº†æœ€å¤§çš„æ¦‚ç‡,softå› ä¸ºä»ç„¶ä¸ºè¾ƒå°çš„x_ièµ‹äºˆäº†ä¸€å®šæ¦‚ç‡
$$</p>
</li>
<li>
<p>word2vecä½¿ç”¨æ¢¯åº¦ä¸‹é™è®­ç»ƒæ­¥éª¤
$$
1.éšæœºåˆå§‹åŒ–u_w\in R^då’Œv_w\in R^d\
2.è®¡ç®—å‚æ•°æ¢¯åº¦\
\frac{\partial}{\partial v_c}\log P(o \mid c)
= \frac{\partial}{\partial v_c}\log\frac{ \exp(u_o^T v_c)}{\sum_{w \in V} \exp(u_w^T v_c)} \
= \frac{\partial}{\partial v_c}\left(\log \exp(u_o^T v_c) - \log \sum_{w \in V} \exp(u_w^T v_c)\right) \
= \frac{\partial}{\partial v_c}\left(u_o^T v_c - \log \sum_{w \in V} \exp(u_w^T v_c)\right) \
= u_o - \frac{\sum_{w \in V} \exp(u_w^T v_c) u_w}{\sum_{w \in V} \exp(u_w^T v_c)}\
= u_o - \sum_{w \in V} \frac{{\exp(u_w^T v_c)}}{{\sum_{w \in V} \exp(u_{w}^T v_c)}} u_w \
= u_o - \sum_{w \in V} P(w\mid c)u_w \
= u_o - \mathbb{E}[u_w]\
=observed - expected\
æ˜“å¾—\sum_{w \in V} P(w\mid c)=1, åˆ™å½“P(o\mid c)\rightarrow 1ä½¿\sum_{w \in V} P(w\mid c)u_w\rightarrow u_o,æ­¤æ—¶æˆ‘ä»¬ä¸éœ€è¦è°ƒæ•´v_cåä¹‹åˆ™ç›¸åº”è°ƒæ•´v_c \ \
\frac{\partial}{\partial u_o}\log P(o \mid c) = \frac{\partial}{\partial u_o}\log\frac{\exp(u_o^T v_c)}{\sum_{w \in V} \exp(u_w^T v_c)}\
= \frac{\partial}{\partial u_o}\left(\log \exp(u_o^T v_c) - \log \sum_{w \in V} \exp(u_w^T v_c)\right) \
= \frac{\partial}{\partial u_o}\left(u_o^T v_c - \log \sum_{w \in V} \exp(u_w^T v_c)\right)\
= v_c - \frac{\sum \frac{\partial}{\partial u_o} \exp(u_w^T v_c)}{\sum_{w \in V}\exp(u_w^T v_c)} v_c \
= v_c - \frac{\exp(u_o^T v_c)}{\sum_{w \in V}\exp(u_w^T v_c)} v_c\
= v_c - P(o \mid c) v_c\
= (1 - P(o \mid c)) v_c\
å½“P(o \mid c) \rightarrow 1 å³é€šè¿‡ä¸­å¿ƒè¯cæˆ‘ä»¬å¯ä»¥æ­£ç¡®é¢„æµ‹ä¸Šä¸‹æ–‡è¯o,æ­¤æ—¶æˆ‘ä»¬ä¸éœ€è¦è°ƒæ•´u_oåä¹‹åˆ™ç›¸åº”è°ƒæ•´u_o\\
å¯¹äºéä¸­å¿ƒè¯çš„æ¢¯åº¦å¦‚ä¸‹:\
\frac{\partial}{\partial u_w}\log P(o \mid c)=\frac{\partial}{\partial u_w}\left(\log \exp(u_o^T v_c) - \log \sum_{w \in V} \exp(u_w^T v_c)\right)=0-\frac{\exp(u_o^T v_c)}{\sum_{w \in V}\exp(u_w^T v_c)} v_c=- P(o \mid c) v_c</p>
<p>\
3.ä½¿ç”¨ä¼˜åŒ–ç®—æ³•æ›´æ–°å‚æ•°\
$$</p>
</li>
<li>
<p>è´Ÿé‡‡æ ·ç›®æ ‡å‡½æ•°</p>
</li>
</ul>
<p>â€‹	èƒŒæ™¯ï¼šsoftmaxä¸­ç”¨äºå½’ä¸€åŒ–çš„åˆ†æ¯çš„è®¡ç®—ä»£ä»·å¤ªé«˜</p>
<p>â€‹	æ€è·¯ï¼šä½¿ç”¨ä¸€ä¸ª true pair (ä¸­å¿ƒè¯åŠå…¶ä¸Šä¸‹æ–‡çª—å£ä¸­çš„è¯)ä¸å‡ ä¸ª noise pair (ä¸­å¿ƒè¯ä¸éšæœºè¯æ­é…) å½¢æˆçš„æ ·æœ¬ï¼Œè®­ç»ƒäºŒå…ƒé€»è¾‘å›å½’ã€‚</p>
<p>â€‹	ä¼˜ç‚¹ï¼š1ï¼‰è®­ç»ƒé€Ÿåº¦å¿«ã€‚2ï¼‰å‡å°å†…å­˜</p>
<p>â€‹	ç¼ºç‚¹ï¼š1ï¼‰å‚æ•°è®¾ç½®æ•æ„Ÿï¼šè´Ÿé‡‡æ ·ä¸­è´Ÿé‡‡æ ·çš„æ•°é‡ä»¥åŠè´Ÿä¾‹è¯çš„é€‰æ‹©éƒ½ä¼šå½±å“æ¨¡å‹çš„æ€§èƒ½ã€‚2ï¼‰å¯¹ä½é¢‘è¯æ•ˆæœå·®ï¼šè´Ÿé‡‡æ ·ä¼šç»™äºˆé«˜é¢‘è¯	æ›´å¤šçš„æƒé‡ï¼Œå› æ­¤å¯¹äºä½é¢‘è¯çš„è¡¨ç¤ºæ•ˆæœå¯èƒ½ä¼šæœ‰æ‰€ä¸‹é™ã€‚
$$
J_{\text{skip-gram}} = -\log \sigma(\mathbf{v}<em>{w_c}^\top \mathbf{v}</em>{w_t}) - \sum_{w_n \in D} \log \sigma(-\mathbf{v}<em>{w_n}^\top \mathbf{v}</em>{w_t})\</p>
<p>\sigma(x) æ˜¯é€»è¾‘å‡½æ•°ï¼Œä¹Ÿç§°ä¸ºsigmoidå‡½æ•°ï¼Œå®šä¹‰ä¸º\sigma(x) = \frac{1}{1 + e^{-x}}\
\mathbf{v}<em>{w_t}æ˜¯ç›®æ ‡è¯w_tçš„è¯å‘é‡è¡¨ç¤ºã€‚\
\mathbf{v}</em>{w_c}æ˜¯ä¸Šä¸‹æ–‡è¯w_cçš„è¯å‘é‡è¡¨ç¤ºã€‚\
\mathbf{v}<em>{w_n}æ˜¯è´Ÿä¾‹è¯w_nçš„è¯å‘é‡è¡¨ç¤ºã€‚\
Dæ˜¯è´Ÿä¾‹æ ·æœ¬é›†åˆï¼ŒåŒ…å«äº†ä»è¯æ±‡è¡¨ä¸­éšæœºé€‰æ‹©çš„ä¸€äº›è´Ÿä¾‹è¯ã€‚\
ç¬¬ä¸€é¡¹è¡¨ç¤ºäº†æ­£ä¾‹æ ·æœ¬çš„è´¡çŒ®ï¼Œå³ç›®æ ‡è¯w_tå’Œä¸Šä¸‹æ–‡è¯w_cçš„å†…ç§¯çš„sigmoidå‡½æ•°çš„è´Ÿå¯¹æ•°ã€‚\
ç¬¬äºŒé¡¹è¡¨ç¤ºäº†è´Ÿä¾‹æ ·æœ¬çš„è´¡çŒ®ï¼Œå³ç›®æ ‡è¯w_tå’Œè´Ÿä¾‹è¯w_nçš„å†…ç§¯çš„sigmoidå‡½æ•°çš„è´Ÿå¯¹æ•°ä¹‹å’Œã€‚\
è¿™ä¸ªç›®æ ‡å‡½æ•°çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–æ­£ä¾‹æ ·æœ¬çš„æ¦‚ç‡ï¼ŒåŒæ—¶æœ€å°åŒ–è´Ÿä¾‹æ ·æœ¬çš„æ¦‚ç‡\\
å¯¹äºskip-gram,ä¸€å¯¹åŒ¹é…çš„ä¸Šä¸‹è¯å’Œä¸­å¿ƒè¯æ˜¯åœ¨ä¸€ä¸ªwindowså†…è®¡ç®—.å¯¹äºä¸€ä¸ªçª—å£å†…çš„ç›®æ ‡å‡½æ•°å¦‚ä¸‹:\
J</em>{\text{skip-gram}}(\mathbf{v}<em>c, \mathbf{w}</em>{t-m}, \ldots, \mathbf{w}<em>{t+m}, U) = \sum</em>{-m \leq j \leq m, j \neq 0} J(\mathbf{v}<em>c, \mathbf{w}</em>{t+j}, U)\
å…¶ä¸­ä¸­å¿ƒè¯ä¸ºw_t,å…¶ä½™çª—å£å†…çš„è¯ä¸ºå…¶åŒ¹é…çš„ä¸Šä¸‹æ–‡è¯
$$</p>
<ul>
<li>
<p>ä¼˜åŒ–ç®—æ³•
$$
æ¢¯åº¦ä¸‹é™ç®—æ³•:\alpha\space is\space step\space size\space or\space learning\space rate   \
update\space eq\space in\space matrix\space notation:\theta_{\text{new}} = \theta_{\text{old}} - \alpha \nabla_{\theta} J(\theta)\
update\space eq\space for\space single\space param:\theta_{j_{\text{new}}} = \theta_{j_{\text{old}}} - \alpha \frac{\partial J(\theta)}{\partial \theta_{j_{\text{old}}}}
$$</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># J is object func;corpus is dataset;theta is params</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># è€ƒè™‘åˆ°æ¯ä¸€ä¸ªè¯è¯­éƒ½æ˜¯å‚æ•° æ•…éå†æ¯ä¸€ä¸ªè¯è¯­çš„å‚æ•° è®¡ç®—å…¶æ¢¯åº¦ å¹¶æ›´æ–°</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># æ›´æ–°å‚æ•°æ—¶ç”¨æ‰€æœ‰æ ·æœ¬è¿›è¡Œæ›´æ–°(è¯„ä¼°è¯­æ–™ä¸­æ¯ä¸€ä¸ªæ ·æœ¬çš„æ¢¯åº¦ å¹¶è¿™ä¸ªç”¨è¿™ä¸ªæ¢¯åº¦æ›´æ–°å…¨éƒ¨å‚æ•°)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># é—®é¢˜:è®¡ç®—éå¸¸è€—èµ„æºä¸”è®¡ç®—æ—¶é—´å¤ªé•¿</span>
</span></span><span class="line"><span class="cl">    <span class="n">theta_grad</span> <span class="o">=</span> <span class="n">eval_grad</span><span class="p">(</span><span class="n">J</span><span class="p">,</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">    <span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">theta_grad</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>$$
éšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•:æ¯æ¬¡epochéšæœºé€‰æ‹©å•ä¸ªæ ·æœ¬è®¡ç®—æ¢¯åº¦å¹¶ç”¨å…¶æ¥æ›´æ–°æ‰€æœ‰æ ·æœ¬å‚æ•°\spaceéšæœºæ¢¯åº¦æ˜¯å¯¹å®Œæ•´æ¢¯åº¦çš„æ— åä¼°è®¡\
ä½†åŸºäºå•ä¸ªæ ·æœ¬æ›´æ–°ä¼šè¡¨ç°ä¸ºå‚æ•°éœ‡è¡å¾ˆå‰å®³,æ”¶æ•›è¿‡ç¨‹å¹¶ä¸å¹³ç¨³.ä¸€èˆ¬è€ƒè™‘åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡æˆ–ä½¿ç”¨mini-batchæ¢¯åº¦ä¸‹é™\
batchä¸‹é™:æŒ‡æ¯æ¬¡å‚æ•°æ›´æ–°ä½¿ç”¨æ‰€æœ‰æ ·æœ¬,å³æ‰€æœ‰æ ·æœ¬éƒ½ä»£å…¥è®¡ç®—ä¸€é,ç„¶åå–å®ƒä»¬çš„æ¢¯åº¦å‡å€¼,æ¥å¯¹å‚æ•°è¿›è¡Œä¸€æ¬¡æ€§æ›´æ–°.batch_size=æ•°æ®é›†å¤§å°.ç›¸å½“äºä¸€æ¬¡epochæ›´æ–°ä¸€æ¬¡å‚æ•°,æ¢¯åº¦ä½¿ç”¨çš„æ˜¯è®¡ç®—æ‰€æœ‰æ¢¯åº¦çš„å‡å€¼\
Mini-batch:æ¯æ¬¡å‚æ•°æ›´æ–°ä½¿ç”¨ä¸€å°æ‰¹æ ·æœ¬,æ¯æ¬¡è®¡ç®—è¿™æ‰¹æ ·æœ¬çš„æ¢¯åº¦å‡å€¼æ›´æ–°.ç›¸å½“äºä¸€æ¬¡epochæ›´æ–°dataiter_sizeæ¬¡å‚æ•°
\mini_bacthå…·æœ‰ä»¥ä¸‹ä¼˜ç‚¹:é€šè¿‡batchå¹³å‡,å‡å°‘æ¢¯åº¦ä¼°è®¡çš„å™ªéŸ³;åœ¨GPUä¸Šå¹¶è¡ŒåŒ–è¿ç®—,åŠ å¿«è¿ç®—é€Ÿåº¦
$$</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># è®¡ç®—éšæœºé€‰å–æ ·æœ¬ä¸­å‚æ•°çš„æ¢¯åº¦ å¦‚æœwindow=1åˆ™ä¸ºSGD,window_size=m(æ•°æ®é›†å¤§å°)åˆ™ä¸ºbatchä¸‹é™ å¦åˆ™ä¸ºmini-batch</span>
</span></span><span class="line"><span class="cl">    <span class="n">window</span> <span class="o">=</span> <span class="n">sample_window</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">theta_grad</span> <span class="o">=</span> <span class="n">eval_grad</span><span class="p">(</span><span class="n">J</span><span class="p">,</span> <span class="n">window</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">    <span class="n">theta</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">-</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">theta_grad</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>word2vecè®­ç»ƒå¾—åˆ°çš„è¯å‘é‡åˆ†å¸ƒä½“ç°è¯­ä¹‰ç›¸ä¼¼åº¦<img src="C:/Users/wcx/Desktop/è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€/images/word2vec/è¯è¯­ç›¸ä¼¼å›¾.png" style="zoom: 80%;" /></p>
</li>
</ul>
<p>å…±ç°çŸ©é˜µ</p>
<ul>
<li>æ¦‚å¿µï¼šåŸºäºçª—å£æˆ–å…¨æ–‡æ¡£è¿›è¡Œé‡‡æ ·ï¼Œå¯¹æ¯ä¸ªä¸­å¿ƒè¯å‘¨å›´çš„å•è¯è¿›è¡Œè®¡æ•°ï¼Œæ„å»ºè®¡æ•°çŸ©é˜µã€‚</li>
<li>ä¼˜åŠ¿ï¼š1ï¼‰èƒ½å¾ˆå¥½çš„åˆ©ç”¨å…¨å±€ä¿¡æ¯</li>
<li>å…±ç°çŸ©é˜µçš„é—®é¢˜ï¼š1ï¼‰ä½¿ç”¨å…±ç°æ¬¡æ•°è¡¡é‡å•è¯çš„ç›¸ä¼¼æ€§ï¼Œä½†æ˜¯ä¼šéšç€è¯æ±‡é‡çš„å¢åŠ è€Œå¢å¤§çŸ©é˜µçš„å¤§å°ã€‚2ï¼‰éœ€è¦å¾ˆå¤šç©ºé—´æ¥å­˜å‚¨è¿™ä¸€é«˜ç»´çŸ©é˜µã€‚3ï¼‰åç»­çš„åˆ†ç±»æ¨¡å‹ä¹Ÿä¼šç”±äºçŸ©é˜µçš„ç¨€ç–æ€§è€Œå­˜åœ¨ç¨€ç–æ€§é—®é¢˜ï¼Œä½¿å¾—æ•ˆæœä¸ä½³ã€‚è§£å†³æ–¹æ¡ˆï¼šçŸ©é˜µé™ç»´ï¼ˆå¥‡å¼‚å€¼åˆ†è§£ï¼‰</li>
</ul>
<p>Glove</p>
<p>å¯å‚è€ƒ<a class="link" href="https://blog.csdn.net/u014665013/article/details/79642083?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522170782019616800192212606%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=170782019616800192212606&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-79642083-null-null.142%5ev99%5epc_search_result_base2&amp;utm_term=Glove&amp;spm=1018.2226.3001.4187"  target="_blank" rel="noopener"
    >blog1</a>å’Œ<a class="link" href="https://showmeai.tech/article-detail/232"  target="_blank" rel="noopener"
    >blog2</a></p>
<ul>
<li>ç›®æ ‡åŒä¸Šè¿°å·¥ä½œç±»ä¼¼ï¼Œéƒ½æ˜¯éœ€è¦å¾—åˆ°èƒ½å¾ˆå¥½è¡¨ç¤ºè¯­ä¹‰çš„è¯å‘é‡</li>
<li>æ€è·¯ï¼š</li>
</ul>
<p>Gloveã€skip-gramã€CBOWå¯¹æ¯”</p>
<ul>
<li>skip-gramã€CBOWæ˜¯åœ¨çª—å£å†…è¿›è¡Œï¼Œç¼ºä¹äº†æ•´ä½“çš„è¯å’Œè¯çš„å…³ç³»ï¼Œè´Ÿæ ·æœ¬é‡‡ç”¨sampleçš„æ–¹å¼ä¼šç¼ºå¤±è¯çš„å…³ç³»ä¿¡æ¯ã€‚</li>
<li>Global Vectorèåˆäº†çŸ©é˜µåˆ†è§£Latent Semantic Analysis (LSA)çš„å…¨å±€ç»Ÿè®¡ä¿¡æ¯å’Œlocal context windowä¼˜åŠ¿ã€‚èå…¥å…¨å±€çš„å…ˆéªŒç»Ÿè®¡ä¿¡æ¯ï¼Œå¯ä»¥åŠ å¿«æ¨¡å‹çš„è®­ç»ƒé€Ÿåº¦ï¼Œåˆå¯ä»¥æ§åˆ¶è¯çš„ç›¸å¯¹æƒé‡ã€‚</li>
<li>skip-gramã€CBOWæ¯æ¬¡éƒ½æ˜¯ç”¨ä¸€ä¸ªçª—å£ä¸­çš„ä¿¡æ¯æ›´æ–°å‡ºè¯å‘é‡ï¼Œä½†æ˜¯Gloveåˆ™æ˜¯ç”¨äº†å…¨å±€çš„ä¿¡æ¯ï¼ˆå…±ç°çŸ©é˜µï¼Œé€šè¿‡å…¨å±€ç»Ÿè®¡é¢‘æ•°ï¼Œå¯ä»¥è®¡ç®—å¾—åˆ°æ¦‚ç‡å€¼ï¼Œè¿™ä¸ªæ¦‚ç‡å€¼å¾ˆå¥½åœ°ä»£è¡¨äº†å…¨å±€æ€§ã€‚ä»è€Œä½¿å¾—è¯å‘é‡å»æ‹Ÿåˆï¼‰ï¼Œä¹Ÿå°±æ˜¯å¤šä¸ªçª—å£è¿›è¡Œæ›´æ–°</li>
</ul>
<h2 id="classifier">Classifier
</h2><h2 id="backpropagation">BackPropagation
</h2><p>éçº¿æ€§å‡½æ•°ï¼Œè¯¦ç»†å‚è€ƒ<a class="link" href="https://cs231n.github.io/neural-networks-1/"  target="_blank" rel="noopener"
    >åšå®¢</a></p>
<ul>
<li>
<p>logistic (â€œsigmoidâ€) ï¼Œå°†xæ˜ å°„åˆ°0~1èŒƒå›´ã€‚</p>
<p>ç¼ºç‚¹ï¼š</p>
<p>ï¼ˆ1ï¼‰sigmoidçš„æ¢¯åº¦æ¶ˆå¤±ï¼Œå‚è€ƒ<a class="link" href="https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b"  target="_blank" rel="noopener"
    >åšå®¢</a>ï¼šä½ çš„æƒé‡çŸ©é˜µ<strong>W</strong>åˆå§‹åŒ–å¾—å¤ªå¤§ï¼ŒçŸ©é˜µä¹˜æ³•çš„è¾“å‡ºå¯èƒ½æœ‰ä¸€ä¸ªéå¸¸å¤§çš„èŒƒå›´ï¼ˆä¾‹å¦‚-400åˆ°400ä¹‹é—´çš„æ•°å­—ï¼‰ï¼Œè¿™å°†ä½¿å‘é‡<strong>z</strong>ä¸­çš„æ‰€æœ‰è¾“å‡ºå‡ ä¹éƒ½æ˜¯äºŒè¿›åˆ¶çš„ï¼šè¦ä¹ˆ1è¦ä¹ˆ0ã€‚ä½¿å¾—ä¸Šæ¸¸æ¢¯åº¦ä¸º0ã€‚ä»æ­¤æ—¶èµ·ï¼Œå‘åä¼ é€’çš„å…¶ä½™éƒ¨åˆ†å°†å…¨éƒ¨ä¸ºé›¶ã€‚ï¼ˆ2ï¼‰å…³äº sigmoid çš„å¦ä¸€ä¸ªä¸æ˜æ˜¾çš„æœ‰è¶£äº‹å®æ˜¯ï¼Œå½“ f = 0.5 æ—¶ï¼Œå…¶å±€éƒ¨æ¢¯åº¦ (f*(1-f)) åœ¨ 0.25 å¤„è¾¾åˆ°æœ€å¤§å€¼ã€‚è¿™æ„å‘³ç€æ¯æ¬¡æ¢¯åº¦ä¿¡å·æµè¿‡ sigmoid é—¨æ—¶ï¼Œå…¶å¹…åº¦æ€»æ˜¯ä¼šå‡å°å››åˆ†ä¹‹ä¸€ï¼ˆæˆ–æ›´å¤šï¼‰ã€‚å¦‚æœä½¿ç”¨åŸºæœ¬ SGDï¼Œè¿™å°†ä½¿ç½‘ç»œçš„è¾ƒä½å±‚è®­ç»ƒé€Ÿåº¦æ¯”è¾ƒé«˜å±‚æ…¢å¾—å¤šã€‚ï¼ˆ3ï¼‰sigmoid è¾“å‡ºä¸æ˜¯ä»¥é›¶ä¸ºä¸­å¿ƒçš„ï¼Œå‚è€ƒ<a class="link" href="https://cs231n.github.io/neural-networks-1/"  target="_blank" rel="noopener"
    >åšå®¢</a>
$$
\sigma(x) = \frac{1}{1 + e^{-x}}\
å¯¹äºh=f(z),f<del>is</del>sigmoid~func\
\frac{\partial h}{\partial z}=\frac{e^{-z}}{(1+e^{-z})^2}=f(z)\cdot (1-f(z))<del>upstream</del>grad
$$</p>
</li>
<li>
<p>tanhï¼Œå°†xæ˜ å°„åˆ°-1~1èŒƒå›´ï¼›tanh åªæ˜¯ä¸€ä¸ªé‡æ–°è°ƒæ•´å’Œç§»ä½çš„ sigmoid å‡½æ•°ã€‚
$$
\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}=2logistics(2\cdot x)-1
$$</p>
</li>
<li>
<p>Hardtanh
$$
\text{hardtanh}(x) = \begin{cases}
-1 &amp; \text{if } x &lt; -1 \
x &amp; \text{if } -1 \leq x \leq 1 \
1 &amp; \text{if } x &gt; 1
\end{cases}
$$</p>
</li>
<li>
<p>ReLuï¼šå¯¹äºæ·±åº¦ç¥ç»ç½‘ç»œï¼Œç°åœ¨é¦–å…ˆè¦å°è¯•çš„æ˜¯ReLUï¼šç”±äºè‰¯å¥½çš„æ¢¯åº¦åå‘ä¼ æ’­ï¼ˆReLU å¯ä»¥é€šè¿‡ç®€å•åœ°å°†æ¿€æ´»çŸ©é˜µé˜ˆå€¼è®¾ç½®ä¸ºé›¶ï¼Œtanhå’Œsigmoidè®¡ç®—è¾ƒä¸ºæ˜‚è´µï¼‰ï¼Œå®ƒè®­ç»ƒé€Ÿåº¦å¿«ï¼ˆçº¿æ€§ï¼‰ä¸”è¡¨ç°è‰¯å¥½ï¼›ä½†æ˜¯å…·æœ‰dead zoneï¼ˆè¾“å…¥å°äºç­‰äº0æ—¶ æ¢¯åº¦æ’ç­‰äº0ï¼Œå¯¼è‡´ç›¸å…³ç¥ç»å…ƒä¸ä¼šæ›´æ–°ï¼‰ï¼Œè§£å†³åŠæ³•ï¼šLeaky ReLu
$$
ReLu(x)=max(x,0)\
LeakyReLu(x) = \begin{cases}
x, &amp; \text{if } x \geq 0 \
\alpha x, &amp; \text{otherwise}
\end{cases}
$$</p>
</li>
<li>
<p>Maxoutï¼šå®ƒç”±å¤šä¸ªçº¿æ€§å‡½æ•°ç»„æˆï¼Œç„¶ååœ¨æ¯ä¸ªä½ç½®ä¸Šé€‰æ‹©æœ€å¤§çš„çº¿æ€§å‡½æ•°çš„è¾“å‡ºä½œä¸ºè¯¥ä½ç½®çš„è¾“å‡ºã€‚ç¥ç»å…ƒäº«æœ‰ ReLU å•å…ƒçš„æ‰€æœ‰ä¼˜ç‚¹ï¼ˆçº¿æ€§æ“ä½œæœºåˆ¶ã€æ— é¥±å’Œï¼‰ï¼Œå¹¶ä¸”æ²¡æœ‰å…¶ç¼ºç‚¹ï¼ˆå‚æ­»çš„ ReLUï¼‰ã€‚ç„¶è€Œï¼Œä¸ ReLU ç¥ç»å…ƒä¸åŒçš„æ˜¯ï¼Œå®ƒä½¿æ¯ä¸ªç¥ç»å…ƒçš„å‚æ•°æ•°é‡åŠ å€ï¼Œä»è€Œå¯¼è‡´å‚æ•°æ€»æ•°å¾ˆé«˜ã€‚
$$
\text{maxout}(x) = \max(w_1^T x + b_1, w_2^T x + b_2, \ldots, w_k^T x + b_k)
$$</p>
</li>
<li>
<p>GELUï¼šGELU is frequently used with Transformers (BERT, RoBERTa, etc.)
$$
\text{GeLU}(x) = \frac{1}{2} \left(1 + \text{erf}\left(\frac{x}{\sqrt{2}}\right)\right)\
= x\cdot P(Xâ‰¤x), X\in N(0,1)\
â‰ˆ x\cdot logistic(1.702x)
$$</p>
</li>
</ul>
<p>ä¸ºä»€ä¹ˆéœ€è¦éçº¿æ€§å‡½æ•°ï¼Ÿ</p>
<ul>
<li>æ²¡æœ‰éçº¿æ€§å‡½æ•°ï¼Œæ·±åº¦ç¥ç»ç½‘ç»œæ— æ³•åšæ›´å¤šäº‹æƒ…ï¼Œåªèƒ½è¿›è¡Œçº¿æ€§å˜æ¢ï¼šé¢å¤–çš„å±‚æ¬¡å¯èƒ½ä¼šè¢«ç¼–è¯‘æˆå•ä¸€çš„çº¿æ€§å˜æ¢ï¼šW1W2 x = Wx</li>
<li>å¦‚æœæœ‰æ›´å¤šåŒ…å«éçº¿æ€§å‡½æ•°çš„å±‚æ¬¡ï¼Œå®ƒä»¬å°±å¯ä»¥é€¼è¿‘ä»»ä½•å¤æ‚çš„å‡½æ•°ï¼</li>
</ul>
<p>äº¤å‰ç†µæŸå¤±å‡½æ•°cross-entropy
$$
pæ˜¯çœŸå®æ¦‚ç‡åˆ†å¸ƒ:å‡è®¾ä¸€ä¸ªçœŸå®çš„æ¦‚ç‡åˆ†å¸ƒåœ¨æ­£ç¡®ç±»åˆ«å¤„ä¸º1ï¼Œåœ¨å…¶ä»–åœ°æ–¹ä¸º0,å³p = [0, â€¦, 0, 1, 0, â€¦, 0]\
qæ˜¯æ¨¡å‹è®¡ç®—çš„æ¦‚ç‡åˆ†å¸ƒ\
cæ˜¯ç±»åˆ«,éœ€è¦è®¡ç®—æ‰€æœ‰ç±»åˆ«.ç”±äºpæ˜¯ç‹¬çƒ­ç¼–ç ,åˆ™å‰©ä¸‹çš„çš„å”¯ä¸€é¡¹æ˜¯çœŸå®ç±»åˆ«yiçš„è´Ÿå¯¹æ•°æ¦‚ç‡:âˆ’ log(q_i)\
H(p, q)=-\sum_{c=1}^C p(c)\cdot log(q(c))\
æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æœ€å¤§åŒ–æ­£ç¡®ç±»åˆ«yçš„æ¦‚ç‡,æˆ–è€…ç­‰ä»·åœ°,æˆ‘ä»¬å¯ä»¥æœ€å°åŒ–è¯¥ç±»åˆ«çš„è´Ÿå¯¹æ•°æ¦‚ç‡
$$</p>
<p>Gradientï¼Œè¯¦ç»†å‚è€ƒ<a class="link" href="http://cs231n.stanford.edu/handouts/derivatives.pdf"  target="_blank" rel="noopener"
    >åšå®¢</a>å’Œ<a class="link" href="http://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes03-neuralnets.pdf"  target="_blank" rel="noopener"
    >æ¨å¯¼</a></p>
<ul>
<li>
<p>Given a function with 1 output and 1 inputï¼›Itâ€™s gradient (slope) is its derivative
$$
f(x)=x^3\
\frac {df}{dx}=3x^2
$$</p>
</li>
<li>
<p>Given a function with 1 output and n inputsï¼›Its gradient is a vector of partial derivatives with respect to each input
$$
f(x)=f(x_1,x_2,&hellip;,x_n)\
\frac {\partial f}{\partial x}=[\frac {\partial f}{\partial x_1},\frac {\partial f}{\partial x_2},&hellip;,\frac {\partial f}{\partial x_n}]
$$</p>
</li>
<li>
<p>Given a function with m outputs and n inputsï¼›Itâ€™s Jacobian is an m x n matrix of partial derivatives
$$
\bf f(x)=[f_1(x_1,x_2,&hellip;,x_n),f_2(x_1,x_2,&hellip;,x_n),..,f_m(x_1,x_2,&hellip;,x_n)]\
\frac {\partial f}{\partial x}=\begin{bmatrix}
\frac{\partial f_1}{\partial x_1} &amp; \frac{\partial f_1}{\partial x_2} &amp; \cdots &amp; \frac{\partial f_1}{\partial x_n} \
\frac{\partial f_2}{\partial x_1} &amp; \frac{\partial f_2}{\partial x_2} &amp; \cdots &amp; \frac{\partial f_2}{\partial x_n} \
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \
\frac{\partial f_m}{\partial x_1} &amp; \frac{\partial f_m}{\partial x_2} &amp; \cdots &amp; \frac{\partial f_m}{\partial x_n}
\end{bmatrix}\
$$</p>
</li>
<li>
<p>1 output, nm inputs: 1 by mn Jacobian? Instead, we leave pure math and use the shape convention: the shape of the gradient is the shape of the parameters
$$
s=Wx+b, where<del>s</del>is~scalar\
\frac {\partial s}{\partial W}=\begin{bmatrix}
\frac{\partial s}{\partial W_{11}} &amp; \frac{\partial s}{\partial W_{12}} &amp; \cdots &amp; \frac{\partial s}{\partial W_{1n}} \</p>
<p>\vdots &amp; \vdots &amp; \ddots &amp; \vdots \
\frac{\partial s}{\partial W_{m1}} &amp; \frac{\partial s}{\partial W_{m2}} &amp; \cdots &amp; \frac{\partial s}{\partial W_{mn}}
\end{bmatrix}
$$</p>
</li>
<li>
<p>m output, nm inputs
$$
f=Wx+b,W<del>and</del>b<del>is</del>params,x<del>is</del>input.\
f(x)=\begin{bmatrix}
w_{11} &amp; w_{12} &amp; \cdots &amp; w_{1n} \
w_{21} &amp; w_{22} &amp; \cdots &amp; w_{2n}\
w_{31} &amp; w_{32} &amp; \cdots &amp; w_{3n} \
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \
w_{m1} &amp; w_{m2} &amp; \cdots &amp; w_{mn}
\end{bmatrix}\cdot \begin{bmatrix} x_1\x_2\x_3\\vdots\x_n \end{bmatrix}+\begin{bmatrix} b_1\b_2\b_3\\vdots\b_m \end{bmatrix}=\begin{bmatrix} w_{11}\cdot x_1+w_{12}\cdot x_2+\cdots+w_{1n}\cdot x_n+b_1\w_{21}\cdot x_1+w_{22}\cdot x_2+\cdots+w_{2n}\cdot x_n+b_2\w_{31}\cdot x_1+w_{32}\cdot x_2+\cdots+w_{3n}\cdot x_n+b_3\\vdots\w_{m1}\cdot x_1+w_{m2}\cdot x_2+\cdots+w_{mn}\cdot x_n+b_m \end{bmatrix}\
æ•…f_1(x_1,x_2,\cdots,x_n)= w_{11}\cdot x_1+w_{12}\cdot x_2+\cdots+w_{1n}\cdot x_n+b_1\
f_2(x_1,x_2,\cdots,x_n)= w_{21}\cdot x_1+w_{22}\cdot x_2+\cdots+w_{2n}\cdot x_n+b_2\
\vdots\
æ•…\frac{\partial f}{\partial W}=\begin{bmatrix}
\frac{\partial f_1}{\partial w_{11}} &amp; \frac{\partial f_1}{\partial w_{12}} &amp; \cdots &amp; \frac{\partial f_1}{\partial w_{1n}} \
\frac{\partial f_2}{\partial w_{21}} &amp; \frac{\partial f_2}{\partial w_{22}} &amp; \cdots &amp; \frac{\partial f_2}{\partial w_{2n}} \
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \
\frac{\partial f_m}{\partial w_{m1}} &amp; \frac{\partial f_m}{\partial w_{m2}} &amp; \cdots &amp; \frac{\partial f_m}{\partial w_{mn}}
\end{bmatrix}=\begin{bmatrix} x_1 &amp; x_2 &amp;\cdots  &amp;x_n \ x_1 &amp; x_2 &amp;\cdots  &amp;x_n\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots\x_1 &amp; x_2 &amp;\cdots  &amp;x_n \end{bmatrix}
$$
ä»£ç éªŒè¯</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># input</span>
</span></span><span class="line"><span class="cl"><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># params</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">y</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#########################</span>
</span></span><span class="line"><span class="cl"><span class="c1">#tensor([[1.],</span>
</span></span><span class="line"><span class="cl"><span class="c1">#        [2.],</span>
</span></span><span class="line"><span class="cl"><span class="c1">#        [3.]], grad_fn=&lt;ViewBackward0&gt;)</span>
</span></span><span class="line"><span class="cl"><span class="c1">#tensor([[0.4173, 0.2071, 0.1727],</span>
</span></span><span class="line"><span class="cl"><span class="c1">#        [0.7474, 0.9319, 0.6996]], requires_grad=True)</span>
</span></span><span class="line"><span class="cl"><span class="c1">#tensor([[1.3498],</span>
</span></span><span class="line"><span class="cl"><span class="c1">#        [4.7099]], grad_fn=&lt;MmBackward0&gt;)</span>
</span></span><span class="line"><span class="cl"><span class="c1">#tensor([[1., 2., 3.],</span>
</span></span><span class="line"><span class="cl"><span class="c1">#        [1., 2., 3.]])</span>
</span></span><span class="line"><span class="cl"><span class="c1">#########################</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Elementwise activation Functionâ€˜s Jacobian matrix; Function has n outputs and n inputs(vectors-to-vectors) â†’ n by n Jacobian
$$
\bf h=f(z)\
h_i=f(z_i),such<del>as</del>sigmoid\
z=[z_1,z_2,\cdots,z_n],h=[f(z_1),f(z_2),\cdots,f(z_n)]\
\frac {\partial h}{\partial z}åŒm<del>outputs</del>and<del>n</del>inputsæƒ…å†µä¸€è‡´\
\frac {\partial h}{\partial z}=\begin{bmatrix} f&rsquo;(z_1) &amp; 0 &amp;\cdots &amp; 0 \ 0 &amp; f&rsquo;(z_2) &amp;\cdots  &amp; 0\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots\0 &amp; 0 &amp;\cdots  &amp;f&rsquo;(z_n) \end{bmatrix}=diag(f&rsquo;(z))\
å¯¹äºæç«¯æƒ…å†µåå·®é¡¹bias(b \in R^n)ç±»ä¼¼,\frac {\partial (Wx+b)}{\partial b}=I(å•ä½çŸ©é˜µ)
$$</p>
</li>
<li>
<p>In a neural networkï¼Œæ¨å¯¼çš„exampleï¼Œå‚è€ƒ<a class="link" href="https://cs231n.github.io/optimization-2/"  target="_blank" rel="noopener"
    >åšå®¢</a>
$$
s=u^Th\
h=f(z)<del>elementwise</del>activate~func\
z=Wx+b\
\frac {\partial s}{\partial b}=\frac {\partial s}{\partial h}\cdot \frac {\partial h}{\partial z}\cdot \frac {\partial z}{\partial b}=u^T \cdot diag(f&rsquo;(z))\cdot \frac {\partial z}{\partial b} \
\frac {\partial s}{\partial W}=\frac {\partial s}{\partial h}\cdot \frac {\partial h}{\partial z}\cdot \frac {\partial z}{\partial W}=u^T \cdot diag(f&rsquo;(z))\cdot \frac {\partial z}{\partial W}\
å¯ä»¥é¿å…é‡å¤è®¡ç®—,è®°\delta=u^T \cdot diag(f&rsquo;(z)),æ˜¯ä¸Šæ¸¸æ¢¯åº¦(è¯¯å·®ä¿¡å·)
$$</p>
</li>
</ul>
<p>å¯¼æ•°çš„å½¢çŠ¶</p>
<ul>
<li>shape conventionï¼šå¯¼æ•°çš„å½¢çŠ¶åº”è¯¥ä¸å‚æ•°çš„å½¢çŠ¶ä¸€è‡´</li>
<li>å†²çªï¼šé›…å¯æ¯”çŸ©é˜µï¼ˆwhich makes the chain rule easyï¼‰å¯èƒ½ä¼šå’Œå½¢çŠ¶è§„çº¦ï¼ˆwhich makes implementing SGD easyï¼‰å†²çªã€‚</li>
</ul>
<p>è®¡ç®—å›¾</p>
<ul>
<li>+ â€œdistributesâ€ the upstream gradient to each summandï¼›max â€œroutesâ€ the upstream gradientï¼ˆæ›´å¤§çš„ä¼šè¢«æ›´æ–°ï¼Œæ›´å°çš„æ¢¯åº¦ä¸º0ä¸ä¼šæ›´æ–°ï¼‰ï¼›* â€œswitchesâ€ the upstream gradient</li>
<li>æ­£ç¡®è®¡ç®—æ–¹æ³•ï¼šå…ˆè®¡ç®—å‡ºæ‰€æœ‰local gradientï¼›ç„¶åæ ¹æ®é“¾å¼æ³•åˆ™é€’å½’è®¡ç®—</li>
<li>åå‘ä¼ æ’­æ—¶é—´å¤æ‚åº¦åˆ†æï¼š1ï¼‰å…ˆè®¡ç®—å‡ºæ‰€æœ‰èŠ‚ç‚¹çš„local gradientï¼ŒO(N)ã€‚2ï¼‰éå†æ‹“æ‰‘å›¾ï¼ˆå¹¿åº¦ä¼˜å…ˆæœç´¢ï¼ŒæŒ‰é˜Ÿåˆ—ï¼Œæ¯ä¸ªèŠ‚ç‚¹åªä¼šå…¥é˜Ÿä¸€æ¬¡å’Œå‡ºé˜Ÿä¸€æ¬¡ï¼‰ï¼Œæ—¶é—´å¤æ‚åº¦ä¹Ÿæ˜¯O(N)</li>
</ul>
<p>è®­ç»ƒå¸¸ç”¨æŠ€å·§å’Œæ³¨æ„äº‹é¡¹</p>
<p>a bit more about neural networkï¼ˆä½œä¸šéœ€è¦ï¼‰</p>
<ul>
<li>
<p>æ­£åˆ™åŒ–ï¼šèƒ½æœ‰æ•ˆé™åˆ¶è¿‡æ‹Ÿåˆ</p>
</li>
<li>
<p>dropoutï¼šä»¥æ¦‚ç‡péšæœºå°†è¾“å…¥å¼ é‡ï¼ˆä¸»è¦æ˜¯åœ¨ä¸­é—´çš„éšå˜é‡ä¸Šæ“ä½œï¼‰çš„ä¸€äº›å…ƒç´ å½’é›¶ã€‚å½“æ¨¡å‹æ›´å¤§æ—¶ï¼Œæœ¬è´¨ä¸Šæ­£åˆ™åŒ–ä¸èƒ½é™åˆ¶è¿‡æ‹Ÿåˆã€‚dropoutæ˜¯ä¸é”™é€‰æ‹©</p>
</li>
<li>
<p>åˆå§‹åŒ–</p>
</li>
<li>
<p>Optimizers</p>
</li>
</ul>
<h2 id="rnn">RNN
</h2><p>Language Modeling</p>
<ul>
<li>
<p>ä»€ä¹ˆæ˜¯è¯­è¨€å»ºæ¨¡ï¼ˆæœ¬è´¨ï¼‰ï¼š<strong>é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯æ˜¯ä»€ä¹ˆ</strong>ï¼ˆthe students opened their __<em>ï¼‰
$$
p(x</em>{t+1}|x_t,\dots,x_2,x_1)
$$</p>
</li>
<li>
<p>æ„å»ºè¯­è¨€æ¨¡å‹</p>
<ul>
<li>
<p>Markov(n-gram)æ¨¡å‹ï¼šMarkov assumption: x<sub>t+1</sub>depends only on the preceding n-1 words
$$
n-gram<del>model:p(x_{t+1}|x_t,\dots,x_2,x_1)=p(x_{t+1}|x_t,\dots,x_{t-n+2})\=\frac{p(x_{t+1},\cdots,x_{t-n+2})}{p(x_t,\cdots,x_{t-n+2})}â‰ˆ\frac {count(x_{t+1},\cdots,x_{t-n+2})}{count(x_t,\cdots,x_{t-n+2})}\
Example:P(books|students</del>opened<del>their) = \frac {count(students</del>opened<del>their</del>books)}{count(students<del>opened</del>their)}
$$
é—®é¢˜ï¼šï¼ˆ1ï¼‰ç¨€ç–æ€§ï¼š&ldquo;students opened their w&quot;å¦‚æœä»æ²¡æœ‰å‡ºç°è¿‡ï¼Œåˆ™åˆ†å­ä¸º0ï¼Œå¯ä»¥å…ˆæ·»åŠ å¾®å°çš„æ‰°åŠ¨é¿å…ã€‚&ldquo;students opened their&quot;å¦‚æœä»æ²¡æœ‰å‡ºç°è¿‡ï¼Œåˆ™åˆ†æ¯ä¸º0ï¼Œå¯ä»¥ä½¿ç”¨å€’é€€æ³•ï¼Œåˆ†æ¯æ›¿æ¢ä¸ºè®¡ç®—&quot;opened their&rdquo;ã€‚æ˜¾ç„¶nè¶Šå¤§ç¨€ç–æ€§è¶Šä¸¥é‡ï¼Œä¸€èˆ¬nä¸èƒ½å¤§äº5ï¼ˆ2ï¼‰å­˜å‚¨é—®é¢˜ï¼šéœ€è¦å­˜å‚¨è¯­æ–™ä¸­æ‰€æœ‰çš„n-gramsï¼Œå¦‚å­˜å‚¨æ‰€æœ‰çš„çŸ­è¯­&quot;students opened their books&quot;çš„æ¬¡æ•°ã€‚ï¼ˆ3ï¼‰æ²¡æœ‰è€ƒè™‘æ›´é•¿çš„ä¸Šä¸‹æ–‡æ¥é¢„æµ‹ä¸‹æ–‡ï¼Œç”Ÿæˆçš„æ–‡æœ¬é€šå¸¸æ²¡æœ‰æ„ä¹‰ã€‚</p>
</li>
<li>
<p>A fixed-window neural language modelï¼šé€šè¿‡æ„å»ºç¥ç»ç½‘ç»œï¼Œè¾“å…¥çª—å£å¤§å°çš„å•è¯ï¼ˆç»è¿‡çº¿æ€§å±‚ï¼Œæ¿€æ´»å±‚ï¼‰ï¼Œé¢„æµ‹ä¸‹ä¸ªå•è¯ã€‚ä¼˜ç‚¹ï¼šè§£å†³äº†ç¨€ç–æ€§å’Œå­˜å‚¨é—®é¢˜ã€‚ç¼ºç‚¹ï¼šï¼ˆ1ï¼‰çª—å£å¤§å°ä¾ç„¶å—é™åˆ¶ï¼Œæ²¡æœ‰è€ƒè™‘æ›´é•¿çš„ä¸Šä¸‹æ–‡ã€‚ï¼ˆ2ï¼‰å’Œword2vecä¸€æ ·ï¼Œ<strong>å®Œå…¨å¿½ç•¥äº†è¯åº</strong>ï¼ˆè¾“å…¥çš„å•è¯å³ä¾¿äº¤æ¢ä½ç½®ï¼Œç¼–ç ä¸å˜ï¼‰ï¼Œå¯¼è‡´å»ºæ¨¡æ•ˆæœä¸ä½³</p>
</li>
</ul>
</li>
</ul>
<p>ç°ä»£è¯­è¨€æ¨¡å‹</p>
<ul>
<li>
<p>RNN</p>
<ul>
<li>æ ¸å¿ƒæ€è·¯ï¼šé‡å¤ä½¿ç”¨ç›¸åŒçš„æƒé‡çŸ©é˜µ</li>
</ul>
<img src="C:/Users/wcx/Desktop/è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€/images/rnn/rnn.jpg" style="zoom:50%;" />
$$
output~distribution:\hat y_t=softmax(Uh_t+b_2)\\
hidden~states:h_t=sigmoid(W_hh_{t-1}+W_ee_t+b1),h_0~is~initial~hidden~state\\
word~embeddings:e_t=Ex_t\\
\bf h~and~e~is~vector~not~matrix
$$
<ul>
<li>
<p>ä¼˜åŠ¿ï¼šï¼ˆ1ï¼‰å¯ä»¥å¤„ç†ä»»æ„é•¿åº¦çš„è¾“å…¥ï¼ˆ2ï¼‰ç¬¬ t æ­¥çš„è®¡ç®—å¯ä»¥ï¼ˆç†è®ºä¸Šï¼‰ä½¿ç”¨æ¥è‡ªè®¸å¤šæ­¥éª¤ä¹‹å‰çš„ä¿¡æ¯ï¼ˆ3ï¼‰æ¨¡å‹å¤§å°ä¸ä¼šå› ä¸ºæ›´é•¿çš„è¾“å…¥è€Œå¢åŠ ï¼ˆ4ï¼‰æ¯ä¸ªæ—¶é—´æ­¥éƒ½åº”ç”¨ç›¸åŒçš„æƒé‡ï¼Œå› æ­¤åœ¨å¤„ç†è¾“å…¥æ—¶å­˜åœ¨å¯¹ç§°æ€§ã€‚ç¼ºç‚¹ï¼šï¼ˆ1ï¼‰é€’å½’è®¡ç®—é€Ÿåº¦è¾ƒæ…¢ï¼ˆ2ï¼‰åœ¨å®è·µä¸­ï¼Œéš¾ä»¥è·å–æ¥è‡ªè®¸å¤šæ­¥éª¤ä¹‹å‰çš„ä¿¡æ¯</p>
</li>
<li>
<p>è®­ç»ƒRNN
$$
ç›®æ ‡å‡½æ•°\
one<del>step:J^t(\theta)=CE(y_t,\hat y_t)=-log\hat y_{x_{t+1}}\
one</del>sentence:J=-\sum_{t=1}^Tlog\hat y_{x_{t+1}},T<del>is</del>sentence~length
$$
æ³¨æ„äº‹é¡¹ï¼šï¼ˆ1ï¼‰è®­ç»ƒæ—¶æ˜¯<strong>æ•™å¸ˆå¼ºè¿«</strong>ï¼Œå³æ¯æ¬¡è¾“å…¥éƒ½æ˜¯çœŸå€¼ã€‚æ¨ç†æ—¶æ˜¯<strong>å­¦ç”Ÿ</strong>ï¼Œå³æ¯æ¬¡è¾“å…¥æ˜¯ä¸Šä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡ºã€‚ï¼ˆ2ï¼‰ä¸ä¼šä½¿ç”¨æ•´æ®µæ–‡æ¡£è¾“å…¥ï¼Œå› ä¸ºå…¨éƒ¨è¯­æ–™è¿‡é•¿ï¼Œè®¡ç®—æ¢¯åº¦è¿‡äºæ˜‚è´µã€‚è€ƒè™‘å…ˆåˆ‡åˆ†æˆå¥å­ï¼ˆé‡‡æ ·å…·ä½“ç­–ç•¥å¯<a class="link" href="https://zh.d2l.ai/chapter_recurrent-neural-networks/language-models-and-dataset.html#id5"  target="_blank" rel="noopener"
    >å‚è€ƒ</a>ï¼Œéšæœºé‡‡æ ·å’Œé¡ºåºé‡‡æ ·ï¼‰ã€‚æ¯æ¬¡è®¡ç®—ä¸€æ‰¹ï¼ˆbatch/small chunk of dataï¼‰çš„æ¢¯åº¦å¹¶æ›´æ–°å‚æ•°ï¼ˆSGDï¼‰</p>
</li>
<li>
<p>RNNçš„æ¢¯åº¦ï¼šé€šè¿‡æ—¶é—´çš„åå‘ä¼ æ’­ï¼Œå³åœ¨æ—¶é—´æ­¥ä¸Šè¿›è¡Œåå‘ä¼ æ’­ã€‚è®¡ç®—é€Ÿåº¦ç¼“æ…¢åŒæ—¶å®¹æ˜“æ¢¯åº¦çˆ†ç‚¸ï¼Œå¯ä»¥è€ƒè™‘<strong>æ—¶é—´æˆªæ–­</strong>ï¼Œè¿™æ ·åšå¯¼è‡´è¯¥æ¨¡å‹ä¸»è¦ä¾§é‡äºçŸ­æœŸå½±å“ï¼Œè€Œä¸æ˜¯é•¿æœŸå½±å“ã€‚å…·ä½“å‚è€ƒ<a class="link" href="https://zh.d2l.ai/chapter_recurrent-neural-networks/bptt.html"  target="_blank" rel="noopener"
    >æ–‡ç« </a>
$$
\frac{\partial J^t}{\partial W_h}=\sum_{i=1}^t \frac{\partial J^t}{\partial W_h}
$$</p>
</li>
<li>
<p>è¯­è¨€æ¨¡å‹è¯„ä¼°æ ‡å‡†ï¼šå›°æƒ‘åº¦ã€‚è¶Šå°çš„å›°æƒ‘åº¦ï¼Œè¡¨ç¤ºæ¨¡å‹çš„é¢„æµ‹æ›´åŠ å‡†ç¡®å’Œè‡ªä¿¡ã€‚
$$
Perplexity=exp(-\frac{1}{n}\sum_{t=1}^n log<del>p(x_{t}|x_{t-1},\cdots,x_1) ),in</del>a~sentence
$$</p>
</li>
<li>
<p><strong>æ¢¯åº¦æ¶ˆå¤±/æ¢¯åº¦çˆ†ç‚¸</strong>ï¼šå½“è¿™äº›æ¢¯åº¦è¾ƒå°æ—¶ï¼Œæ¢¯åº¦ä¿¡å·éšç€è¿›ä¸€æ­¥åå‘ä¼ æ’­è€Œå˜å¾—è¶Šæ¥è¶Šå°ã€‚è¿œå¤„çš„æ¢¯åº¦ä¿¡å·ä¼šå› ä¸ºæ¯”èµ·è¿‘å¤„çš„æ¢¯åº¦ä¿¡å·è¦å°å¾—å¤šè€Œä¸¢å¤±ã€‚ å› æ­¤ï¼Œ<strong>æ¨¡å‹æƒé‡åªä¼šé’ˆå¯¹è¿‘å¤„çš„å½±å“è¿›è¡Œæ›´æ–°ï¼Œè€Œä¸æ˜¯é•¿æœŸå½±å“</strong>ã€‚æ¢¯åº¦çˆ†ç‚¸ä¹Ÿæ˜¯åŒç†ï¼Œå‚è€ƒ<a class="link" href="https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b"  target="_blank" rel="noopener"
    >åšå®¢</a>ã€‚åæœï¼šç½‘ç»œå‚æ•°ä¸­å¯èƒ½å‡ºç°INFï¼ˆæ•°å€¼æº¢å‡ºï¼‰æˆ–è€…NANï¼ˆè®¡ç®—ä¸­å‡ºç°é™¤ä»¥0æˆ–è€…é›¶ä¹˜ä»¥æ— ç©·å¤§ï¼‰è§£å†³æ–¹æ³•ï¼šï¼ˆ1ï¼‰æ¢¯åº¦è£å‰ªï¼šé™åˆ¶æ¢¯åº¦çš„å¤§å°ï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼ˆ2ï¼‰æ›´æ¢æ¿€æ´»å‡½æ•°sigmoidä¸ºtanhã€reluç­‰ï¼ˆ3ï¼‰ä½¿ç”¨æ›´å¥½çš„æœºåˆ¶ï¼šLSTMã€GRUã€å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶ã€æ®‹å·®è¿æ¥ï¼ˆResnetï¼Œç›¸å¯¹è¾ƒå¥½çš„è§£å†³åŠæ³•ï¼‰ç­‰ï¼ˆ4ï¼‰æ›´å¥½çš„åˆå§‹åŒ–ï¼Œå¦‚ï¼šxavierï¼ˆ5ï¼‰è°ƒæ•´å­¦ä¹ ç‡ç­‰
$$
\frac{\partial J^t}{\partial h_0}=\frac{\partial h_1}{\partial h_0}\cdot \frac{\partial h_2}{\partial h_1}\cdots \frac{\partial J^t}{\partial h_t}\
=\frac{\partial J^t}{\partial h_t}\cdot \prod [ diag(\sigma&rsquo;(W_h\cdot h_{t-1}+W_x\cdot x))\cdot W_h]\=\frac{\partial J^t}{\partial h_t}\cdot  W_h^t\cdot \prod diag(\sigma&rsquo;(W_h\cdot h_{t-1}+W_x\cdot x))\
å› ä¸º\sigma&rsquo;(z)=\sigma(z)\cdot (1-\sigma(z)),å½“zè¿‡å¤§æˆ–è¿‡å°éƒ½ä¼šä½¿å¾—è¶‹è¿‘äº0;åŒæ—¶W_hè¿‡å°æˆ–è€…è¿‡å¤§ä¼šæ¢¯åº¦æ¶ˆå¤±æˆ–è€…çˆ†ç‚¸
\
\
æ¢¯åº¦è£å‰ªä¸»è¦æ˜¯ä¸ºäº†é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
gradient<del>clip:\
if</del>||g||â‰¥threshold~then\
g\leftarrow \frac{threshold}{||g||}\cdot g
$$</p>
</li>
<li>
<p>RNNåº”ç”¨åœºæ™¯ï¼šæƒ…æ„Ÿåˆ†æã€æ–‡æœ¬ç”Ÿæˆã€æœºå™¨ç¿»è¯‘ç­‰</p>
</li>
</ul>
</li>
<li>
<p>LSTM</p>
<ul>
<li>
<p>æ ¸å¿ƒç»„ä»¶ï¼šhidden stateä¸cell stateï¼ˆBoth are vectors length nï¼›The cell stores long-term informationï¼›The LSTM can read, erase, and write information from the cellï¼‰ï¼›ç”±ä»¥ä¸‹ä¸‰ä¸ªé—¨æ§åˆ¶ï¼šé—å¿˜é—¨ï¼ˆæ“¦é™¤æ—§ä¿¡æ¯ï¼Œearseï¼‰ã€è¾“å…¥é—¨ï¼ˆæ·»åŠ æ–°çš„ä¿¡æ¯ï¼Œwriteï¼‰ã€è¾“å‡ºé—¨ï¼ˆå†³å®šè¾“å‡ºå“ªäº›ä¸œè¥¿ï¼Œreadï¼‰ï¼ŒThe gates are also vectors of length nï¼›<strong>The gates are dynamic</strong>: their value is computed based on the current context
$$
æ¯ä¸€ä¸ªé—¨éƒ½æ˜¯å‘é‡,ä½¿ç”¨\sigma å°†å€¼æ˜ å°„åˆ°0-1ä¹‹é—´,åç»­ä½¿ç”¨Hardmardç§¯å†³å®šå“ªäº›ä¿¡æ¯ä¿ç•™å“ªäº›ä¸¢å¼ƒ\
forget<del>gate:f^t=\sigma(W_f\cdot h^{t-1}+U_f\cdot x^t+b_f):æ§åˆ¶ä»old</del>cell<del>stateä¸­ä¿ç•™æˆ–é—å¿˜çš„å†…å®¹\
input</del>gate:i^t=\sigma(W_i\cdot h^{t-1}+U_i\cdot x^t+b_i):æ§åˆ¶new<del>cell</del>stateå†…å®¹çš„å“ªäº›éƒ¨åˆ†è¢«å†™å…¥ç»†èƒ\
output<del>gate:o^t=\sigma(W_o\cdot h^{t-1}+U_o\cdot x^t+b_o):æ§åˆ¶cell</del>stateçš„å“ªäº›éƒ¨åˆ†è¾“å‡ºåˆ°éšè—çŠ¶æ€\
new<del>cell</del>content:\widetilde c^t=tanh(W_c\cdot h^{t-1}+U_c\cdot x^t+b_c):å‡†å¤‡å†™å…¥çš„æ–°å†…å®¹\
cell<del>state:c^t=f^t \circ c^{t-1}+i^t\circ \widetilde c^t(\circ <del>is</del>Hardmard</del>product):æ“¦é™¤æ—§ä¿¡æ¯å’Œå†™å…¥æ–°ä¿¡æ¯\
hidden<del>state:h^t=o^t\circ tanh(c^t):ä»cell</del>stateè¯»å“ªäº›ä¿¡æ¯
$$
<img src="C:/Users/wcx/Desktop/è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€/images/rnn/lstm.jpg" style="zoom:50%;" /></p>
</li>
<li>
<p>lstmçš„æ¿€æ´»å‡½æ•°ä¸­ï¼Œ<strong>ä½¿ç”¨sigmoidå’Œtanhçš„åŸå› </strong>ï¼šï¼ˆ1ï¼‰é—¨æ§ä½¿ç”¨sigmoidä¸ºäº†æ˜ å°„è‡³0-1ä¹‹é—´ã€‚ï¼ˆ2ï¼‰tanhä¸»è¦ç”¨åœ¨è®¡ç®—éšå˜é‡å’Œæ–°å†…å®¹ã€‚ä¸ºäº†ç¼“è§£æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸ï¼Œé‡‡ç”¨(-1,1)ä¹‹é—´çš„tanhï¼Œèƒ½é¿å…sigmoidçš„é—®é¢˜ã€‚åŒæ—¶è¿™ä¸å¤§å¤šæ•°åœºæ™¯ä¸‹ç‰¹å¾åˆ†å¸ƒæ˜¯0ä¸­å¿ƒçš„å»åˆã€‚æ­¤å¤–ï¼Œtanhå‡½æ•°åœ¨è¾“å…¥ä¸º0è¿‘ç›¸æ¯” Sigmoidå‡½æ•°æœ‰æ›´å¤§çš„æ¢¯åº¦ï¼Œé€šå¸¸ä½¿æ¨¡å‹æ”¶æ•›æ›´å¿«ã€‚</p>
</li>
<li>
<p>lstmå¯ä»¥ä¿å­˜æ›´é•¿çš„æ—¶é—´æ­¥ä¿¡æ¯ï¼Œæ¯”å¦‚ï¼šå½“æŸä¸ªä½ç½®çš„é—å¿˜é—¨ä¸º1ï¼Œè¾“å…¥é—¨ä¸º0ï¼Œå°†ä¸€ç›´ä¿å­˜è¯¥ä½ç½®ä¿¡æ¯ã€‚</p>
</li>
<li>
<p>æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸ä¸ä»…ä»…æ˜¯RNNçš„é—®é¢˜ï¼ŒåŒ…æ‹¬å‰é¦ˆå’Œå·ç§¯ç¥ç»ç½‘ç»œï¼Œç‰¹åˆ«æ˜¯éå¸¸æ·±å±‚çš„ç½‘ç»œã€‚ç”±äºé“¾å¼æ³•åˆ™/éçº¿æ€§å‡½æ•°çš„é€‰æ‹©ï¼Œæ¢¯åº¦åœ¨åå‘ä¼ æ’­æ—¶å¯èƒ½ä¼šå˜å¾—éå¸¸å°ã€‚å› æ­¤ï¼Œè¾ƒä½å±‚çš„å­¦ä¹ é€Ÿåº¦éå¸¸ç¼“æ…¢ï¼ˆå³ï¼Œå¾ˆéš¾è®­ç»ƒï¼‰ã€‚å¦ä¸€ä¸ªè§£å†³æ–¹æ¡ˆï¼šè®¸å¤šæ–°çš„æ·±åº¦å‰é¦ˆ/å·ç§¯æ¶æ„æ·»åŠ äº†æ›´å¤šçš„ç›´æ¥è¿æ¥ï¼ˆä»è€Œå…è®¸æ¢¯åº¦æµåŠ¨ï¼‰ï¼Œå¦‚ResNetï¼ŒHighwayNetã€‚</p>
</li>
<li>
<p>ResNetè¦è§£å†³çš„æ˜¯æ·±åº¦ç¥ç»ç½‘ç»œçš„â€œé€€åŒ–â€é—®é¢˜ï¼Œ<strong>â€œé€€åŒ–â€æŒ‡çš„æ˜¯ï¼Œç»™ç½‘ç»œå åŠ æ›´å¤šçš„å±‚åï¼Œæ€§èƒ½å´å¿«é€Ÿä¸‹é™çš„æƒ…å†µ</strong>ï¼ˆåŒ…æ‹¬ä½†ä¸é™äºç”±äºå¾ˆæ·±å‡ºç°æ¢¯åº¦æ¶ˆå¤±ã€çˆ†ç‚¸ï¼‰ã€‚ResNetèƒ½ä¿è¯å½“åé¢çš„ç½‘ç»œå±‚æ²¡æœ‰å¸®åŠ©ç”šè‡³å€’é€€èƒ½è‡³å°‘ä¿è¯ä¹‹å‰çš„æ€§èƒ½ã€‚</p>
</li>
<li>
<p>LSTM<strong>ç¼“è§£</strong>æ¢¯åº¦æ¶ˆå¤±ï¼Œå…·ä½“å‚è€ƒ<a class="link" href="https://zhuanlan.zhihu.com/p/109519044"  target="_blank" rel="noopener"
    >ä¸“æ </a>ï¼šæ ¹æ®å…¬å¼ï¼Œf<sub>t</sub>æ ¹æ®éœ€è¦å¯ä»¥æ—¶è€Œå¤§æ—¶è€Œå°ï¼Œä»è€Œä¿è¯è¿ä¹˜æ—¶æ¯ä¸€é¡¹å¯ä»¥éšæ—¶æ”¹å˜ï¼Œ0<del>1ä¹‹é—´æˆ–è€…å¤§äºã€‚è€Œ**æ™®é€šRNNåœ¨è¿ä¹˜æ—¶ï¼Œæ¯ä¸€é¡¹ä¸€ç›´éƒ½æ˜¯åœ¨0</del>1ä¹‹é—´ï¼ˆæ¢¯åº¦æ¶ˆå¤±ï¼‰æˆ–è€…å¤§äº1ï¼ˆæ¢¯åº¦çˆ†ç‚¸ï¼‰**LSTMä¸­cellçŠ¶æ€çš„åŠ æ³•æ›´æ–°ç­–ç•¥ä½¿å¾—æ¢¯åº¦ä¼ é€’æ›´æ°å½“ï¼›é—¨æ§å•å…ƒå¯ä»¥å†³å®šé—å¿˜å¤šå°‘æ¢¯åº¦ï¼Œä»–ä»¬å¯ä»¥åœ¨ä¸åŒçš„æ—¶åˆ»å–ä¸åŒçš„å€¼ã€‚
$$
\frac{\partial c_t}{\partial c_{t-1}}=\frac{\partial c_t}{\partial f_t}\cdot \frac{\partial f_t}{\partial h_{t-1}}\cdot \frac{\partial h_{t-1}}{\partial c_{t-1}}+\frac{\partial c_t}{\partial i_t}\cdot \frac{\partial i_t}{\partial h_{t-1}}\cdot \frac{\partial h_{t-1}}{\partial c_{t-1}}+\frac{\partial c_t}{\partial \widetilde c_t}\cdot \frac{\partial \widetilde c_t}{\partial h_{t-1}}\cdot \frac{\partial h_{t-1}}{\partial c_{t-1}}+\frac{\partial c_t}{\partial c_{t-1}}\=c_{t-1} \sigma&rsquo;(\cdot)W_f\cdot o_{t-1}tanh(c_{t-1})+\widetilde c_t \sigma&rsquo;(\cdot)W_i\cdot o_{t-1}tanh(c_{t-1})+i_ttanh&rsquo;(\cdot)W_c\cdot o_{t-1}tanh(c_{t-1})+f_t
$$</p>
</li>
</ul>
</li>
<li>
<p>GRU</p>
</li>
<li>
<p>åŒå‘RNNï¼šåªé€‚ç”¨æœ‰æƒè®¿é—®æ•´ä¸ªåºåˆ—çš„æƒ…å†µã€‚ä¸é€‚ç”¨äºè¯­è¨€å»ºæ¨¡ï¼Œå› ä¸ºè¯­è¨€å»ºæ¨¡éœ€è¦é¢„æµ‹ä¸‹ä¸€ä¸ªè¯ã€‚ä½†æ¯”å•å‘RNNèƒ½æ›´å¥½åˆ©ç”¨ä¸Šä¸‹æ–‡</p>
</li>
<li>
<p>å¤šå±‚RNNï¼šæ¯ä¸€ä¸ªæ—¶é—´æ­¥ç”±å¤šå±‚éšå˜é‡å †å ï¼Œæˆ–è€…ä¸ºæœ‰å¤šä¸ªRNNè®¡ç®—ç‰¹å¾ã€‚è¾ƒä½çš„ RNNs åº”è¯¥è®¡ç®—è¾ƒä½çº§åˆ«çš„ç‰¹å¾ï¼Œè€Œè¾ƒé«˜çš„ RNNs åº”è¯¥è®¡ç®—è¾ƒé«˜çº§åˆ«çš„ç‰¹</p>
</li>
<li>
<p>seq2seq</p>
<ul>
<li>åº”ç”¨ï¼šNMTï¼ˆç¥ç»æœºå™¨ç¿»è¯‘ï¼‰ã€æ–‡æœ¬æ‘˜è¦ã€å¯¹è¯ç³»ç»Ÿ</li>
<li>æ¶æ„ï¼šencoderã€decoder</li>
<li>è§£ç æ–¹å¼ï¼šè´ªå©ªè§£ç ï¼ˆæ¯æ¬¡å–æ¦‚ç‡æœ€å¤§çš„ï¼Œåªæ˜¯æœ¬åœ°æœ€ä½³ä¸”æ— æ³•åé€€ï¼Œå¯èƒ½ä¸æ˜¯å…¨å±€æœ€ä½³ã€‚ç”Ÿæˆåœæ­¢<END>ç¬¦å·å°±åœæ­¢ç”Ÿæˆï¼‰ã€ç©·ä¸¾æœç´¢è§£ç ï¼ˆä¸ç°å®ï¼‰ã€æŸæœç´ ï¼ˆè·Ÿè¸ªkä¸ªåˆ†æ”¯ï¼Œç¬¬tæ­¥å°±ä¼šæœ‰t<sup>k-1</sup>è¢«è·Ÿè¸ªï¼Œæ˜¯ä¸€ä¸ªæŒ‡æ•°çº§çš„æ ‘ç»“æ„ã€‚å½“å…¶ä¸­ä¸€æ¡è·¯å¾„ç”Ÿæˆåœæ­¢ç¬¦å·æ—¶ï¼Œç»§ç»­æ¢ç´¢å…¶ä»–è·¯å¾„ï¼Œå®Œæˆçš„è·¯å¾„æ”¾åœ¨ä¸€è¾¹ã€‚é€‰æ‹©å¾—åˆ†æœ€å¥½çš„è·¯å¾„æ—¶ï¼Œéœ€é™¤ä»¥å•è¯æ•°ã€‚ä¸ç„¶æ ¹æ®å…¬å¼è¶Šé•¿çš„å¥å­å¾—åˆ†è¶Šä½ï¼‰</li>
<li>NMTçš„ä¼˜åŠ¿ä¸ç¼ºç‚¹</li>
<li>è¯„ä¼°æœºå™¨ç¿»è¯‘è´¨é‡ï¼šBLEUï¼ˆè®¡ç®—çœŸå€¼ä¸é¢„æµ‹å€¼çš„ç›¸ä¼¼åº¦ï¼‰</li>
</ul>
</li>
</ul>
<h2 id="attention">Attention
</h2><p>Seq2Seq+cross-attention</p>
<ul>
<li>
<p>èƒŒæ™¯ï¼šSeq2Seqæ¶æ„ä½¿ç”¨encoderå°†æºå¥å­ä¿¡æ¯å‹ç¼©æˆä¸€ä¸ªéšå˜é‡ï¼Œå†å°†éšå˜é‡é€å…¥åˆ°decoder</p>
</li>
<li>
<p>é—®é¢˜ï¼šï¼ˆ1ï¼‰ä»…ç”¨ä¸€ä¸ªéšå˜é‡åŒ…å«æºå¥å­çš„ä¿¡æ¯ï¼Œå­˜åœ¨ä¿¡æ¯ç“¶é¢ˆï¼ˆInformation bottleneckï¼Œfixï¼šå¯é€šè¿‡å¹³å‡æ¯ä¸€ä¸ªæ—¶é—´æ­¥çš„éšçŠ¶æ€æ¥æ¦‚æ‹¬æ•´ä¸ªå¥å­çš„ä¿¡æ¯ï¼‰ï¼ˆ2ï¼‰å­˜åœ¨è¿œè·ç¦»äº¤äº’é—®é¢˜ï¼šéš¾ä»¥å­¦ä¹ é•¿è·ç¦»ä¾èµ–å…³ç³»ï¼ˆå› ä¸ºæ¢¯åº¦é—®é¢˜ï¼å³ä¾¿æ˜¯LSTMä¹Ÿä¸èƒ½å®Œç¾è§£å†³ï¼‰ã€åªèƒ½ä»¥çº¿æ€§é¡ºåºåœ°è§‚å¯Ÿæºå¥ï¼ˆè™½ç„¶å¯ä»¥æ‰©å±•ä¸ºåŒå‘ï¼Œä½†æ˜¯ä¾æ—§ä¸å¤Ÿçµæ´»ï¼‰ï¼ˆ3ï¼‰ç¼ºä¹å¹¶è¡ŒåŒ–ï¼šæœªæ¥çš„RNNéšçŠ¶æ€æ— æ³•åœ¨ä¹‹å‰è¢«è®¡ç®—</p>
</li>
<li>
<p>Seq2Seq with Attentionï¼šæƒ³æ³•ï¼šè§£å†³å¹¶è¡ŒåŒ–ï¼ˆä¸å¯å¹¶è¡ŒåŒ–æ“ä½œçš„æ•°é‡ä¸éšåºåˆ—é•¿åº¦å¢åŠ è€Œå¢åŠ ï¼‰ã€ä¿¡æ¯ç“¶é¢ˆå’Œæœ€å¤§äº¤äº’è·ç¦»ï¼ˆæœ€å¤§äº¤äº’è·ç¦»ï¼šO(1)ï¼Œå› ä¸ºæ‰€æœ‰å•è¯åœ¨æ¯ä¸€å±‚éƒ½ä¼šç›¸äº’ä½œç”¨ï¼‰ï¼›æ ¸å¿ƒæ€æƒ³ï¼šåœ¨è§£ç å™¨çš„æ¯ä¸€æ­¥ä¸­ï¼Œåˆ©ç”¨ä¸ç¼–ç å™¨çš„ç›´æ¥è¿æ¥æ¥ä¸“æ³¨äºæºåºåˆ—çš„ç‰¹å®šéƒ¨åˆ†ã€‚<strong>æ³¨æ„åŠ›å°†æ¯ä¸ªå•è¯çš„è¡¨å¾è§†ä¸ºä¸€ä¸ªqueryï¼Œä»¥è®¿é—®å¹¶åˆå¹¶ä¸€ç»„valueçš„ä¿¡æ¯(ä»¥æƒé‡çš„æ–¹å¼åˆå¹¶ï¼Œéå¸¸çµæ´»)</strong>ã€‚å…·ä½“æ­¥éª¤ï¼š<strong>decoderçš„æ¯ä¸€æ—¶é—´æ­¥ä½œä¸ºqueryï¼Œencoderçš„æ¯ä¸€æ—¶é—´æ­¥éƒ½æœ‰ä¸€å¯¹è‡ªå·±çš„&lt;key,value&gt;ã€‚åªä¸è¿‡æ­¤æ—¶çš„q,k,vå‡ä¸ºå¯¹åº”çš„éšå˜é‡</strong>ã€‚queryä¼šä¸æ¯ä¸€ä¸ªkeyåšå†…ç§¯ï¼Œç„¶åé€šè¿‡softmaxå¾—åˆ°æ­¤queryåœ¨encoderæ¯ä¸€ä¸ªæ—¶é—´æ­¥çš„æƒé‡åˆ†æ•°ï¼ˆæ€»å’Œä¸º1ï¼‰ã€‚æœ€åï¼Œå¯¹æ¯ä¸ªvalueåšåŠ æƒå¹³å‡ï¼Œå…¬å¼å¦‚ä¸‹
$$
encoder<del>hidden</del>states:h_1,\cdots,h_N\in R^h\
On<del>timestep</del>t,<del>decoder</del>hidden<del>state:s_t\in R^h\
the</del>attention<del>scores</del>for<del>this</del>step:e_t=[s_t^Th_1,\cdots,s_t^Th_N]\
the<del>attention</del>distribution<del>for</del>this<del>step:\alpha_t=softmax(e_t)\
a</del>weighted<del>sum</del>of<del>the</del>encoder<del>hidden</del>states<del>to</del>get<del>the</del>attention<del>output:o_t=\sum_{i=1}^N \alpha_t^ih_i\
concatenate</del>the<del>attention</del>output<del>with</del>the<del>decoder</del>hidden<del>state</del>to<del>predict</del>next~token:\hat y=MLP([o_t;s_t])
$$
<img src="C:/Users/wcx/Desktop/è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€/images/rnn/attention.jpg" style="zoom:33%;" /></p>
</li>
</ul>
<img src="C:/Users/wcx/Desktop/è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€/images/rnn/rnn_att.jpg" style="zoom:33%;" />
<ul>
<li>
<p>ä¼˜åŠ¿ï¼šï¼ˆ1ï¼‰æé«˜äº†ç¥ç»æœºå™¨ç¿»è¯‘çš„æ€§èƒ½ï¼šå…è®¸è§£ç å™¨ä¸“æ³¨äºæºè¯­è¨€çš„æŸäº›éƒ¨åˆ†ï¼ˆ2ï¼‰æ³¨æ„åŠ›æä¾›äº†æ›´â€œäººç±»åŒ–â€çš„æœºå™¨ç¿»è¯‘è¿‡ç¨‹æ¨¡å‹ï¼šåœ¨ç¿»è¯‘æ—¶å¯ä»¥å›é¡¾æºè¯­å¥ï¼Œè€Œä¸å¿…è®°ä½å…¨éƒ¨å†…å®¹ï¼ˆ3ï¼‰ æ³¨æ„åŠ›è§£å†³äº†ç“¶é¢ˆé—®é¢˜ï¼šæ³¨æ„åŠ›ä½¿è§£ç å™¨èƒ½å¤Ÿç›´æ¥æŸ¥çœ‹æºè¯­è¨€; ç»•è¿‡ç“¶é¢ˆï¼ˆ4ï¼‰æ³¨æ„åŠ›æœ‰åŠ©äºè§£å†³æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼šæä¾›äº†åˆ°è¿œè·ç¦»çŠ¶æ€çš„æ·å¾„ï¼ˆ5ï¼‰æé«˜äº†å¯è§£é‡Šæ€§ï¼šé€šè¿‡æ£€æŸ¥æ³¨æ„åŠ›åˆ†æ•°çš„åˆ†å¸ƒï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°è§£ç å™¨æ­£åœ¨å…³æ³¨ä»€ä¹ˆã€‚æ‰“å°åˆ†å¸ƒå›¾ï¼Œå¯è§†åŒ–æ³¨æ„åŠ›åˆ†æ•°</p>
</li>
<li>
<p>æ³¨æ„åŠ›åˆ†æ•°(attention score)çš„å˜ç§ã€‚<strong>æ³¨æ„åŠ æ€§æ³¨æ„åŠ›å’Œç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›çš„åŒºåˆ«</strong>ã€‚
$$
Basic<del>dot</del>product<del>attention:e_i=s^Th_i,dim(s)==dim(h_i)\
Multiplicative</del>attention:e_i=s^TWh_i,dim(s)â‰ dim(h_i),W\in R^{dim(s)Ã—dim(h_i)}\
Reduced<del>rank</del>multiplicative<del>attention:e_i=s^T(U^TV)h_i,U\in R^{dim(s)Ã—k},V\in R^{kÃ—dim(h_i)},k&laquo;dim(s),dim(h_i)\
Additive</del>attention:e_i=v^Ttanh(W_1h_i+W_2s),v<del>is</del>a<del>weight</del>vector\bf(å¯ä»¥çœ‹ä½œå°†valueä¸­æœ‰ç”¨çš„ä¿¡æ¯ç­›é€‰å‡ºæ¥)
$$</p>
</li>
<li>
<p>æ ¸å¿ƒæ€æƒ³ï¼š<strong>ç»™å®šä¸€ç»„&lt;key,value&gt;å’Œqueryï¼Œæ³¨æ„åŠ›æœºåˆ¶æ˜¯é€šè¿‡æƒé‡åˆ†æ•°å¯¹valueè¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå¾—åˆ°valueä¸­åŒ…å«çš„ä¿¡æ¯çš„é€‰æ‹©æ€§æ‘˜è¦ï¼Œå…¶ä¸­æŸ¥è¯¢ç¡®å®šè¦å…³æ³¨å“ªäº›å€¼</strong></p>
</li>
</ul>
<p>self-attention/Transformer</p>
<p>å‚è€ƒèµ„æºï¼šhttps://jalammar.github.io/illustrated-transformer/</p>
<ul>
<li>
<p>èƒŒæ™¯ï¼šæ˜¯å¦<strong>encoderéƒ¨åˆ†ä¹Ÿèƒ½å»é™¤RNN</strong>ï¼Œç›´æ¥å…¨éƒ¨æ›¿æ¢ä¸ºæ³¨æ„åŠ›ã€‚ï¼ˆ1ï¼‰å¯¹æºå¥é€æ­¥å»ºæ¨¡ï¼Œä¸ç¬¦åˆäººå·¥ç¿»è¯‘çš„æ­¥éª¤ï¼Œåº”è¯¥å¯éšæ—¶æŸ¥çœ‹ä¸”èƒ½åŒå‘æŸ¥çœ‹ï¼ˆ2ï¼‰é€æ­¥å»ºæ¨¡æºå¥ï¼Œä¸èƒ½å¾ˆå¥½çš„åˆ©ç”¨GPUå¹¶è¡Œ</p>
</li>
<li>
<p>attention in encoder</p>
<ul>
<li>
<p>å…·ä½“å†…å®¹ï¼šè¾“å…¥çš„æ¯ä¸€ä¸ªå¥å­çš„æ¯ä¸€ä¸ªtokenï¼ˆç»è¿‡Embeddingåçš„è¯åµŒå…¥ï¼‰ï¼Œéƒ½ä¼šåŒæ—¶è¢«Qï¼ŒKï¼ŒVæƒé‡çŸ©é˜µåˆ†åˆ«ç¼–ç ä¸º&lt;query,key,value&gt;ã€‚åç»­æ“ä½œåŒä¸Šï¼Œå…¬å¼å¦‚ä¸‹
$$
w_{1:n}<del>is</del>a<del>sequence</del>of<del>words</del>in<del>vocabulary</del>V\
x_i=Ew_i,x_i<del>is</del>word<del>embedding\
q_i=Qx_i,k_i=Kx_i,v_i=Vx_i\
e_{ij}=q_i^T\cdot k_j(è®¡ç®—ç›¸ä¼¼æ€§),\alpha_{ij}=\frac{exp(e_{ij})}{\sum exp(e_{i*})}(score)\
weighted</del>sum<del>of</del>values:o_i=\sum_j \alpha_{ij}\cdot v_j
$$</p>
</li>
<li>
<p>é—®é¢˜1ï¼šæ²¡æœ‰é¡ºåºçš„æ¦‚å¿µï¼Œå³åŒä¸€ä¸ªå•è¯åœ¨ä¸åŒä½ç½®ä¸Šç»“æœæ˜¯ä¸€æ ·çš„ï¼Œè¿™ä¸ç¬¦åˆè¯­ä¹‰ã€‚è§£å†³æ–¹æ¡ˆï¼šå¼•å…¥ä½ç½®å‘é‡ï¼ŒåŸºæœ¬å…¬å¼å¦‚ä¸‹
$$
position<del>vectors:p_i\in \mathbb{R}^d,i\in{1,2,\cdots,n}\
word</del>embedding:x_i\
positioned~embedding:\hat x_i=x_i+p_i\</p>
<p>å¯¹äºä½ç½®poså’Œç»´åº¦i,ä½ç½®ç¼–ç PE_{(pos, i)}å¯ä»¥ç”±ä»¥ä¸‹å…¬å¼è®¡ç®—\
PE_{(pos, i)} = \begin{cases}
\sin(pos / 10000^{2i/d_{\text{model}}}) &amp; \text{if } i \text{ is even} \
\cos(pos / 10000^{2i/d_{\text{model}}}) &amp; \text{if } i \text{ is odd}
\end{cases}
\
å…¶ä¸­posæ˜¯è¾“å…¥åºåˆ—ä¸­çš„ä½ç½®,ä»1å¼€å§‹è®¡æ•°
iæ˜¯ä½ç½®ç¼–ç å‘é‡ä¸­çš„ç»´åº¦
d_{\text{model}}æ˜¯Transformeræ¨¡å‹çš„è¾“å…¥å’Œè¾“å‡ºå‘é‡çš„ç»´åº¦ã€‚
\
åœ¨è¿™ä¸ªå…¬å¼ä¸­,10000^{2i/d_{\text{model}}}æ§åˆ¶ç€æ­£å¼¦å’Œä½™å¼¦å‡½æ•°çš„å‘¨æœŸã€‚
$$
ä½ç½®å‘é‡åˆ†ç±»ï¼šï¼ˆ1ï¼‰ä¸å¯å­¦ä¹ çš„ï¼Œå³æ ¹æ®æ•°å­¦å…¬å¼å†³å®šçš„ï¼Œå¦‚<strong>æ­£å¼¦ä½ç½®è¡¨ç¤º</strong>ï¼ˆä¼˜åŠ¿ï¼šå‘¨æœŸæ€§è¡¨æ˜â€œç»å¯¹ä½ç½®â€å¯èƒ½å¹¶ä¸é‚£ä¹ˆé‡è¦ï¼Œæ¯”å¦‚å½“iè¶³å¤Ÿå¤§æ—¶ã€å¯èƒ½å¯ä»¥å¯¹æ›´é•¿çš„åºåˆ—è¿›è¡Œå¤–æ¨ï¼Œå› ä¸ºå‘¨æœŸé‡æ–°å¼€å§‹ï¼‰ï¼ˆ2ï¼‰å¯å­¦ä¹ çš„ï¼Œå³æŠŠä½ç½®å‘é‡ä½œä¸ºå¯å­¦ä¹ çš„å‚æ•°ã€‚ä¼˜åŠ¿ï¼šæ›´åŠ çµæ´»ï¼Œè¿™ä¹Ÿæ˜¯ç›®å‰ç³»ç»Ÿç”¨çš„æœ€å¤šçš„ï¼ˆè¯¾å ‚æé—®ï¼šæ€ä¹ˆçŸ¥é“æ‰€å­¦çš„å°±æ˜¯ä½ç½®ä¿¡æ¯ã€‚å›ç­”ï¼šå…¶å®ä¹Ÿæ²¡æœ‰å…¶ä»–ä¿¡æ¯èƒ½ä»£è¡¨äº†ã€‚è¯å‘é‡ä¼šå› ä¸ºè¾“å…¥çš„å¥å­å˜åŒ–è€Œå˜åŒ–ï¼Œè€Œä½ç½®å‘é‡ä¸€ç›´ä¸å˜ï¼‰ã€‚ç¼ºç‚¹ï¼šæ— æ³•å¯¹è¶…å‡º1~nçš„å¥å­å¤–æ¨ã€‚</p>
</li>
<li>
<p>é—®é¢˜2ï¼šæ²¡æœ‰éçº¿æ€§ï¼Œä¸€åˆ‡éƒ½åªæ˜¯åŠ æƒå¹³å‡ã€‚è§£å†³æ–¹æ¡ˆï¼šæ¯ä¸€ä¸ªä½ç½®çš„è¾“å‡ºï¼ˆå³æ¯ä¸€ä¸ªtokençš„åŠ æƒå¹³å‡æ±‚å’Œçš„valueè¾“å‡ºï¼‰ï¼Œå¥—ä¸Šéçº¿æ€§å±‚å’Œå‰é¦ˆå±‚ï¼ˆFFN/MLPï¼‰ã€‚å®éªŒè¡¨æ˜ï¼š<strong>å¢å¤§å‰é¦ˆå­å±‚éšçŠ¶æ€çš„ç»´åº¦æœ‰åˆ©äºæå‡æœ€ç»ˆç¿»è¯‘ç»“æœçš„è´¨é‡ï¼Œå› æ­¤ï¼Œå‰é¦ˆå­å±‚éšçŠ¶æ€çš„ç»´åº¦ä¸€èˆ¬æ¯”è‡ªæ³¨æ„åŠ›å­å±‚è¦å¤§ã€‚FFNçš„å‚æ•°å æ•´ä¸ªTransformerçš„ä¸‰åˆ†ä¹‹äºŒï¼Œç ”ç©¶è¡¨æ˜FFNå±‚å­˜å‚¨äº†Transformerçš„çŸ¥è¯†</strong></p>
<p>$$
FFN(x) = Relu(xW_1 + b_1)W_2 + b_2
$$
<img src="C:/Users/wcx/Desktop/è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€/images/attention/FFN.jpg" style="zoom:33%;" /></p>
</li>
<li>
<p>é—®é¢˜3ï¼šéœ€è¦æœ‰è¯­è¨€å»ºæ¨¡çš„ç‰¹ç‚¹ï¼Œå³ä¸èƒ½çœ‹åˆ°æœªæ¥çš„å•è¯ï¼Œåªèƒ½çœ‹åˆ°è¿‡å»çš„å•è¯ã€‚è§£å†³æ–¹æ¡ˆï¼šmaskåœ¨ä¹‹åçš„å•è¯ï¼Œå³èµ‹å€¼ä¸ºè´Ÿæ— ç©·ï¼Œå¯ä½¿å¾—ç‚¹ç§¯åçš„æ³¨æ„åŠ›æƒé‡ä¸º0ï¼Œå®ç°äº†ä¸çœ‹æœªæ¥åŒæ—¶ä¹Ÿä¿è¯äº†å¹¶è¡ŒåŒ–ã€‚<strong>Maskçš„æœ¬è´¨æ˜¯æ§åˆ¶ä¿¡æ¯æµåŠ¨</strong></p>
</li>
<li>
<p>Stacked form of Attentionï¼šç›´æ¥è®¡ç®—å‡ºæ•´ä¸ªseqä¸­çš„æ³¨æ„åŠ›åŠ æƒå¹³å‡å€¼ï¼Œç‰¹ç‚¹ï¼šè‡ªæ³¨æ„åŠ›çš„æ³¨æ„åŠ›åˆ†æ•°ç»´åº¦ä¸ºnÃ—nï¼ˆå¯ä»¥ç†è§£ä¸ºæ¯ä¸€ä¸ªtokenå¯¹å…¶ä»–tokenåŒ…æ‹¬è‡ªå·±çš„æ³¨æ„åŠ›åˆ†æ•°ï¼‰ã€<strong>è¾“å‡ºçš„ç»´åº¦å’Œè¾“å…¥çš„ç»´åº¦ä¸€æ ·</strong>
$$
input<del>words</del>vectors:X=[x_1,x_2,\cdots,x_n]\in\mathbb{R}^{nÃ—d}\
Q,K,V\in\mathbb{R}^{dÃ—k};XQ,XK,XV\in\mathbb{R}^{nÃ—k}\
output = softmax(XQ\cdot(XK)^T)\cdot XV \in \mathbb{R}^{nÃ—d}\
$$
å›¾ç¤ºï¼Œå‚è€ƒ<a class="link" href="https://jalammar.github.io/illustrated-transformer/"  target="_blank" rel="noopener"
    >åšå®¢</a>ï¼Œå¦‚ä¸‹</p>
<p>ï¼ˆ1ï¼‰è®¡ç®—queryï¼Œkeyï¼Œvalueï¼›XçŸ©é˜µçš„æ¯ä¸€è¡Œä»£è¡¨ä¸€ä¸ªå•è¯ï¼Œç»´åº¦ä¸ºnÃ—dï¼Œè¿™é‡Œä»¥2ä¸ªå•è¯4ç»´ä¸ºä¾‹ã€‚è®ºæ–‡ä¸­è¯åµŒå…¥ç»´åº¦ä¸º64ï¼Œæƒé‡çŸ©é˜µç»´åº¦ä¸º64Ã—512</p>
<img src="C:/Users/wcx/Desktop/è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€/images/attention/qkv.jpg" style="zoom:33%;" />
<p>ï¼ˆ2ï¼‰è®¡ç®—åŠ æƒå¹³å‡å€¼</p>
<img src="C:/Users/wcx/Desktop/è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€/images/attention/score.jpg" style="zoom:33%;" />
</li>
<li>
<p>å¤šå¤´æ³¨æ„åŠ›ï¼šå¸Œæœ›ä»ä¸åŒè§’åº¦æ¥æŸ¥çœ‹å¥å­ï¼ˆç±»ä¼¼äºMOEï¼‰ã€‚å…·ä½“å†…å®¹ï¼šå°†dç»´åˆ’åˆ†ä¸ºhä¸ªå¤´ï¼Œç»´åº¦é™ä¸ºd/hï¼Œå¤´æ•°ä¸ºhã€‚è®¡ç®—hç»„ï¼ˆæ¯ä¸€ä¸ªå¤´å•ç‹¬è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°ï¼›æ€»çš„è®¡ç®—æ•ˆç‡å’Œå•å¤´ä¸€æ ·ï¼‰æœ€åå°†æ¯ç»„çš„valueè¿æ¥åœ¨ä¸€èµ·ï¼Œéœ€ä¹˜ä¸Šæƒé‡æ˜ å°„åˆ°æ‰èƒ½å’ŒFFNï¼ˆä¸è¾“å…¥æ—¶çš„tokenç»´åº¦ä¸€è‡´ï¼Œå•å¤´çš„ç»´åº¦åªæœ‰nÃ—d/kï¼‰åŒ¹é…ï¼Œæˆ–è€…è¯´<strong>ä¹˜ä¸Šæƒé‡çŸ©é˜µæ˜¯ä¸ºäº†å­¦ä¹ å¦‚ä½•æå–å¤šå¤´å€¼çš„ä¿¡æ¯</strong>ã€‚è¯¾å ‚æé—®ï¼šå‹ç¼©ç»´åº¦åå¯¹ç²¾åº¦æ²¡æœ‰å½±å“å—ï¼›å›ç­”ï¼šåœ¨å®é™…æ“ä½œä¸­æ²¡æœ‰å½±å“</p>
<img src="C:/Users/wcx/Desktop/è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€/images/attention/mutli-head.jpg" style="zoom:33%;" />
<p>ä»£ç éªŒè¯</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># ä»¥ä¸‹éªŒè¯XQ,XK,XVçš„ç»´åº¦</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 4å•è¯ 6ç»´åº¦ nÃ—d</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">6</span><span class="p">)</span> 
</span></span><span class="line"><span class="cl"><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.1725</span><span class="p">,</span> <span class="mf">0.3749</span><span class="p">,</span> <span class="mf">0.9455</span><span class="p">,</span> <span class="mf">0.0374</span><span class="p">,</span> <span class="mf">0.4991</span><span class="p">,</span> <span class="mf">0.7726</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span><span class="mf">0.4857</span><span class="p">,</span> <span class="mf">0.1395</span><span class="p">,</span> <span class="mf">0.1681</span><span class="p">,</span> <span class="mf">0.6111</span><span class="p">,</span> <span class="mf">0.2824</span><span class="p">,</span> <span class="mf">0.9753</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span><span class="mf">0.2526</span><span class="p">,</span> <span class="mf">0.5623</span><span class="p">,</span> <span class="mf">0.7512</span><span class="p">,</span> <span class="mf">0.8236</span><span class="p">,</span> <span class="mf">0.4917</span><span class="p">,</span> <span class="mf">0.4934</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span><span class="mf">0.0304</span><span class="p">,</span> <span class="mf">0.6789</span><span class="p">,</span> <span class="mf">0.4181</span><span class="p">,</span> <span class="mf">0.0152</span><span class="p">,</span> <span class="mf">0.1853</span><span class="p">,</span> <span class="mf">0.9303</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 4å•è¯ 2å¤´ ç»´åº¦é™ä½è‡³3ç»´åº¦ nÃ—kÃ—d/k</span>
</span></span><span class="line"><span class="cl"><span class="c1"># ç°åœ¨ç»´åº¦çš„å«ä¹‰æ˜¯æ¯ä¸ªå•è¯æœ‰ä¸¤ä¸ªå¤´ç»´åº¦æ˜¯3,æˆ‘ä»¬éœ€è¦æŠŠæ¯ä¸€ç»„è”åˆèµ·æ¥</span>
</span></span><span class="line"><span class="cl"><span class="n">z</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">tensor</span><span class="p">([[[</span><span class="mf">0.1725</span><span class="p">,</span> <span class="mf">0.3749</span><span class="p">,</span> <span class="mf">0.9455</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">         <span class="p">[</span><span class="mf">0.0374</span><span class="p">,</span> <span class="mf">0.4991</span><span class="p">,</span> <span class="mf">0.7726</span><span class="p">]],</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="p">[[</span><span class="mf">0.4857</span><span class="p">,</span> <span class="mf">0.1395</span><span class="p">,</span> <span class="mf">0.1681</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">         <span class="p">[</span><span class="mf">0.6111</span><span class="p">,</span> <span class="mf">0.2824</span><span class="p">,</span> <span class="mf">0.9753</span><span class="p">]],</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="p">[[</span><span class="mf">0.2526</span><span class="p">,</span> <span class="mf">0.5623</span><span class="p">,</span> <span class="mf">0.7512</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">         <span class="p">[</span><span class="mf">0.8236</span><span class="p">,</span> <span class="mf">0.4917</span><span class="p">,</span> <span class="mf">0.4934</span><span class="p">]],</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="p">[[</span><span class="mf">0.0304</span><span class="p">,</span> <span class="mf">0.6789</span><span class="p">,</span> <span class="mf">0.4181</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">         <span class="p">[</span><span class="mf">0.0152</span><span class="p">,</span> <span class="mf">0.1853</span><span class="p">,</span> <span class="mf">0.9303</span><span class="p">]]])</span>
</span></span><span class="line"><span class="cl"><span class="c1"># è”åˆèµ·æ¥ 2å¤´ æ¯å¤´ 4å•è¯ç»´åº¦é™ä½è‡³3ç»´åº¦ kÃ—nÃ—d/k ç±»ä¼¼äºå¸¦æœ‰çš„batchçš„ç»´åº¦</span>
</span></span><span class="line"><span class="cl"><span class="n">z</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">tensor</span><span class="p">([[[</span><span class="mf">0.1725</span><span class="p">,</span> <span class="mf">0.3749</span><span class="p">,</span> <span class="mf">0.9455</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">         <span class="p">[</span><span class="mf">0.4857</span><span class="p">,</span> <span class="mf">0.1395</span><span class="p">,</span> <span class="mf">0.1681</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">         <span class="p">[</span><span class="mf">0.2526</span><span class="p">,</span> <span class="mf">0.5623</span><span class="p">,</span> <span class="mf">0.7512</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">         <span class="p">[</span><span class="mf">0.0304</span><span class="p">,</span> <span class="mf">0.6789</span><span class="p">,</span> <span class="mf">0.4181</span><span class="p">]],</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="p">[[</span><span class="mf">0.0374</span><span class="p">,</span> <span class="mf">0.4991</span><span class="p">,</span> <span class="mf">0.7726</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">         <span class="p">[</span><span class="mf">0.6111</span><span class="p">,</span> <span class="mf">0.2824</span><span class="p">,</span> <span class="mf">0.9753</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">         <span class="p">[</span><span class="mf">0.8236</span><span class="p">,</span> <span class="mf">0.4917</span><span class="p">,</span> <span class="mf">0.4934</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">         <span class="p">[</span><span class="mf">0.0152</span><span class="p">,</span> <span class="mf">0.1853</span><span class="p">,</span> <span class="mf">0.9303</span><span class="p">]]])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># å’Œç›´æ¥è½¬æ¢ä¸º(2,4,3)ä¸ä¸€æ ·</span>
</span></span><span class="line"><span class="cl"><span class="n">tensor</span><span class="p">([[[</span><span class="mf">0.1725</span><span class="p">,</span> <span class="mf">0.3749</span><span class="p">,</span> <span class="mf">0.9455</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">         <span class="p">[</span><span class="mf">0.0374</span><span class="p">,</span> <span class="mf">0.4991</span><span class="p">,</span> <span class="mf">0.7726</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">         <span class="p">[</span><span class="mf">0.4857</span><span class="p">,</span> <span class="mf">0.1395</span><span class="p">,</span> <span class="mf">0.1681</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">         <span class="p">[</span><span class="mf">0.6111</span><span class="p">,</span> <span class="mf">0.2824</span><span class="p">,</span> <span class="mf">0.9753</span><span class="p">]],</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="p">[[</span><span class="mf">0.2526</span><span class="p">,</span> <span class="mf">0.5623</span><span class="p">,</span> <span class="mf">0.7512</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">         <span class="p">[</span><span class="mf">0.8236</span><span class="p">,</span> <span class="mf">0.4917</span><span class="p">,</span> <span class="mf">0.4934</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">         <span class="p">[</span><span class="mf">0.0304</span><span class="p">,</span> <span class="mf">0.6789</span><span class="p">,</span> <span class="mf">0.4181</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">         <span class="p">[</span><span class="mf">0.0152</span><span class="p">,</span> <span class="mf">0.1853</span><span class="p">,</span> <span class="mf">0.9303</span><span class="p">]]])</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p><strong>Scaled Dot Product</strong>ï¼ˆ<strong>è®­ç»ƒæ—¶ä½¿ç”¨</strong>ï¼‰ï¼šï¼ˆ1ï¼‰å½“å¯¹å‘é‡çš„ç»´åº¦dè¿›è¡Œç‚¹ç§¯æ—¶ï¼Œå³ä½¿æ˜¯éšæœºå‘é‡ï¼Œç‚¹ç§¯å¤§å°ä¼šéšç€æ ¹å·dçš„å¢å¤§è€Œå¢å¤§ã€‚é€šè¿‡æ ¹å·dæ¥å¯¹ç‚¹ç§¯è¿›è¡Œå½’ä¸€åŒ–ï¼Œä»¥é˜»æ­¢è¿™ç§ç¼©æ”¾ã€‚ï¼ˆ2ï¼‰ç¼©æ”¾ç‚¹ç§¯æ¨¡å‹èƒ½é˜²æ­¢ç‚¹ç§¯ç»“æœè¿‡å¤§å¯¼è‡´ softmax æ¢¯åº¦è¿‡å°ï¼Œåå‘ä¼ æ’­å›°éš¾çš„æƒ…å†µï¼Œä¿è¯è®­ç»ƒæ—¶çš„ç¨³å®šæ€§ã€‚
$$
y=\frac{e^x}{\sum_{i=1}^n e^i}\
\frac {\partial y}{\partial x}=\frac{e^x\sum_{i=1ä¸”iâ‰ x}^n e^i}{(\sum_{i=1}^n e^i)^2}=\frac{e^x\sum_{i=1ä¸”iâ‰ x}^n e^i}{(e^x+\sum_{i=1ä¸”iâ‰ x}^n e^i)^2}\
è‹¥e^xè¿‡å¤§,å¯¼è‡´å…¶æ¢¯åº¦è¿‡å°
$$</p>
</li>
<li>
<p><strong>Residual connections</strong>ï¼šé˜²æ­¢é€€åŒ–ï¼Œé¿å…å› ä¸ºç½‘ç»œè¿‡æ·±è€Œæ¢¯åº¦æ¶ˆå¤±ã€‚å’Œå±‚å½’ä¸€åŒ–éƒ½å±äºoptimization trick</p>
</li>
<li>
<p><strong>Layer normalization</strong>ï¼šä¸»è¦çš„æ€æƒ³æ˜¯å¯¹<strong>æ¯ä¸ªæ ·æœ¬çš„æ¯ä¸ªç‰¹å¾è¿›è¡Œæ ‡å‡†åŒ–</strong>ï¼Œå…·ä½“æ¥è¯´ï¼Œå¯¹äºä¸€ä¸ªå±‚çš„è¾“å…¥ï¼Œæ¯ä¸ªæ ·æœ¬çš„æ¯ä¸ªç‰¹å¾éƒ½è¢«æ ‡å‡†åŒ–ï¼Œä½¿å¾—å…¶å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1ï¼ˆå°†æ•°æ®åˆ†å¸ƒæ§åˆ¶åœ¨å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1ï¼Œé¿å…è¿‡å¤§æˆ–è€…è¿‡å°ï¼Œæ–¹å·®ç†è§£ä¸ºæ•°æ®çš„ç´§å‡‘ç¨‹åº¦ã€‚å¯ä»¥ç†è§£ä¸º<strong>åˆ†å¸ƒç¨³å®šä¸‹æ¥ï¼Œå®‰å¿ƒå­¦ä¹ </strong>ï¼‰å±‚å½’ä¸€åŒ–æŠ€æœ¯å¯ä»¥æœ‰æ•ˆåœ°ç¼“è§£ä¼˜åŒ–è¿‡ç¨‹ä¸­æ½œåœ¨çš„ä¸ç¨³å®šã€æ”¶æ•›é€Ÿåº¦æ…¢ç­‰é—®é¢˜ã€‚è€ŒBatch normæ˜¯å¯¹æ¯ä¸ªç‰¹å¾çš„æ‰€æœ‰æ ·æœ¬è¿›è¡Œæ ‡å‡†åŒ–ï¼Œå…·ä½“åŒºåˆ«å¯å‚è€ƒ<a class="link" href="https://developer.aliyun.com/article/902038"  target="_blank" rel="noopener"
    >åšå®¢</a>
$$
for<del>an</del>individual<del>vector(word):x=[x_1,x_2,\cdots,x_{dn}]\
compute</del>\mu(å‡å€¼)=\frac{1}{dn} \sum_{i=1}^{dn}x_i
<del>and</del>\sigma(æ ‡å‡†å·®)= \sqrt{\frac{1}{dn} \sum_{i=1}^{dn}(x_i - \mu)^2}
\
\hat x=\frac{x-\mu}{\sigma+\epsilon},\epsilon æ˜¯ä¸€ä¸ªå¾ˆå°çš„æ‰°åŠ¨ é˜²æ­¢é™¤æ•°ä¸º0\
LayerNorm=\gamma\hat x +\beta,\gammaå’Œ\betaæ˜¯å¯å­¦ä¹ å‚æ•°,ç”¨äºç¼©æ”¾å’Œå¹³ç§»æ ‡å‡†åŒ–åçš„ç‰¹å¾\\
h_{pre-norm} = f(LN(h)) + h,å³å…ˆåšLN,å†å°†å…¶è¾“å…¥è‡³Attnæˆ–FFN,å†å’Œä¹‹å‰çš„éšå˜é‡ç›¸åŠ \
h_{post-norm} = LN(f(h) + h),å³å…ˆè¿‡Attnæˆ–FFn,å†å’Œä¹‹å‰çš„éšå˜é‡ç›¸åŠ ,æœ€ååšLN\
äº‹å®è¯æ˜,å‰æ ‡å‡†åŒ–çš„æ¢¯åº¦åœ¨åˆå§‹åŒ–æ—¶è¦å¥½å¾—å¤š,ä»è€Œå¯¼è‡´è®­ç»ƒé€Ÿåº¦æ›´å¿«
$$
å®Œæ•´çš„ä¸€å—encoderï¼Œ<strong>ä¸ºä»€ä¹ˆä¸€å—encoderé‡Œä¼šæœ‰ä¸¤å±‚add&amp;norm</strong>ã€‚å®é™…ä»£ç æ˜¯å‰å½’ä¸€åŒ–ï¼Œå³å…ˆå±‚å½’ä¸€åŒ–ï¼Œå†æ®‹å·®è¿æ¥</p>
<img src="C:/Users/wcx/Desktop/è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€/images/attention/enc.jpg" style="zoom:33%;" />
</li>
</ul>
</li>
<li>
<p>attention in decoderï¼ˆè®­ç»ƒ/æ¨ç†å…·ä½“ç»†èŠ‚ï¼‰</p>
<ul>
<li>
<p>ç›¸åŒä¹‹å¤„ï¼šåŸºç¡€æ¶æ„ä¸ºå¤šå¤´æ³¨æ„åŠ›ï¼Œä¸encoderä½¿ç”¨ç›¸åŒçš„ä½ç½®å‘é‡å’Œè¯å‘é‡ï¼›ä¸åŒä¹‹å¤„ï¼šæ–°å¢ç»„ä»¶ï¼šencoderéƒ¨åˆ†åškeyå’Œvalueã€Mask</p>
</li>
<li>
<p>encoderä¸decoderçš„è¿æ¥ï¼šcross-attentionç±»ä¼¼äºRNN+attentionã€‚
$$
output<del>vectors</del>from<del>encoder:h_1,h_2,\cdots,h_n\
input</del>vectors<del>from</del>decoder:z_1,z_2,\cdots,z_n\
ç±»ä¼¼äºä»æºå¥ä¸­æå–ä¿¡æ¯(RNN+Attention):k_i=Kh_i,v_i=Vh_i,q_i=Qz_i
$$</p>
</li>
<li>
<p>Maskï¼šå°†æƒé‡åˆ†æ•°èµ‹å€¼ä¸ºè´Ÿæ— ç©·ï¼Œä»¥å®ç°ä¿¡æ¯ä¸æµé€šã€‚æ€è·¯ï¼šåœ¨æ¯ä¸ªæ—¶é—´æ­¥ï¼Œæˆ‘ä»¬å¯ä»¥æ”¹å˜keyå’Œqueryçš„é›†åˆï¼ŒåªåŒ…æ‹¬è¿‡å»çš„å•è¯ï¼ˆæ•ˆç‡ä½ä¸‹ï¼‰ä¸ºäº†ä¿è¯å¹¶è¡Œç‡ï¼Œé€šè¿‡è®¾ç½®æ³¨æ„åŠ›åˆ†æ•°ä¸ºï¼âˆæ¥å±è”½å¯¹æœªæ¥å•è¯çš„æ³¨æ„åŠ›ã€‚
$$
e_{ij}=\begin{cases}
q_i^Tk_j&amp;i\geq j \
-\infty&amp;i&lt;j\
\end{cases}
$$
<img src="C:/Users/wcx/Desktop/è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€/images/attention/mask.jpg" style="zoom:33%;" /></p>
</li>
<li>
<p>è®­ç»ƒï¼šç›´æ¥å°†æºå’Œç›®æ ‡å…¨éƒ¨ç»™å‡ºï¼ˆæ•™å¸ˆå¼ºè¿«ï¼‰ï¼Œèƒ½åˆ©ç”¨åˆ°çŸ©é˜µçš„å¹¶è¡Œè®¡ç®—ï¼Œè¿™å°±æ˜¯æ¯”èµ·RNNæœ€å¤§çš„æ”¹è¿›</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># å‚è€ƒä»£ç é“¾æ¥http://nlp.seas.harvard.edu/</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">EncoderDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="n">src_embed</span><span class="p">,</span> <span class="n">tgt_embed</span><span class="p">,</span> <span class="n">generator</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">EncoderDecoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">src_embed</span> <span class="o">=</span> <span class="n">src_embed</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">tgt_embed</span> <span class="o">=</span> <span class="n">tgt_embed</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span> <span class="o">=</span> <span class="n">generator</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">),</span> <span class="n">src_mask</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                            <span class="n">tgt</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">src_embed</span><span class="p">(</span><span class="n">src</span><span class="p">),</span> <span class="n">src_mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tgt_embed</span><span class="p">(</span><span class="n">tgt</span><span class="p">),</span> <span class="n">memory</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">SimpleLossCompute</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">opt</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">generator</span> <span class="o">=</span> <span class="n">generator</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">criterion</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">opt</span> <span class="o">=</span> <span class="n">opt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">norm</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># [bs,seq,V_size]</span>
</span></span><span class="line"><span class="cl">        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="c1"># [bs*seq,V_size]</span>
</span></span><span class="line"><span class="cl">                              <span class="n">y</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">/</span> <span class="n">norm</span> <span class="c1"># bs*seq å¦‚[2,3,0]ç±»ä¼¼äºç‹¬çƒ­ç¼–ç ä½œç”¨ ä½¿ç”¨likehood ä½œä¸ºç›®æ ‡å‡½æ•°</span>
</span></span><span class="line"><span class="cl">        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">opt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">opt</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">norm</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">run_epoch</span><span class="p">(</span><span class="n">data_iter</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_compute</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_iter</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">src</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">trg</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">src_mask</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">trg_mask</span><span class="p">)</span> <span class="c1">#[bs,seq,dim] </span>
</span></span><span class="line"><span class="cl">        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_compute</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">trg_y</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">ntokens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">       	<span class="o">.....</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="o">....</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>è®­ç»ƒæ—¶ç›®æ ‡å‡½æ•°
$$
L=-\sum^T_{t=1}log<del>P(y_t|y_{&lt;t})\
è¿™é‡Œè®­ç»ƒæ—¶ä¸éœ€è¦è§£ç </del>åªéœ€è®¡ç®—å‡ºæ¯ä¸ªtokençš„æ¦‚ç‡åˆ†å¸ƒå³å¯
$$</p>
</li>
<li>
<p>é¢„æµ‹ï¼šæ¯æ¬¡è¾“å‡ºå¯¹ä¸‹ä¸€ä¸ªå•è¯çš„é¢„æµ‹ï¼Œä¼šé‡‡å–è§£ç æ–¹å¼å¦‚ï¼šè´ªå¿ƒï¼ŒæŸæœç´¢</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">greedy_decode</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">start_symbol</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">memory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">ys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">start_symbol</span><span class="p">)</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="n">src</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                           <span class="n">Variable</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> 
</span></span><span class="line"><span class="cl">                           <span class="n">Variable</span><span class="p">(</span><span class="n">subsequent_mask</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">                                    <span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="n">src</span><span class="o">.</span><span class="n">data</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">        <span class="n">prob</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">out</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># é¢„æµ‹æ—¶é‡‡ç”¨æœ€åä¸€ä¸ªtokençš„è¡¨å¾æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªtoken</span>
</span></span><span class="line"><span class="cl">        <span class="n">_</span><span class="p">,</span> <span class="n">next_word</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">prob</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">next_word</span> <span class="o">=</span> <span class="n">next_word</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">ys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">ys</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="n">src</span><span class="o">.</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">next_word</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">ys</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ul>
</li>
<li>
<p>model overviewï¼Œå‚è€ƒ<a class="link" href="https://jalammar.github.io/illustrated-transformer/"  target="_blank" rel="noopener"
    >åšå®¢</a></p>
<p>ï¼ˆ1ï¼‰æ¯ä¸€ä¸ªencoderå’Œdecoderä¸å…±äº«æƒé‡</p>
<img src="C:/Users/wcx/Desktop/è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€/images/attention/stacked_enc_dec.jpg" style="zoom:33%;" />
<p>ï¼ˆ2ï¼‰ä»¥2encoderï¼Œ2decoderä¸ºä¾‹ã€‚æµç¨‹ï¼šï¼ˆ1ï¼‰è¾“å…¥æºå¥è‡³ç¼–ç å™¨è¾“å‡ºåå¾—åˆ°e_outputï¼ˆ2ï¼‰<start>è¾“å…¥ç¼–ç å™¨ï¼Œå¾—åˆ°ä¸‹ä¸€ä¸ªtokenï¼ˆ3ï¼‰æ‹¼æ¥tokenç»§ç»­è¾“å…¥ï¼Œé‡å¤ä»¥ä¸Šæ“ä½œï¼Œç›´åˆ°è¾“å‡º<end>ã€‚è®­ç»ƒæ—¶å°†ä½¿ç”¨çœŸå®å€¼æ‹¼æ¥ï¼Œæµ‹è¯•æ—¶ä½¿ç”¨ä¸Šä¸€æ­¥é¢„æµ‹çš„ç»“æœæ‹¼æ¥</p>
</li>
</ul>
<img src="C:\Users\wcx\Desktop\è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€\images\attention\enc-dec.jpg" style="zoom: 50%;" />
<ul>
<li>Transformerç¼ºç‚¹å’Œé—®é¢˜ï¼šï¼ˆ1ï¼‰äºŒæ¬¡è®¡ç®—ï¼šè‡ªæ³¨æ„åŠ›çš„æ—¶é—´å¤æ‚åº¦ï¼ˆçŸ©é˜µä¹˜æ³•å¤æ‚åº¦O(N<SUP>2</SUP>d)ï¼‰ï¼Œè®¡ç®—éšç€åºåˆ—é•¿åº¦å‘ˆäºŒæ¬¡å¢é•¿ã€‚è€Œå¯¹äºRNNï¼Œè®¡ç®—ä»…å‘ˆçº¿æ€§å¢é•¿ï¼ŒæŸç§ç¨‹åº¦ä¸Šæ˜¯ä¸€ç§å€’é€€ã€‚fixï¼šLinformerå°†åºåˆ—é•¿åº¦ç»´åº¦æ˜ å°„åˆ°ä¸€ä¸ªè¾ƒä½ç»´åº¦çš„ç©ºé—´ï¼Œç”¨äºå€¼å’Œé”®ã€‚ç„¶è€Œå®é™…å¹¶æ²¡æœ‰å¤ªå¤šå·¥ä½œèƒ½å¤Ÿæ˜¾è‘—æé«˜æ•ˆç‡çš„ï¼ˆ2ï¼‰ä½ç½®ç¼–ç ï¼šä½¿ç”¨ç®€å•çš„ç»å¯¹ç´¢å¼•æ¥è¡¨ç¤ºä½ç½®æ˜¯æˆ‘ä»¬èƒ½åšçš„æœ€å¥½çš„å—ï¼Ÿè€ƒè™‘ç›¸å¯¹ä½ç½®æˆ–è€…ä¾èµ–äºè¯­æ³•çš„ä½ç½®</li>
<li>æ³¨æ„åŠ›å˜ç§ï¼š<strong>æ³¨æ„åŠ›maskçš„æœ¬è´¨æ˜¯æ§åˆ¶ä¿¡æ¯æµåŠ¨</strong>ï¼Œè€ƒè™‘åˆ°åŸå§‹æ³¨æ„åŠ›åœ¨æ—¶é—´æ•ˆç‡ä¸Šçš„ï¼Œå‚è€ƒç¨€ç–æ³¨æ„åŠ›ç­‰ä¼˜åŒ–æ–¹å¼https://zhuanlan.zhihu.com/p/527688857ã€https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/reports/default/15837192.pdf</li>
<li>ä½ç½®ç¼–ç å˜ç§ï¼šRoPEã€ReRoPE</li>
</ul>
<h2 id="pre-training">Pre-training
</h2><ul>
<li>
<p>æ€æƒ³ï¼šä½¿ç”¨å¤§è§„æ¨¡æ•°æ®è¿›è¡Œè‡ªç›‘ç£å­¦ä¹ </p>
</li>
<li>
<p>åˆ†è¯</p>
<ul>
<li>èƒŒæ™¯ï¼šç›®å‰çš„è¯å…¸æ“ä½œï¼Œå¦‚æœé‡åˆ°æœªçŸ¥çš„è¯ç»Ÿä¸€æ˜ å°„åˆ°ä¸€ä¸ªç‰¹æ®Šè¯å…ƒ<unk>ï¼Œè¿™ä¼šä¸¢å¤±å¾ˆå¤šä¿¡æ¯ã€‚åŒæ—¶ä¸€ä¸ªè¯æœ‰å¾ˆå¤šå½¢æ€ï¼Œä½†æ˜¯æ„ä¹‰å‡ ä¹ä¸€æ ·ï¼Œä¸å¯èƒ½æ¯ä¸€ç§å½¢æ€éƒ½ä¸ºå…¶å•ç‹¬å»ºç«‹ä¸€ä¸ªè¯åµŒå…¥ã€‚</li>
<li>è§£å†³ï¼šsubword åˆ†è¯</li>
<li>åˆ†è¯å¸¸ç”¨æ–¹æ³•ï¼Œå‚è§<a class="link" href="https://cloud.tencent.com/developer/article/1865689"  target="_blank" rel="noopener"
    >åšå®¢</a>ï¼Œhttps://github.com/google/sentencepiece
<ul>
<li>BPE</li>
<li>Wordpiece</li>
<li>SentencePiece</li>
</ul>
</li>
</ul>
</li>
<li>
<p>é¢„è®­ç»ƒçš„åŠ¨æœºï¼šæ¥æºäºword2vecçš„å¤±è´¥ï¼ˆä¸€ä¸ªå•è¯é€šå¸¸æœ‰å¤šä¸ªæ„æ€ï¼Œè€Œword2vecæŠŠå®ƒä»¬å‹ç¼©æˆä¸€ä¸ªè¯å‘é‡ï¼‰ï¼Œç„¶è€Œä¸€ä¸ªå•è¯çš„æ„ä¹‰éœ€è¦åœ¨å…·ä½“çš„ä¸Šä¸‹æ–‡ä¸­ä½“ç°ã€‚è¯¾å ‚æé—®ï¼šåœ¨word2vecé˜¶æ®µï¼Œå¯èƒ½ä¸éœ€è¦æ ‡ç‚¹ã€‚ä½†æ˜¯ç°åœ¨åœ¨å®è·µä¸­éœ€è¦æ ‡ç‚¹ï¼Œå°½å¯èƒ½ä¿æŒå’Œäººç±»æ¥æ”¶åˆ°çš„ä¸€è‡´ã€‚é¢„è®­ç»ƒç»“æ„ï¼šåŸºäºBi-LSTMæˆ–è€…Transformerã€‚<strong>é¢„è®­ç»ƒæ–¹æ³•ï¼šéšè—äº†è¾“å…¥çš„ä¸€éƒ¨åˆ†ä»æ¨¡å‹ä¸­æå–ç‰¹å¾ï¼Œå¹¶å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œä»¥é‡å»ºè¿™äº›éƒ¨åˆ†</strong>ã€‚é¢„è®­ç»ƒçš„å¥½å¤„ï¼šï¼ˆ1ï¼‰ä¸‹æ¸¸ä»»åŠ¡å¯ä»¥æ ‡æ³¨å°‘é‡æ•°æ®ï¼ˆ2ï¼‰æ ¹æ®ä¸Šä¸‹æ–‡è¡¨å¾äº†è¯­è¨€ä¿¡æ¯ï¼ˆ3ï¼‰æ›´å¥½çš„å‚æ•°åˆå§‹åŒ–ï¼Œè€Œä¸æ˜¯ä»å¤´å¼€å§‹è®­ç»ƒï¼ˆ4ï¼‰å¯ç”¨äºç”Ÿæˆè¯­è¨€çš„æ¦‚ç‡åˆ†å¸ƒ</p>
</li>
<li>
<p>èƒ½ä»é‡å»ºè¯­å¥ä¸­å­¦åˆ°ä»€ä¹ˆï¼ˆå­¦ä¹ å®Œå½¢å¡«ç©ºï¼‰ï¼šäº‹å®çŸ¥è¯†ã€è¯­æ³•çŸ¥è¯†ã€å®ä½“æŒ‡ä»£ä¿¡æ¯ã€åˆ†ç±»ä¿¡æ¯ã€æƒ…æ„Ÿåˆ†æã€æ¨ç†èƒ½åŠ›ç­‰</p>
</li>
<li>
<p>ä»è¯­è¨€å»ºæ¨¡è®­ç»ƒï¼šè¯­è¨€å»ºæ¨¡çš„æœ¬è´¨æ˜¯æ ¹æ®å‰é¢çš„å¥å­é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚å¯ä»¥ä½¿ç”¨æ•™å¸ˆå¼ºè¿«çš„æ–¹æ³•è®­ç»ƒé¢„è®­ç»ƒæ¨¡å‹å»é¢„æµ‹ä¸‹ä¸€ä¸ªå•è¯ã€‚</p>
</li>
<li>
<p>é¢„è®­ç»ƒçš„è®­ç»ƒæ•°æ®æºï¼šBookCorpusã€English Wikipediaã€WebText</p>
</li>
<li>
<p>é¢„è®­ç»ƒçš„ä¸‰ç§æ¶æ„</p>
<ul>
<li>
<p>Encoders-only</p>
<ul>
<li>
<p>ç‰¹ç‚¹ï¼šåŒå‘å­¦ä¹ ï¼Œå¯ä»¥ä»¥æœªæ¥ä¸ºæ¡ä»¶ã€‚<strong>ä¸èƒ½è¯­è¨€å»ºæ¨¡</strong>ï¼Œå³åœ¨NLGå¾ˆå¼±ã€‚è€ƒè™‘å¦‚ä½•æå‡å…¶è¯­è¨€å¼ºè¡¨å¾èƒ½åŠ›</p>
</li>
<li>
<p>è®­ç»ƒçš„ç›®æ ‡ä¼˜åŒ–å‡½æ•°ï¼šæ›¿æ¢æ‰é‡Œé¢éƒ¨åˆ†å•è¯ä½¿ç”¨ç‰¹æ®Šçš„[MASK]æ ‡è®°è¿›è¡Œè¾“å…¥ï¼Œé¢„æµ‹å‡ºè¿™äº›å•è¯ã€‚æ„Ÿè§‰å’Œæ‰©æ•£æ¨¡å‹çš„æ€è·¯æœ‰å¼‚æ›²åŒå·¥ä¹‹å¦™ï¼š<strong>ç”¨æ®‹ç¼º/å™ªå£°çš„æ•°æ®è¿˜åŸæˆåŸå§‹çš„æ•°æ®</strong>
$$
xæ˜¯æºå¥,\hat xæ˜¯è¢«æ©ç›–åçš„å¥å­\
ç›®æ ‡å‡½æ•°:p_{\theta}(x|\hat x)
$$</p>
</li>
<li>
<p>BERTä¸ºä¾‹ï¼ŒMasked LMç»†èŠ‚ï¼šéšæœºé¢„æµ‹15%çš„subwordsï¼šï¼ˆ1ï¼‰å…¶ä¸­çš„80%ç”¨[Mask]ä»£æ›¿ï¼ˆ2ï¼‰å…¶ä¸­10%ç”¨å…¶ä»–å­è¯ä»£æ›¿ï¼ˆ3ï¼‰å‰©ä½™10%ä¸å˜ï¼Œä¿è¯å½“æ¨¡å‹é‡åˆ°å®Œæ•´çš„å¥å­æ—¶ä¹Ÿèƒ½å¾ˆå¥½çš„è¡¨å¾ã€‚</p>
</li>
<li>
<p>BERTçš„å…¶ä»–ç»†èŠ‚ï¼šï¼ˆ1ï¼‰è¿˜åŠ å…¥äº†é¢„æµ‹æ˜¯å¦Bå¥å­æ˜¯Aå¥å­çš„å»¶ç»­ã€‚ä½†äº‹å®è¯æ˜è¿™å¹¶ä¸æ˜¯ç‰¹åˆ«æœ‰æ•ˆï¼Œå½“æ—¶äººä»¬å¸Œæœ›ä»–èƒ½å­¦åˆ°é•¿è·ç¦»çš„æ¦‚å¿µï¼ˆ2ï¼‰æ€ä¹ˆå°±å°†éšè—å˜é‡å°±æ˜ å°„åˆ°äº†æ¨¡å‹æƒ³è¦é¢„æµ‹çš„å•è¯ï¼Œå›ç­”ï¼šå¯èƒ½æ˜¯æœ€åæœ‰ä¸€å±‚è½¬æ¢åˆ°è¯è¡¨ç©ºé—´çš„çº¿æ€§å±‚</p>
</li>
<li>
<p>BERTå˜ç§ï¼šRoBERTaï¼šç§»é™¤å¯¹ä¸‹ä¸€å¥å­çš„é¢„æµ‹ï¼Œä½¿è¾“å…¥çš„å¥å­æ›´é•¿ã€SpanBERTï¼šMaskè¿ç»­çš„å‡ ä¸ªè¯ï¼Œå¢åŠ ä»»åŠ¡éš¾åº¦</p>
</li>
<li>
<p>Finetune vs <strong>PEFT</strong>ï¼Œå‚è€ƒ2023ç‰ˆPPTï¼šèƒŒæ™¯ï¼šåº”ç”¨é¢„è®­ç»ƒæ¨¡å‹åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­æ—¶éœ€è¦è¿›è¡Œå¾®è°ƒã€‚ç†è®ºä¸Šè¯´ï¼Œå…¨å‚æ•°å¾®è°ƒå¯èƒ½æ•ˆæœæ›´å¥½ï¼Œä½†æ¶ˆè€—å†…å­˜è¾ƒå¤šã€‚PEFTä¼šä»¥å—é™çš„æ–¹å¼è°ƒæ•´é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¿™æ ·å¯ä»¥å‡å°‘è¿‡æ‹Ÿåˆæˆ–è€…å®ç°æ›´é«˜æ•ˆçš„å¾®è°ƒå’Œæ¨æ–­ã€‚PEFTï¼Œå„ç§æ–¹æ³•è¯¦ç»†ä»‹ç»å‚è€ƒ<a class="link" href="https://www.zhihu.com/question/593383416/answer/2982770383"  target="_blank" rel="noopener"
    >åšå®¢</a>ï¼šï¼ˆ1ï¼‰Adapter Tuningï¼šåœ¨å‰é¦ˆå±‚å‰åŠ å…¥Adapterå±‚ï¼Œæ¯ä¸€ä¸ªAdapterå±‚éƒ½ä¼šä½œé™ç»´å†å‡ä¸ºçš„æ“ä½œï¼ŒåŒæ—¶ä¹Ÿå¼•å…¥äº†skip-connectã€‚ç¼ºç‚¹æ˜¯ä¼šå¼•å…¥é¢å¤–çš„å‚æ•°ï¼ˆ1ï¼‰prefix-tuningï¼šåœ¨è¾“å…¥çš„å¥å­å‰æ·»åŠ å‰ç¼€å‚æ•°ï¼Œå¯åƒå¤„ç†çœŸå®å•è¯ä¸€æ ·å¤„ç†å‰ç¼€ï¼Œå¯ä»¥ç†è§£ä¸ºæ˜¯tokenä½†æ˜¯èƒ½è®­ç»ƒã€‚å¥½å¤„ï¼šå¯ä»¥æ ¹æ®éœ€è¦é€‰æ‹©ä¸åŒçš„å‰ç¼€æ ‡è®°ï¼Œä»¥é€‚åº”ä¸åŒçš„ä»»åŠ¡å’Œé¢†åŸŸï¼ˆ3ï¼‰LoRAï¼šåŠ å…¥ä½ç§©çŸ©é˜µã€‚ç›®å‰è¾ƒæ–°çš„PEFTæ–¹å¼ï¼š<strong>Qloraã€Dora</strong>ç­‰</p>
</li>
</ul>
</li>
<li>
<p>Encoder-Decoders</p>
<ul>
<li>ç‰¹ç‚¹ï¼šèƒ½è¿›è¡Œè¯­è¨€å»ºæ¨¡ï¼Œç¼–ç å±‚å¯¹è¾“å…¥çš„å¥å­è¿›è¡Œç†è§£ï¼Œè§£ç å±‚è¿›è¡Œè¯­è¨€å»ºæ¨¡</li>
<li>ä»£è¡¨æ¨¡å‹ï¼šT5ï¼ˆæ©ç›–æºå¥çš„éƒ¨åˆ†tokenï¼Œé¢„æµ‹å‡ºè¢«æ©ç›–çš„tokenï¼‰ã€BART</li>
<li><strong>T5ä¸­çš„è®­ç»ƒç›®æ ‡</strong>ï¼šæ©ç›–æ‰æºå¥çš„å­è¯ï¼Œç”Ÿæˆè¢«æ©ç›–çš„è¯ã€‚T5èƒ½å¾ˆå¥½çš„è¿›è¡ŒçŸ¥è¯†é—®ç­”</li>
<li>æ„Ÿè§‰æ˜¯æ¯”è¾ƒå¥½çš„ç­–ç•¥ï¼Œä½†æ˜¯<strong>ä¸ºä»€ä¹ˆè®¸å¤šå¤§æ¨¡å‹æ²¡æœ‰è¿™æ ·ç”¨</strong>ã€‚èƒŒæ™¯ï¼šencoder-onlyè™½ç„¶åœ¨NLUå¾ˆå¼ºä½†åœ¨NLGæ–¹é¢ä¸è¡Œï¼Œç›®å‰åªæ¯”è¾ƒencoder-decoderå’Œdecoder-onlyã€‚åŸå› ï¼šï¼ˆ1ï¼‰enc-decå¯èƒ½ä¼šè¿›ä¸€æ­¥å¢åŠ å‚æ•°é‡ï¼Œæ•ˆç‡ä¹Ÿä¼šè¾ƒä½ï¼Œå³ä½¿enc-decä¸Šé™å¯èƒ½ä¼šæ›´é«˜ï¼ˆ2ï¼‰ä»æ•ˆæœä¸Šï¼Œ<strong>decoder-onlyçš„zero-shotèƒ½åŠ›æ›´å¼º</strong>ï¼Œè¿™ä¸€ç‚¹éå¸¸é‡è¦ï¼ˆ3ï¼‰ç”Ÿæˆä»»åŠ¡å¯ä»¥å…¼å®¹ç†è§£ä»»åŠ¡ï¼Œå³decoder-onlyåœ¨NLUæ–¹é¢ä¹Ÿæ¯”è¾ƒå¼ºï¼ˆ4ï¼‰é¢„è®­ç»ƒå’Œä¸‹æ¸¸ä»»åŠ¡çš„ç»Ÿä¸€ï¼šä¸‡ç‰©çš†å¯ç”Ÿæˆï¼Œä»ç”Ÿæˆçš„è§’åº¦æ¥çœ‹ï¼Œdecoder-onlyå°±æ˜¯æœ€åˆç†çš„ï¼Œé¢„è®­ç»ƒæ—¶çœ‹ä¸åˆ°ä¸‹æ–‡ï¼Œä¸‹æ¸¸ä»»åŠ¡ä½¿ç”¨æ—¶ä¹Ÿçœ‹ä¸åˆ°ä¸‹æ–‡ï¼ŒåŠ ä¸ªencoderå°±æ¯”è¾ƒå¥‡æ€ªäº†ï¼Œå±äºæ˜¯ç¼–ç æ—¶å¯ä»¥æ³„éœ²ä¸‹æ–‡ï¼Œè€Œè§£ç æ—¶ä¸è®©çœ‹åˆ°ä¸‹æ–‡ï¼ˆ5ï¼‰ä»ç†è®ºä¸Šï¼Œ<strong>encoderä¸­çš„è‡ªæ³¨æ„åŠ›ç½‘ç»œå­˜åœ¨ç€ä½ç§©é—®é¢˜</strong>ï¼Œå¯èƒ½ä¼šå½±å“æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ï¼Œè€Œdecoderçš„attentionçŸ©é˜µæ˜¯ä¸ªä¸‹ä¸‰è§’çŸ©é˜µï¼Œæ˜¯æ»¡ç§©çš„ã€‚&ndash;è‹å‰‘æ—</li>
</ul>
</li>
<li>
<p>Decoders-only</p>
<ul>
<li>
<p>ç‰¹ç‚¹ï¼šå¾ˆå¥½çš„è¯­è¨€å»ºæ¨¡</p>
</li>
<li>
<p>è®­ç»ƒç›®æ ‡ï¼šå‚è€ƒGPTï¼Œè¿›è¡Œè¯­è¨€å»ºæ¨¡å¼é¢„è®­ç»ƒï¼Œå³åœ¨å¤§é‡æ–‡æ¡£è¯­æ–™ä¸Šè¿›è¡Œé¢„æµ‹ä¸‹ä¸€ä¸ªtokenã€‚åç»­å¤§æ¨¡å‹æ—¶ä»£æå‡ºæŒ‡ä»¤å¾®è°ƒï¼ˆQAï¼‰</p>
</li>
<li>
<p>GPTç³»åˆ—ï¼šGPTï¼ˆ117M ï¼‰å’ŒGPT2ï¼ˆ1.5Bï¼‰ä¸»è¦æ˜¯å±•ç¤ºç”Ÿæˆèƒ½åŠ›çš„æå‡ï¼ŒGPT3ï¼ˆ<strong>175B</strong> ï¼‰å±•ç¤ºä¸Šä¸‹æ–‡å­¦ä¹ ã€é›¶æ ·æœ¬æ³›åŒ–èƒ½åŠ›</p>
</li>
<li>
<p><strong>Scaling Laws</strong>ï¼šå‚è€ƒ<a class="link" href="https://zhuanlan.zhihu.com/p/631357320"  target="_blank" rel="noopener"
    >åšå®¢</a>ï¼šéšç€æ¨¡å‹å¤§å°ã€æ•°æ®é›†å¤§å°å’Œç”¨äºè®­ç»ƒçš„è®¡ç®—æµ®ç‚¹æ•°çš„å¢åŠ ï¼Œæ¨¡å‹çš„æ€§èƒ½ä¼šæé«˜ã€‚å¹¶ä¸”ä¸ºäº†è·å¾—æœ€ä½³æ€§èƒ½ï¼Œæ‰€æœ‰ä¸‰ä¸ªå› ç´ <strong>å¿…é¡»åŒæ—¶æ”¾å¤§</strong>ã€‚å½“ä¸å—å…¶ä»–ä¸¤ä¸ªå› ç´ çš„åˆ¶çº¦æ—¶ï¼Œæ¨¡å‹æ€§èƒ½ä¸æ¯ä¸ªå•ç‹¬çš„å› ç´ éƒ½æœ‰<strong>å¹‚å¾‹å…³ç³»</strong>ã€‚</p>
</li>
<li>
<p>Prefix LMä¸Casual LMï¼Œå‚è€ƒ<a class="link" href="https://zhuanlan.zhihu.com/p/672257397"  target="_blank" rel="noopener"
    >åšå®¢</a>ã€‚Prefix LMï¼šEncoderå’ŒDecoder<strong>å…±äº«</strong>äº†åŒä¸€ä¸ªTransformerç»“æ„ï¼Œåœ¨Transformerå†…éƒ¨é€šè¿‡Attention Maskæœºåˆ¶æ¥å®ç°ã€‚å‚è€ƒLLMï¼Œæ¸…åçš„<a class="link" href="https://arxiv.org/pdf/2103.10360.pdf"  target="_blank" rel="noopener"
    >GLM</a><img src="C:/Users/wcx/Desktop/%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%e5%a4%84%e7%90%86%e5%9f%ba%e7%a1%80/images/attention/prefixlm.jpg"
	
	
	
	loading="lazy"
	
	
></p>
<p>Casual LMä¸ºç»å…¸çš„only decoderæ¶æ„ï¼Œcasual attention maskå³ç»å…¸çš„æ©è”½æœªæ¥tokençš„æ“ä½œ</p>
<p><img src="C:/Users/wcx/Desktop/%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%e5%a4%84%e7%90%86%e5%9f%ba%e7%a1%80/images/attention/casuallm.jpg"
	
	
	
	loading="lazy"
	
	
></p>
<p>æ€»ç»“ï¼šå‰ç¼€è¯­è¨€æ¨¡å‹å¯ä»¥æ ¹æ®ç»™å®šçš„å‰ç¼€ç”Ÿæˆåç»­çš„æ–‡æœ¬ï¼Œè€Œå› æœè¯­è¨€æ¨¡å‹åªèƒ½æ ¹æ®ä¹‹å‰çš„æ–‡æœ¬ç”Ÿæˆåç»­çš„æ–‡æœ¬ã€‚</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Bertè¯¦è§£ï¼Œå‚è€ƒhttp://jalammar.github.io/illustrated-bert/ æºä»£ç ï¼šhttps://github.com/google-research/bert</p>
<p>Details about BERT</p>
<p>â€¢ Two models were released:</p>
<p>â€¢ BERT-base: 12 layers, 768-dim hidden states, 12 attention heads, 110 million params.</p>
<p>â€¢ BERT-large: 24 layers, 1024-dim hidden states, 16 attention heads, 340 million params.</p>
<p>â€¢ Trained on:</p>
<p>â€¢ BooksCorpus (800 million words)</p>
<p>â€¢ English Wikipedia (2,500 million words)</p>
<p>â€¢ Pretraining is expensive and impractical on a single GPU.</p>
<p>â€¢ BERT was pretrained with 64 TPU chips for a total of 4 days.</p>
<p>â€¢ (TPUs are special tensor operation acceleration hardware)</p>
<p>â€¢ Finetuning is practical and common on a single GPU</p>
<p>â€¢ â€œPretrain once, finetune many times.â€</p>
<p>å…·ä½“å¦‚ä½•åˆ†å‰²ï¼ˆç­–ç•¥ï¼šé‡‡å–æœ€å°‘åˆ†å‰²æ¬¡æ•°çš„åˆ†è¯ç­–ç•¥ï¼Œæ¯”å¦‚ifyå¯åˆ†æˆif+yï¼Œä¹Ÿå¯å•ç‹¬ï¼Œå¦‚æœè¯è¡¨æœ‰ifyåˆ™ä¸æ‹†ifyï¼‰ã€‚</p>
<p>Transformer decoder with 12 layers, 117M parameters.</p>
<p>â€¢ 768-dimensional hidden states, 3072-dimensional feed-forward hidden layers.</p>
<p>â€¢ Byte-pair encoding with 40,000 merges</p>
<p>â€¢ Trained on BooksCorpus: over 7000 unique books.</p>
<p>â€¢ Contains long spans of contiguous text, for learning long-distance dependencies.</p>
<p>â€¢ The acronym â€œGPTâ€ never showed up in the original paper; it could stand for</p>
<p>â€œGenerative PreTrainingâ€ or â€œGenerative Pretrained Transformer</p>
<p>é¢„è®­ç»ƒæ¨¡å‹æ¶æ„</p>
<ul>
<li>encoderï¼šBERTï¼ˆmaskedLMï¼‰:ç­–ç•¥ï¼šæ›¿æ¢ã€maskã€ä¿æŒä¸å˜ï¼Œæ¥é¢„æµ‹åº”è¯¥å‡ºç°çš„å•è¯ï¼›é¢å¤–åŠ äº†ä¸€ä¸ªé¢„æµ‹å¥å­Bæ˜¯å¦æ˜¯Açš„å»¶ç»­ï¼ˆä½†äº‹å®è¯æ˜è¿™å¹¶ä¸æ˜¯ç‰¹åˆ«æœ‰æ•ˆï¼Œå½“æ—¶äººä»¬å¸Œæœ›ä»–èƒ½å­¦åˆ°é•¿è·ç¦»çš„æ¦‚å¿µï¼‰ã€‚æ€ä¹ˆå°±å°†éšè—å˜é‡å°±æ˜ å°„åˆ°äº†æ¨¡å‹æƒ³è¦é¢„æµ‹çš„å•è¯ï¼ˆå›ç­”ï¼šå¯èƒ½æ˜¯æœ€åæœ‰ä¸€å±‚è½¬æ¢æˆè¯è¡¨çš„çº¿æ€§å±‚ï¼‰ã€‚å˜ç§ã€‚</li>
<li>encoder-decoderï¼šå°†ä¸€æ®µé•¿æ–‡æœ¬åˆ†æˆä¸¤å—ï¼Œç”±å‰ä¸€æ®µæ¥é¢„æµ‹åä¸€æ®µã€‚QA</li>
<li>decoder</li>
</ul>
<p>GPT-2çš„æ ‡é¢˜æ˜¾ç¤ºä½œè€…ä»»åŠ¡language modelåº”è¯¥æ˜¯ä¸€ä¸ªæ— ç›‘ç£çš„å¤šä»»åŠ¡å­¦ä¹ è€…ï¼Œå³å¯ä»¥æ˜¾ç¤ºé›¶æ ·æœ¬å­¦ä¹ ï¼ˆå³ç»™å‡ºæ¨¡å‹æ²¡æœ‰è§è¿‡çš„æ ·æœ¬æ—¶ï¼Œä¹Ÿèƒ½å¾ˆå¥½åœ°å¤„ç†ï¼‰</p>
<h2 id="nlg">NLG
</h2><ul>
<li>
<p>NLPè‡ªç„¶è¯­è¨€å¤„ç†=NLUè‡ªç„¶è¯­è¨€ç†è§£+NLGè‡ªç„¶è¯­è¨€ç”Ÿæˆ</p>
</li>
<li>
<p>NLGåˆ†ç±»ï¼šä»å¼€æ”¾æ€§è§’åº¦åˆ†ç±»ï¼ˆå³ç”Ÿæˆçš„æ–‡æœ¬å¼€æ”¾ç¨‹åº¦ã€å¤šæ ·æ€§ï¼‰ä»closeåˆ°openï¼šMachine Translationã€Summarizationã€Task-driven Dialogã€ChitChat Dialogã€Story Generation</p>
</li>
<li>
<p>NLGæ¨¡å‹</p>
<ul>
<li>
<p>é¢„æµ‹next tokenå…¬å¼
$$
input_seq:[y_0,y_1,\cdots,y_{t-1}]\
For<del>model</del>f<del>and</del>vocab<del>V,we</del>get<del>scores</del>S=f({y_{&lt;t}},\theta)\
P(y_t|{y_{&lt;t}})=\frac{exp(S_w)}{\sum_{w&rsquo;\in Vexp(S_{w&rsquo;})}}\
\hat y_t=g(P(y_t|{y_{&lt;t}})),g<del>is</del>decoding~algorithm
$$</p>
</li>
<li>
<p>å¯¹äºéå¼€æ”¾æ€§ä»»åŠ¡å¦‚æœºå™¨ç¿»è¯‘ï¼Œå¸¸ç”¨Enc-Decæ¶æ„ï¼ˆä¸ºäº†æ›´å¤šçš„åŸå¥çš„çº¦æŸï¼‰ï¼›å¯¹äºå¼€æ”¾æ€§ç”Ÿæˆä»»åŠ¡ï¼Œå¸¸ç”¨Decæ¶æ„ï¼ˆè‡ªå›å½’å¼ï¼Œå¾ªç¯æ‹¼æ¥é¢„æµ‹çš„tokenä»¥é¢„æµ‹ä¸‹ä¸€ä¸ªtokenç›´åˆ°å‡ºç°ç»“æŸç¬¦ï¼‰</p>
</li>
</ul>
</li>
<li>
<p>è§£ç ï¼šç”¨äºæ¨ç†ï¼Œè®­ç»ƒæ—¶åŠ å…¥ï¼Ÿï¼Ÿï¼Ÿå„ç§è§£ç ç­–ç•¥ä»£ç å®ç°å‚è€ƒ<a class="link" href="https://avoid.overfit.cn/post/42c2631bc56347849d538768d84d47c2"  target="_blank" rel="noopener"
    >åšå®¢</a></p>
<ul>
<li>
<p>è§£ç çš„å…¬å¼å®šä¹‰
$$
åœ¨æ¯ä¸ªæ—¶é—´æ­¥tè®¡ç®—å‡ºè¯æ±‡è¡¨ä¸­æ¯ä¸ªtokençš„å¾—åˆ†:S=f({y_{&lt;t}})\
softmaxè®¡ç®—è¯æ±‡è¡¨ä¸­æ¯ä¸ªtokençš„æ¦‚ç‡åˆ†å¸ƒp:P(y_t=w|{y_{&lt;t}})=\frac{exp(S_w)}{\sum_{w&rsquo;\in Vexp(S_{w&rsquo;})}}\
è§£ç ç®—æ³•å®šä¹‰ä¸ºä»è¿™ä¸ªåˆ†å¸ƒä¸­é€‰æ‹©tokençš„å‡½æ•°g:\hat y_t=g(P(y_t|{y_{&lt;t}}))
$$</p>
</li>
<li>
<p>Greedy Decodingä¸Beam Search
$$
è´ªå©ªè§£ç :\hat y_t=argmax(P(y_t|{y_{&lt;t}})),å³åœ¨æ¦‚ç‡åˆ†å¸ƒä¸­é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„è¯æ±‡
$$
å‚è€ƒä»£ç </p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">greedy_decode</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">start_symbol</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">memory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">ys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">start_symbol</span><span class="p">)</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="n">src</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> 
</span></span><span class="line"><span class="cl">                           <span class="n">Variable</span><span class="p">(</span><span class="n">ys</span><span class="p">),</span> 
</span></span><span class="line"><span class="cl">                           <span class="n">Variable</span><span class="p">(</span><span class="n">subsequent_mask</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">                                    <span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="n">src</span><span class="o">.</span><span class="n">data</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">        <span class="n">prob</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">out</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="c1"># é¢„æµ‹æ—¶é‡‡ç”¨æœ€åä¸€ä¸ªtokençš„è¡¨å¾æ¥é¢„æµ‹ä¸‹ä¸€ä¸ªtoken</span>
</span></span><span class="line"><span class="cl">        <span class="n">_</span><span class="p">,</span> <span class="n">next_word</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">prob</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">next_word</span> <span class="o">=</span> <span class="n">next_word</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">ys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">ys</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="n">src</span><span class="o">.</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">next_word</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">ys</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Beam Searchï¼šæœ‰æ›´å¤§é€‰æ‹©çš„å€™é€‰åºåˆ—</p>
<p>å‚è€ƒä»£ç ï¼šä½œä¸šå››/ä½œä¸šäº”</p>
<p>æ€»çš„æ¥è¯´ï¼Œ<strong>åŸºäºæœ€å¤§æ¦‚ç‡è§£ç å¯¹äºåƒæœºå™¨ç¿»è¯‘å’Œæ‘˜è¦è¿™æ ·ä½ç†µä»»åŠ¡æ˜¯æœ‰åˆ©çš„</strong>ï¼ä¸Šè¿°äºŒè€…æ–¹æ³•çš„é—®é¢˜ï¼šå¯¹äºæœ€å¯èƒ½çš„å­—ç¬¦ä¸²å®¹æ˜“é‡å¤ã€‚åŸå› ï¼šè‡ªæˆ‘æ”¾å¤§æ•ˆåº”ï¼Œæ¨¡å‹è®¤ä¸ºé‡å¤ç”Ÿæˆè¿™æ®µtokençš„è´Ÿä¼¼ç„¶åˆ†æ•°è¶Šæ¥è¶Šå°ï¼Œå³ä¿¡å¿ƒè¶Šæ¥è¶Šå¤§ã€‚ç›®å‰æ‰©å¤§å‚æ•°è§„æ¨¡ã€æ•°æ®è§„æ¨¡ä¾æ—§æ²¡æœ‰è§£å†³æ­¤é—®é¢˜ã€‚è§£å†³æ–¹æ¡ˆï¼šï¼ˆ1ï¼‰è§„åˆ™é¿å…é‡å¤n-gramï¼ˆ2ï¼‰ä½¿ç”¨ä¸åŒçš„è®­ç»ƒç›®æ ‡å‡½æ•°ï¼šUnlikelihood objectiveæƒ©ç½šå·²ç»ç”Ÿæˆçš„æ ‡è®°ã€Coverage lossé˜²æ­¢æ³¨æ„æœºåˆ¶å…³æ³¨ç›¸åŒçš„å•è¯ï¼ˆ3ï¼‰ä½¿ç”¨ä¸åŒçš„è§£ç æ–¹æ³•ï¼šå¯¹æ¯”è§£ç ã€‚</p>
<p>å¯¹äºå¼€æ”¾å¼ç”Ÿæˆï¼Œæ‰¾åˆ°æœ€å¯èƒ½çš„å­—ç¬¦ä¸²æ˜¯åˆç†çš„å—ï¼Ÿå¯¹æ¯”äº†Beam searchå’ŒçœŸå®äººç±»è¡¨è¾¾æ—¶çš„é€‰æ‹©tokençš„æ¦‚ç‡ï¼Œå‘ç°äººç±»çš„é€‰æ‹©å…·æœ‰éšæœºæ€§ã€‚å› æ­¤ï¼Œæå‡ºäº†å¼•å…¥éšæœºæ€§çš„æ–¹æ³•ï¼Œå³é‡‡æ ·Sampling</p>
</li>
<li>
<p>Top-k sampling</p>
<p>å®Œå…¨éšæœºé‡‡æ ·ï¼Œå³èµ‹äºˆè¯è¡¨ä¸­æ‰€æœ‰tokenç›¸åŒçš„æœºä¼šï¼Œè¿™å¯èƒ½ä¼šå¼•å…¥å®Œå…¨ä¸åŒ¹é…çš„tokenã€‚æå‡ºåªä»æ¦‚ç‡åˆ†å¸ƒä¸­çš„å‰kä¸ªtokenä¸­è¿›è¡Œé‡‡æ ·ï¼Œä¿è¯äº†åˆç†æ€§å’Œéšæœºæ€§ã€‚kä¸ºè¶…å‚æ•°ã€‚top-kçš„é—®é¢˜ï¼šä¸€æ—¦è®¾å®šä¼šå›ºå®šã€‚æœ‰æ—¶ä¼š cut off too quicklyï¼Œå³å‰ï¼kä¸ªtokenéƒ½åˆç†ï¼›æœ‰æ—¶ cut off too slowlyï¼Œå³å½“ä»…æœ‰ï¼œkä¸ªtokenåˆç† å‰©ä½™çš„tokenå®Œå…¨ä¸åˆç†ã€‚å› æ­¤å¼•å…¥åŠ¨æ€é€‰æ‹©top-p</p>
</li>
<li>
<p>Top-p samplingï¼šä»æ’åå‰pçš„ç´¯ç§¯æ¦‚ç‡è´¨é‡ä¸­æŠ½æ ·æ‰€æœ‰ä»¤ç‰Œ
$$
å½“åˆ†å¸ƒP_tè¾ƒå¹³å¦æ—¶,æœ‰é™çš„kä¼šæ¶ˆé™¤è®¸å¤šå¯è¡Œé€‰é¡¹\
å½“åˆ†å¸ƒP_tæ›´å°–é”æ—¶,è¾ƒé«˜çš„kå…è®¸å¤ªå¤šé€‰é¡¹æœ‰æœºä¼šè¢«é€‰ä¸­\
è§£å†³æ–¹æ¡ˆ:top-p~é‡‡æ ·\
ä»æ’åå‰pçš„ç´¯ç§¯æ¦‚ç‡è´¨é‡ä¸­æŠ½æ ·æ‰€æœ‰ä»¤ç‰Œï¼ˆå³ï¼Œè´¨é‡é›†ä¸­çš„åœ°æ–¹ï¼‰\
æ ¹æ®P_tçš„å‡åŒ€ç¨‹åº¦å˜åŒ–k
$$
è¯¦ç»†æµç¨‹ï¼šï¼ˆ1ï¼‰softmaxåä»é«˜åˆ°ä½æ’åºï¼ˆ2ï¼‰è®¡ç®—å‰ç¼€å’Œï¼ˆ3ï¼‰å½“æŸä¸ªä½ç½®çš„å‰ç¼€å’Œé«˜äºé˜ˆå€¼åˆ™åé¢ä½ç½®çš„èˆå¼ƒï¼ˆ4ï¼‰æ‰¾åˆ°ç´¯ç§¯æ¦‚ç‡è¶…è¿‡ç»™å®šé˜ˆå€¼pçš„æœ€å°tokenå­é›†ï¼Œè¿™ä¸ªå­é›†å°±æ˜¯æ‰€è°“çš„â€œæ ¸â€ï¼ˆnucleusï¼‰å‚è€ƒä»£ç å¦‚ä¸‹ï¼š</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># å‚è€ƒä»£ç å¦‚ä¸‹</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">top_p_sampling</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">top_p</span><span class="o">=</span><span class="mf">0.95</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">inference_mode</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_tokens</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">next_token_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">,:]</span> <span class="c1"># [bs, seq_len, V_size]</span>
</span></span><span class="line"><span class="cl">            <span class="n">sorted_logits</span><span class="p">,</span> <span class="n">sorted_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">next_token_logits</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># é»˜è®¤æœ€åä¸€ç»´é™åºæ’åˆ—</span>
</span></span><span class="line"><span class="cl">            <span class="n">sorted_probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">sorted_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">cumulative_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">sorted_probs</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># è®¡ç®—å‰ç¼€å’Œ</span>
</span></span><span class="line"><span class="cl">            <span class="n">sorted_indices_to_remove</span><span class="o">=</span><span class="n">cumulative_probs</span> <span class="o">&gt;</span> <span class="n">top_p</span> <span class="c1"># å¾—åˆ°æ¯ä¸ªä½ç½®æ˜¯å¦è¶…å‡ºé˜ˆå€¼ è¶…å‡ºé˜ˆå€¼è¯´æ˜åé¢çš„tokenä¸åˆç† æœªè¶…è¿‡è¯´æ˜ç›®å‰ä½ç½®çš„tokenåˆç†</span>
</span></span><span class="line"><span class="cl">            <span class="n">sorted_indices_to_remove</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span><span class="kc">False</span> <span class="c1"># æš‚ä¸”ä¸çŸ¥é“ä»€ä¹ˆä½œç”¨</span>
</span></span><span class="line"><span class="cl">            <span class="n">indices_to_remove</span><span class="o">=</span><span class="n">sorted_indices</span><span class="p">[</span><span class="n">sorted_indices_to_remove</span><span class="p">]</span> <span class="c1"># è·å¾—å‰”é™¤çš„tokenä½ç½®</span>
</span></span><span class="line"><span class="cl">            <span class="n">next_token_logits</span><span class="o">.</span><span class="n">scatter_</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">indices_to_remove</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:],</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">))</span> <span class="c1"># å¡«å……-inf è¿™æ ·é‡‡æ ·çš„æƒé‡ä¸º0 å°†æ°¸è¿œä¸ä¼šè¢«é‡‡æ ·</span>
</span></span><span class="line"><span class="cl">            <span class="n">probs</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">next_token_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">next_token</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># æŒ‰æƒé‡é‡‡æ · æ¦‚ç‡é«˜çš„tokenè¶Šå®¹æ˜“è¢«é‡‡æ ·</span>
</span></span><span class="line"><span class="cl">            <span class="n">input_ids</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">next_token</span><span class="p">],</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">generated_text</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">generated_text</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>å…¶ä»–é‡‡æ ·ç­–ç•¥ï¼šTypical Samplingï¼šReweights the score based on the entropy of the distributionã€‚Epsilon Samplingï¼šSet a threshold for lower bounding valid probabilitiesã€‚å½“å‰æ¯”è¾ƒç«çƒ­çš„å¤§æ¨¡å‹é‡‡æ ·ç­–ç•¥ï¼Œä¸»è¦æ˜¯ä¸ºäº†å‡è½»å¹»è§‰ç­‰ï¼šDolaã€OPERAã€Activation decodingã€ITIç­‰</p>
</li>
<li>
<p>æ‰©å¤§éšæœºæ€§ï¼šæ¸©åº¦ç³»æ•°ã€‚å¹³ç¼“æ¯ä¸ªtokenä¹‹é—´çš„å·®å¼‚æ€§ï¼Œéœ€è¦ç»“åˆbeam searchå’Œtop-pä½¿ç”¨ï¼Œè¿™æ ·å¯é€‰æ‹©æ›´å¤šçš„tokenã€‚</p>
<p>æ¥è‡ªhuggingface ä»£ç ä¸­çš„æ³¨é‡Šï¼š</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-markdown" data-lang="markdown"><span class="line"><span class="cl">[`LogitsWarper`] for temperature (exponential scaling output probability distribution), which effectively means that it can control the randomness of the predicted tokens. Often used together with [`TopPLogitsWarper`] and [`TopKLogitsWarper`]
</span></span></code></pre></td></tr></table>
</div>
</div><p>ä½¿ç”¨æ–¹æ³•ï¼š</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-markdown" data-lang="markdown"><span class="line"><span class="cl">Strictly positive float value used to modulate the logits distribution. A value smaller than <span class="sb">`1`</span> decreases randomness (and vice versa), with <span class="sb">`0`</span> being equivalent to shifting all probability mass to the most likely token
</span></span></code></pre></td></tr></table>
</div>
</div><p>$$
P(y_t=w|{y_{&lt;t}})=\frac{exp(S_w/\tau)}{\sum_{w&rsquo;\in Vexp(S_{w&rsquo;}/\tau)}}\
\tau&gt;1,æ¦‚ç‡åˆ†å¸ƒæ›´å‡åŒ€,è¾“å‡ºæ›´å¤šæ ·æ€§\
\tau&lt;1,æ¦‚ç‡åˆ†å¸ƒå°–é”,è¾“å‡ºæ›´å•ä¸€ä»£ç 
$$</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="o">/</span><span class="n">temperature</span>
</span></span><span class="line"><span class="cl"><span class="n">probabilities</span><span class="o">=</span><span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">### hf æºç </span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">TemperatureLogitsWarper</span><span class="p">(</span><span class="n">LogitsWarper</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">temperature</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">temperature</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="p">(</span><span class="n">temperature</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">except_msg</span> <span class="o">=</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="sa">f</span><span class="s2">&#34;`temperature` (=</span><span class="si">{</span><span class="n">temperature</span><span class="si">}</span><span class="s2">) has to be a strictly positive float, otherwise your next token &#34;</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;scores will be invalid.&#34;</span>
</span></span><span class="line"><span class="cl">            <span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">temperature</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span> <span class="ow">and</span> <span class="n">temperature</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">except_msg</span> <span class="o">+=</span> <span class="s2">&#34; If you&#39;re looking for greedy decoding strategies, set `do_sample=False`.&#34;</span>
</span></span><span class="line"><span class="cl">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">except_msg</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@add_start_docstrings</span><span class="p">(</span><span class="n">LOGITS_PROCESSOR_INPUTS_DOCSTRING</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_ids</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">,</span> <span class="n">scores</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">scores_processed</span> <span class="o">=</span> <span class="n">scores</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">scores_processed</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Contrastive searchï¼šå‚è€ƒ<a class="link" href="https://huggingface.co/blog/introducing-csearch"  target="_blank" rel="noopener"
    >åšå®¢</a>ã€‚èƒŒæ™¯ï¼šç›®å‰çš„è§£ç æ–¹æ³•åˆ†ä¸ºäº†ç¡®å®šæ€§ï¼ˆDeterministic Methodsï¼Œå¦‚ï¼šgreedy searchã€beam searchï¼‰å’Œéšæœºæ€§æ–¹æ³•ï¼ˆtop-kã€top-pï¼‰ã€‚ç¡®å®šæ€§æ–¹æ³•å­˜åœ¨çš„é—®é¢˜ï¼šä¼šå¯¼è‡´<strong>æ¨¡å‹é€€åŒ–</strong>ï¼Œå³ç”Ÿæˆçš„æ–‡æœ¬ä¸è‡ªç„¶ä¸”åŒ…å«ä¸å¿…è¦çš„é‡å¤ã€‚ä¸ç¡®å®šæ€§æ–¹æ³•å­˜åœ¨çš„é—®é¢˜ï¼šè™½ç„¶æ ¸é‡‡æ ·å¯ä»¥ç”Ÿæˆæ²¡æœ‰é‡å¤çš„æ–‡æœ¬ï¼Œä½†ç”Ÿæˆæ–‡æœ¬çš„è¯­ä¹‰ä¸€è‡´æ€§å¹¶ä¸æ˜¯å¾ˆå¥½ã€‚æˆ‘ä»¬æ³¨æ„åˆ°ï¼Œè¿™ç§è¯­ä¹‰ä¸ä¸€è‡´çš„é—®é¢˜å¯ä»¥é€šè¿‡é™ä½æ¸©åº¦ (temperature) æ¥éƒ¨åˆ†è§£å†³ã€‚ç„¶è€Œï¼Œé™ä½æ¸©åº¦ä¼šä½¿æ ¸é‡‡æ ·æ›´æ¥è¿‘è´ªå¿ƒæœç´¢ï¼Œè¿™å…¶å®å°±å˜æˆäº†è´ªå¿ƒæœç´¢å’Œæ ¸é‡‡æ ·ä¹‹é—´çš„æƒè¡¡ã€‚ä¸€èˆ¬æ¥è®²ï¼Œè¦æ‰¾åˆ°ä¸€ä¸ªæ—¢èƒ½é¿å…è´ªå¿ƒæœç´¢åˆèƒ½é¿å…æ ¸é‡‡æ ·é™·é˜±çš„å¿«æ·ä¸”ä¸æ¨¡å‹æ— å…³çš„æ¸©åº¦ç›¸å½“æœ‰æŒ‘æˆ˜ã€‚å¼•å…¥å¯¹æ¯”æœç´¢ï¼Œå…¬å¼å¦‚ä¸‹ï¼šç»™å®šå‰t-1åºåˆ—çš„tokenï¼Œæ¥é¢„æµ‹ç¬¬tä¸ªtokenã€‚å…¶ä¸­vä¸ºk ä¸ªæ¦‚ç‡æœ€å¤§çš„å€™é€‰è¯å…ƒçš„é›†åˆã€‚pä¸ºæ¨¡å‹å¯¹vé›†åˆä¸­æ¯ä¸ªè¯å…ƒçš„é¢„æµ‹æ¦‚ç‡ã€‚s(,)å‡½æ•°ä¸ºè®¡ç®—å€™é€‰é›†åˆä¸­çš„æ¯ä¸ªtokenä¸å‰æ–‡tokençš„ç›¸ä¼¼ç¨‹åº¦ã€‚æƒ©ç½šé¡¹çš„ä½œç”¨ä¸ºé˜²æ­¢æ¨¡å‹é€€åŒ–ï¼Œæƒ©ç½šå¯èƒ½ä¼šé‡å¤ç”Ÿæˆçš„æƒ…å†µã€‚å½“alphaä¸º0æ—¶ï¼Œé€€åŒ–ä¸ºè´ªå©ªè§£ç ã€‚å½“alphaè¶Šå°ï¼Œæƒ©ç½šåŠ›åº¦è¶Šå°ï¼Œåä¹‹äº¦ç„¶ã€‚
$$
\begin{equation}
x_t = \arg\max_{v \in V^{(k)}} \left{ (1 - \alpha) \times \underbrace{p_{\theta}(v \mid x_{&lt; t})}<em>{\text{model confidence}} - \alpha \times \left( \max \left{ \underbrace{s(h_v, h</em>{x_j})}_{\text{degeneration penalty}} : 1 \leq j \leq t - 1 \right} \right) \right},
\end{equation}
$$
è´ªå©ªè§£ç å’Œå¯¹æ¯”è§£ç ç»“æœå¯è§†åŒ–å¯¹æ¯”ï¼šåˆ†åˆ«å°†è´ªå¿ƒæœç´¢å’Œå¯¹æ¯”æœç´¢ç”Ÿæˆçš„è¯å…ƒç›¸ä¼¼åº¦çŸ©é˜µå¯è§†åŒ–ã€‚ä¸¤ä¸ªè¯å…ƒä¹‹é—´çš„ç›¸ä¼¼æ€§è¢«å®šä¹‰ä¸ºå®ƒä»¬çš„å‘é‡è¡¨å¾ (å³æœ€åä¸€ä¸ªè½¬æ¢å™¨å±‚çš„éšè—çŠ¶æ€) ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼æ€§ã€‚è´ªå¿ƒæœç´¢ (ä¸Š) å’Œå¯¹æ¯”æœç´¢ (ä¸‹) çš„ç»“æœã€‚ä»è´ªå¿ƒæœç´¢çš„ç»“æœä¸­ï¼Œæˆ‘ä»¬çœ‹åˆ°éå¯¹è§’çº¿çš„ç›¸ä¼¼åº¦å¾ˆé«˜ï¼Œè¿™æ¸…æ¥šåœ°è¡¨æ˜è´ªå¿ƒæœç´¢äº§ç”Ÿäº†é‡å¤ã€‚ç›¸åï¼Œåœ¨å¯¹æ¯”æœç´¢çš„ç»“æœä¸­ï¼Œé«˜ç›¸ä¼¼åº¦åˆ†æ•°ä¸»è¦å‡ºç°åœ¨å¯¹è§’çº¿ä¸Šï¼Œè¿™è¯æ˜æˆ‘ä»¬æˆåŠŸè§£å†³äº†é€€åŒ–é—®é¢˜ã€‚å¯¹æ¯”æœç´¢çš„è¿™ä¸€ä¼˜è‰¯ç‰¹æ€§æ˜¯é€šè¿‡åœ¨è§£ç è¿‡ç¨‹ä¸­å¼•å…¥é€€åŒ–æƒ©ç½šæ¥å®ç°çš„ã€‚</p>
<img src="C:/Users/wcx/Desktop/è‡ªç„¶è¯­è¨€å¤„ç†åŸºç¡€/images/LM/c_search_visual.jpg" style="zoom:50%;" />
</li>
<li>
<p>æé«˜è§£ç æ•ˆæœï¼šèƒŒæ™¯ï¼šå¦‚æœæˆ‘çš„æ¨¡å‹è§£ç å‡ºäº†ä¸€ä¸ªç³Ÿç³•çš„åºåˆ—å‘¢ï¼Ÿæå‡ºRe-rankingï¼Œå³ä¸€æ¬¡æ€§è§£ç å‡ºä¸€æ‰¹åºåˆ—ï¼Œå®šä¹‰æ‰“åˆ†å‡½æ•°ï¼ˆå¦‚ï¼šå›°æƒ‘åº¦ï¼‰ï¼ŒåŸºäºè¯„åˆ†é‡æ–°æ’åºåï¼Œé€‰æ‹©è¯„åˆ†æœ€é«˜çš„åºåˆ—ã€‚</p>
</li>
</ul>
</li>
<li>
<p>NLGè®­ç»ƒ</p>
<ul>
<li>NLGæ¨¡å‹çš„ä¸€äº›é—®é¢˜ï¼šé‡å¤æŸæ®µè¯è¯­ã€å¤è¯»æœºï¼ˆå¤§æ¨¡å‹å¸¸è§çš„é—®é¢˜ï¼Œå³ç›´æ¥å°†è®­ç»ƒé›†ä¸­è®­ç»ƒè¿‡çš„æ•°æ®è¿›è¡Œå›ç­”ï¼Œæ²¡æœ‰è¿›è¡Œæ€è€ƒã€‚è§£å†³æ–¹æ¡ˆï¼šå¼•å…¥å¤šæ ·æ€§çš„è®­ç»ƒæ•°æ®ï¼Œæ¯”å¦‚ï¼šmathã€codingæå‡LLMæ¨ç†å’Œæ€è€ƒèƒ½åŠ›ã€‚å‚è€ƒ<a class="link" href="https://zhuanlan.zhihu.com/p/667274901"  target="_blank" rel="noopener"
    >åšå®¢</a>ï¼‰</li>
<li>Exposure Biasï¼šåå·®æ”¾å¤§ã€‚ç”±äºåœ¨è®­ç»ƒæ—¶ï¼Œä½¿ç”¨æ•™å¸ˆå¼ºè¿«å³è¾“å…¥çš„æ˜¯äººç±»çš„çœŸå®tokenï¼Œä½†é¢„æµ‹æ—¶ä½¿ç”¨çš„æ˜¯æ¨¡å‹ä¸Šä¸€æ­¥é¢„æµ‹çš„tokenï¼Œå®¹æ˜“é€ æˆæ»šé›ªçƒå¼çš„é”™è¯¯ï¼Œå¯¼è‡´å¾®ç¬‘é”™è¯¯ä¸æ–­æ”¾å¤§</li>
<li>Exposure Biasçš„è§£å†³æ–¹æ¡ˆï¼šï¼ˆ1ï¼‰Scheduled samplingï¼šè®­ç»ƒæ—¶ï¼Œå°†è¾“å…¥çš„tokenéƒ¨åˆ†æ›¿æ¢ä¸ºæ¨¡å‹ä¸Šä¸€æ­¥top-pè§£ç å‡ºçš„tokenï¼Œè€Œä¸å®Œå…¨æ˜¯ç”¨golden tokenä½œä¸ºè¾“å…¥ã€‚ä¸æ–­å¢åŠ pæ¨¡æ‹Ÿå®é™…é¢„æµ‹æ—¶çš„æƒ…å†µã€‚åœ¨å®è·µä¸­ä¼šå¸¦æ¥æ”¹è¿›ï¼Œä½†å¯èƒ½ä¼šå¯¼è‡´å¥‡æ€ªçš„è®­ç»ƒç›®æ ‡ï¼ŒçŒœæƒ³å¯èƒ½æ˜¯å¼•å…¥éšæœºtokenåä½†ä¸æ˜¯åŒ¹é…çš„ç›®æ ‡tokenï¼ˆ2ï¼‰Dataset Aggregationï¼šåœ¨è®­ç»ƒçš„ä¸åŒæ—¶é—´é—´éš”ï¼Œä»å½“å‰çš„æ¨¡å‹ç”Ÿæˆåºåˆ—ï¼Œå°†è¿™äº›åºåˆ—ä½œä¸ºé¢å¤–çš„ç¤ºä¾‹æ·»åŠ åˆ°è®­ç»ƒé›†ä¸­ï¼ˆ3ï¼‰Retrieval Augmentationï¼šå­¦ä¹ ä»ç°æœ‰çš„äººç±»å†™ä½œåŸå‹è¯­æ–™åº“ä¸­æ£€ç´¢åºåˆ—ï¼ˆ4ï¼‰Reinforcement Learningï¼šreward modeléœ€è¦çš„ä¾æ®ï¼šåŸºäºéªŒè¯æŒ‡æ ‡ï¼š<strong>BLEUã€ROUGE ã€CIDErã€SPIDEr</strong>ã€åŸºäºäººç±»åå¥½ï¼šRLHFç­‰</li>
</ul>
</li>
<li>
<p>è¯„ä¼°NLG</p>
<ul>
<li>
<p>åŸºäºå†…å®¹é‡åˆåº¦ï¼ˆè§„åˆ™ï¼‰ï¼šè®¡ç®—ç”Ÿæˆçš„æ–‡æœ¬ä¸é»„é‡‘æ ‡å‡†ï¼ˆäººå·¥ç¼–å†™çš„ï¼‰æ–‡æœ¬ä¹‹é—´çš„è¯æ±‡ç›¸ä¼¼æ€§ï¼Œä¸»è¦ä¸ºåŸºäºN-gram</p>
<ul>
<li>
<p>BLEU</p>
</li>
<li>
<p>ROUGE</p>
</li>
<li>
<p>METEOR</p>
</li>
<li>
<p>CIDEr</p>
<p>åŸºäºè§„åˆ™æŒ‡æ ‡çš„é—®é¢˜ï¼šå¯¹äºç›¸åŒæ„æ€ï¼Œä½†æ˜¯è¯æ±‡å¹¶ä¸ç›¸åŒçš„ï¼Œå¹¶ä¸æœ‰æ•ˆã€‚å¯¹äºè¶Šæ˜¯opençš„ä»»åŠ¡ï¼Œè¶Šä¸ç†æƒ³ã€‚</p>
</li>
</ul>
</li>
<li>
<p>åŸºäºæ¨¡å‹æ‰“åˆ†ï¼šä½¿ç”¨å­¦ä¹ åˆ°çš„å•è¯å’Œå¥å­<strong>è¡¨å¾</strong>æ¥è®¡ç®—ç”Ÿæˆæ–‡æœ¬å’Œå‚è€ƒæ–‡æœ¬ä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼æ€§ã€ä¸å†å­˜åœ¨n-gramçš„ç“¶é¢ˆï¼Œå› ä¸ºæ–‡æœ¬å•å…ƒè¢«è¡¨ç¤ºä¸ºåµŒå…¥ã€è¿™äº›åµŒå…¥æ˜¯é¢„è®­ç»ƒçš„ï¼Œç”¨äºè¡¡é‡ç›¸ä¼¼æ€§çš„è·ç¦»åº¦é‡å¯ä»¥æ˜¯å›ºå®šçš„</p>
<ul>
<li>Word distance functionsï¼šVector Similarityã€Word Moverâ€™s Distanceã€BERTSCORE</li>
<li>Beyond word matchingï¼šSentence Movers Similarityã€BLEURT</li>
<li>Evaluating Open-ended Text Generationï¼šMAUVE</li>
</ul>
</li>
<li>
<p>åŸºäºäººç±»è¯„ä¼°ï¼šè¯„ä¼°äººå‘˜è€ƒè™‘çš„ç»´åº¦ï¼šæµç•…æ€§ã€è¿è´¯æ€§ã€äº‹å®æ€§å’Œæ­£ç¡®æ€§ã€å¸¸è¯†æ€§ã€é£æ ¼ã€è¯­æ³•æ­£ç¡®æ€§ã€å…¸å‹æ€§ã€å†—ä½™</p>
</li>
<li>
<p>benchmarkï¼šè®¸å¤šbenchmarkä¸»è¦ä¸ºåšæ–‡æœ¬åˆ†ç±»æˆ–è€…é€‰æ‹©é¢˜ï¼Œè®¡ç®—å‡†ç¡®åº¦æˆ–è€…F1ã€‚</p>
</li>
</ul>
</li>
<li>
<p>ä¼¦ç†è€ƒè™‘ï¼š</p>
</li>
</ul>
<p>è‡ªæˆ‘æ”¾å¤§æ•ˆåº”ï¼šé‡å¤åŒä¸€ä¸ªphraseï¼Œå¹¶ä¸”é‡å¤çš„è¶Šå¤šä¿¡å¿ƒè¶Šå¤§ã€‚ç›®å‰è§„æ¨¡å’Œæ¶æ„éƒ½è¿˜æ²¡æœ‰è§£å†³è¿™ç§é—®é¢˜</p>
<p>å‡å°‘é‡å¤æ–¹æ³•</p>
<p>top-pï¼Œå‚è€ƒ<a class="link" href="https://blog.csdn.net/dongtuoc/article/details/135042289?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522171034123216800215038564%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=171034123216800215038564&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-135042289-null-null.142%5ev99%5epc_search_result_base8&amp;utm_term=top_p&amp;spm=1018.2226.3001.4187"  target="_blank" rel="noopener"
    >åšå®¢</a></p>
<p>è§£ç å¼•å…¥éšæœºæ€§ï¼Œæ¨¡æ‹Ÿäººç±»å†™åšçš„æ³¢åŠ¨ï¼šTop-ké‡‡æ ·ã€top-pï¼ˆæ›´çµæ´»çš„top-kï¼Œè®¡ç®—é‡æ²¡æœ‰åŒºåˆ«ï¼Œå› ä¸ºä»ç„¶è¦å…¨éƒ¨è®¡ç®—å‡ºè¯å…¸æ‰€æœ‰å•è¯çš„æ¦‚ç‡ï¼‰</p>
<p>æ‰©å¤§éšæœºæ€§ï¼šæ¸©åº¦ç³»æ•°ï¼šå¯¹æ‰€æœ‰è¾“å‡ºé™¤ä»¥tï¼Œå†åšsoftmaxã€‚è¾“å‡ºä¼šæ›´åŠ å¤šæ ·æ€§ã€å¹³å¦å‡åŒ€ã€‚</p>
<p>LLMå®¹æ˜“å‡ºç°å¹»è§‰çš„åŸå› å¯èƒ½ä¸è§£ç ç­–ç•¥æœ‰å…³ï¼šå¯å½’å› äºtop-pé‡‡æ ·ä¸ºæé«˜å¤šæ ·æ€§è€Œå¼•å…¥çš„éšæœºæ€§ï¼Œè¿™å¯èƒ½ä¼šæ— æ„ä¸­å¯¼è‡´å¹»è§‰ä¸è¶³å¯å½’å› äºtop-pé‡‡æ ·ä¸ºæé«˜å¤šæ ·æ€§è€Œå¼•å…¥çš„éšæœºæ€§ï¼Œè¿™å¯èƒ½ä¼šæ— æ„ä¸­å¯¼è‡´å¹»è§‰ã€‚éšæœºæ€§è™½ç„¶æ˜¯å¯¼è‡´å¹»è§‰çš„å› ç´ ï¼Œä½†æ˜¯æˆ‘ä»¬ä¸èƒ½å› å™åºŸé£Ÿï¼Œå³ä¸èƒ½ä¸ºäº†ç¼“è§£å¹»è§‰è€Œå¯¼è‡´å¤§æ¨¡å‹ç”Ÿæˆå¥å­çš„æµç•…æ€§å¤§å¹…é™ä½ã€‚https://zhuanlan.zhihu.com/p/664293575</p>
<p>è…¾è®¯LLMå¹»è§‰ç»¼è¿°ï¼Œå‚è€ƒ<a class="link" href="https://www.jiqizhixin.com/articles/2023-09-14-2"  target="_blank" rel="noopener"
    >é“¾æ¥</a>ï¼šå¹»è§‰æ¥æº</p>
<ol>
<li><strong>å¤§æ¨¡å‹ç¼ºä¹ç›¸å…³çŸ¥è¯†æˆ–è€…è®°å¿†é”™è¯¯çŸ¥è¯†</strong>ï¼šåœ¨å¤§æ¨¡å‹å›ç­”ç”¨æˆ·é—®é¢˜æˆ–è€…è§£å†³æ›´å¤æ‚çš„ä¸‹æ¸¸ä»»åŠ¡æ—¶ï¼Œå¦‚æœç¼ºå°‘äº†æ‰€éœ€è¦çš„çŸ¥è¯†æˆ–è€…ä»è®­ç»ƒæ•°æ®ä¸­è®°å¿†äº†é”™è¯¯çš„çŸ¥è¯†ï¼Œåˆ™æœ‰å¯èƒ½å‡ºç°å¹»è§‰ã€‚</li>
<li><strong>å¤§æ¨¡å‹é«˜ä¼°äº†è‡ªå·±çš„èƒ½åŠ›</strong>ï¼šä¸€äº›å·¥ä½œå‘ç°ï¼Œå¤§æ¨¡å‹å¾€å¾€æ— æ³•å‡†ç¡®åœ°ä¼°è®¡è‡ªå·±çš„èƒ½åŠ›è¾¹ç•Œã€‚å› æ­¤ï¼Œå¤§æ¨¡å‹åœ¨å›å¤è¶…å‡ºè‡ªå·±èƒ½åŠ›çš„é—®é¢˜æ—¶ï¼Œå¾€å¾€ä¼šé«˜ä¼°è‡ªå·±ï¼Œä»è€Œè‡ªä¿¡åœ°ç¼–é€ å¹»è§‰å›å¤ã€‚</li>
<li><strong>å¯¹é½è¿‡ç¨‹ä¸­å¼•å…¥å¹»è§‰</strong>ï¼šå¤§æ¨¡å‹åœ¨é¢„è®­ç»ƒé˜¶æ®µå¤–ï¼Œè¿˜éœ€è¦è¿›è¡Œå¯¹é½ï¼ŒåŒ…æ‹¬æŒ‡ä»¤å¾®è°ƒå’Œ RLHFã€‚è¿™äº›æ­¥éª¤å¯èƒ½è¯¯å¯¼å¤§æ¨¡å‹å‡ºç°å¹»è§‰ã€‚ä¾‹å¦‚ä¸æ°å½“çš„æŒ‡ä»¤å¾®è°ƒå¯èƒ½è®©å¤§æ¨¡å‹å­¦ä¼šæé€ è‡ªå·±ä¸ä¼šçš„ç­”æ¡ˆï¼ŒRLHF ä¹Ÿå¯èƒ½è®©å¤§æ¨¡å‹å­¦ä¼šä¸ºäº†è®¨å¥½äººç±»è€Œç¼–é€ å†…å®¹ã€‚</li>
<li><strong>ç”Ÿæˆè¿‡ç¨‹ä¸­å¼•å…¥å¹»è§‰</strong>ï¼šä¸€äº›å·¥ä½œè®¤ä¸ºï¼Œä¸æ°å½“çš„ç”Ÿæˆç­–ç•¥ä¹Ÿå¯èƒ½å¯¼è‡´å¤§æ¨¡å‹å‡ºç°å¹»è§‰ã€‚ä¾‹å¦‚ï¼ŒåŸºäºé‡‡æ ·çš„è§£ç ç”Ÿæˆæ–¹å¼ä¸­å¼•å…¥çš„éšæœºæ€§è¢«è¯æ˜å¯èƒ½å¯¼è‡´å¹»è§‰ï¼Œè€Œå¤§æ¨¡å‹å¸¸ç”¨çš„è‡ªå›å½’ç”Ÿæˆæ–¹å¼ä¹Ÿå¯èƒ½å¯¼è‡´å¹»è§‰çš„ç´¯ç§¯ä¼ æ’­ç°è±¡ã€‚</li>
</ol>
<p>åœ¨LUREè®ºæ–‡ä¸­ï¼Œè®ºè¿°ç›®æ ‡ç‰©ä½“çš„ä¸ç¡®å®šæ€§ï¼Œä½œè€…è®¤ä¸ºå¯èƒ½æ˜¯ç”±äºæŸæœç´¢å¯¼è‡´çš„ã€‚å¯ä»¥è§£é‡Šä¸ºè¢«é‡‡æ ·çš„å¥å­è™½ç„¶æ•´ä½“ä¸ç¡®å®šæ€§ä½ï¼Œä½†æ˜¯å¯¹äºé‚£å‡ ä¸ªå…·ä½“çš„ç›®æ ‡ç‰©ä½“å¯èƒ½å­˜åœ¨ä¸ç¡®å®šæ€§ã€‚</p>
<p>æ›å…‰è¯¯å·®ï¼šï¼ˆè‡ªå›å½’çš„é—®é¢˜ï¼Ÿï¼Ÿï¼Ÿï¼Ÿæ»šé›ªçƒå¼çŠ¯é”™ï¼‰ã€‚è§£å†³ï¼šè®¡åˆ’é‡‡æ ·ï¼ˆè®­ç»ƒæ—¶ä»¥æ¦‚ç‡pï¼Œä½¿ç”¨é¢„æµ‹çš„tokenä»£æ›¿gold tokenï¼‰ã€æ•°æ®é›†ï¼ˆè®­ç»ƒåˆ°ä¸€å®šç¨‹åº¦åï¼Œç”¨æ¨¡å‹ç”Ÿæˆä¸€äº›æ–‡æœ¬æ’å…¥åˆ°æ•°æ®é›†ä¸­ï¼‰</p>
<p>è¯„ä¼°æŒ‡æ ‡ï¼šBLEUã€ROUGEã€CIDErã€SPIDEr</p>
<p><a class="link" href="http://jalammar.github.io/illustrated-gpt2/"  target="_blank" rel="noopener"
    >http://jalammar.github.io/illustrated-gpt2/</a></p>
<h2 id="prompt">Prompt
</h2><p>Promptä¸å¾®è°ƒçš„è”ç³»ï¼šåœ¨Promptä¸­ç»™å‡ºcaseä¹Ÿèƒ½æå¤§çš„æå‡æœ€åçš„ç»“æœã€‚ä½†æ˜¯promptæ˜¯è¾“å…¥ç»™å†»ç»“çš„æ¨¡å‹ä¸­ã€‚</p>
<p>è¦æƒ³é€šè¿‡Promptæå‡æœ€åçš„ç»“æœï¼Œç»™å‡ºçš„ç¤ºä¾‹ä¸­ä¸ä»…åªè¦é—®é¢˜å’Œæœ€åç­”æ¡ˆï¼Œè¿˜åº”ç»™å‡ºæ€ç»´é“¾è¿‡ç¨‹ï¼Œè¿™ä¼šé¼“åŠ±LMéµå¾ªè¿™æ ·çš„æ¨¡å¼ã€‚</p>
<h2 id="instruction">Instruction
</h2><h2 id="rlhf">RLHF
</h2><h2 id="dpo">DPO
</h2><h2 id="reasoning">Reasoning
</h2><h2 id="agents">Agents
</h2>
</section>


    <footer class="article-footer">
    

    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI&#43;WdtXRGWt2kTvGFasHpSy3SV"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG&#43;vnGctmUb0ZY0l8"crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"integrity="sha384-&#43;VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4&#43;/RRE05"crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ],
            ignoredClasses: ["gist"]
        });})
</script>
    
</article>

    

    

     
    
        
    <div class="disqus-container">
    <div id="disqus_thread"></div>
<script>
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "hugo-theme-stack" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

<style>
    .disqus-container {
        background-color: var(--card-background);
        border-radius: var(--card-border-radius);
        box-shadow: var(--shadow-l1);
        padding: var(--card-padding);
    }
</style>

<script>
    window.addEventListener('onColorSchemeChange', (e) => {
        if (typeof DISQUS == 'object') {
            DISQUS.reset({
                reload: true
            });
        }
    })
</script>

    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2025 Hugo Theme Stack Starter
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.26.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
